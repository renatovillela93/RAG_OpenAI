BIM Education in Landscape Architecture: The Rapperswil Model \nAbstract\nIn 2016, Switzerland decided to embrace digitization in every industry, in all sectors, and at \r\nall  levels.  Within  the  Landscape  Architecture  program  at  the  OST  University  of  Applied  Sciences, teaching and research with strong emphasis on Digital Construction had already been carried out for years. In view of the country’s vigorous drive towards digitization and being the only bachelor's pro-\r\ngram in the German-speaking part of Switzerland, Rapperswil Landscape Architecture is committed to \r\npartake and to aid in this digitization process. The paper gives an overview of Digital Construction in \r\nLandscape Architecture education in Rapperswil, status 2022.\n\nIntroduction \nIn the coming years, the construction industry worldwide will undergo digital transformation. \nBuilding Information Modeling (BIM) plays a central role with the digital twin and with a \nclearly defined process. The strategy of the Swiss Federal Council from 2016 for digital Swit-\nzerland (SCHWEIZERISCHE EIDGENOSSENSCHAFT 2016) and the establishment of the frame-\nwork “Bauen Digital Schweiz – Digital Construction  Switzerland”, the country chapter of \nbuildingSMART International, gave the Swiss construction industry a big boost in the direc-\ntion of digitization The Swiss government  even  went one step further and defined a clear \ntime frame. By 2025, Switzerland will implement the BIM process not only in architecture, \nbut in all infrastructure construction projects. The Swiss Federal railway company Schwei-\nzerische Bundesbahnen (SBB), a government-owned company, must apply it in all projects \nby then. SBB is also a big player in real estate architecture projects where greenspaces are \nalways required. Therefore, this is not only applicable to engineers, but also landscape archi-\ntects have to get ready for digital construction. As result, Rapperswil is consistently pursuing \nthe goal of implementing “Digital Construction” in Landscape Architecture education. \n\nDigital Construction \nDigital Construction is the general term for using different digital technologies to build more \nefficiently. The below methods and processes belong to Digital Construction and are taught \nat Rapperswil. \n\nBIM Construction \nRapperswil students work three-dimensionally from day one. In the first semester, the BIM \narchitecture construction software (Revit) and the principle of a digital twin are taught. The \nstudents  are  required  to  build  an  existing  structure  (pavilion,  pergola,  water  feature,  etc.). \nThis approach has the following advantages: \nFast learning of architecture representation principles (floor plans, elevations, sections, 3D views), \n“One single source of truth” – the 3D model is the basis for all (representations, schedules\/quantities, etc.),\nObject oriented construction only with 3D objects, which belong to building categories, \nVery structured modelling with parametric objects (standard families, external families and project families), The model has container function for fundamental construction data. It is used for structural engineering (formwork\/reinforcement) and for MEP (Mechanical, Electric, Plumbing) modelling. \n\nIn the 2nd semester, the students integrate a building into an existing site based on GIS data \nwith  civil  engineering  programs  (InfraWorks  \/  Civil  3D).  They  locate  driveways,  parking \nlots, retention\/infiltration basins in the project. Students get to know the 3D Global Naviga-\ntion Satellite System (GNSS) excavator control system and learn what to look out for when \npreparing data for it. In principal students learn to use the correct tools for different chal-\nlenges, as BIM construction in Landscape Architecture consists of tools for architecture pro-\njects and tools for civil engineering projects. The scheme BIM4RainWaterManament (PET-\nSCHEK 2019) gives a good overview of the Rapperswil teaching in Digital Construction. \n\nBefore the students model the terrain digitally, they learn the craft by hand for one semester. \nIn the construction course in the first semester, the students have to solve numerous small \ntasks on terrain modeling with elevation points\/contour lines and prove their skills in a 1 ½ \nhour exam at the end of the semester. The exercises are based on U.S. grading courses, which \nare common at every north American landscape architecture program. Richard Untermann, \nwith the book “Grade Easy” (UNTERMANN 1972), was an important pioneer for several text-\nbooks on the English-language book market on terrain modelling and serves as the basis for \nthe Rapperwil grading education. \n\nMore complex architectural constructions, which serve as the basis for structural calculations, \nare the subject of the “Constructive Design” module in the 4th semester. This is also where \nthe cooperation with the civil engineers of the newly formed School of Architecture, Civil \nEngineering, Landscape Architecture, Spatial Planning of the OST is practiced for the first \ntime. \n\nThe previously often time-consuming visualizations are becoming a sideshow thanks to the \nBIM construction training. Software like Enscape3D or Twinmotion enables the virtual real-\nity (VR) inspection of the model with a headset or on the screen. Individual images in differ-\nent resolutions can be created from any point. Students can check out headsets and VR capa-\nble computers from a central IT service at OST. \n\nCommon Data Environment (CDE) \nIn addition to the 3D model, the management of processes and information is central to Digital Construction. Internet-based platforms, called Common Data Environment (CDE), are \nresponsible for data exchange, collaboration on a model, costs, quantities, materials, delivery, \ntesting and acceptance processes in all life cycle phases of the structure. \n\nIn the spring semester of 2020, like the other Swiss universities, all of Rapperswil’s landscape \narchitecture courses took place online. Since the first wave of the pandemic, Teams \/ Zoom \nconferences had been part of everyday life for all students. However, Rapperswil went a step \nfurther. It was made mandatory for all students to submit their BIM construction projects via \nthe CDE Autodesk Construction Cloud (ACC). A project folder is dedicated to each course, with student subfolders. There the students store their models, photos, sketches and text. The \nlecturers evaluate the work digitally, with the 3D model being the starting point. \n\nThomas  Putscher,  lecturer  at  OST,  writes,  “I  consider  the  submission  to  the  Construction \nCloud to be a good thing. The students found their way around quickly and it went smoothly. \nMeetings took place directly via Teams with the open 3D cloud model. The corrections to \nthe  model  were very easy  for me because I could do them directly online. I uploaded my \nevaluation sheets and informed all students via email about their grades. If necessary, there \nwere debriefings online with the open 3D model. All in all, the construction cloud has saved \nme a lot of time.” For Rapperswil, the full integration of the Common Data Environment into \nlandscape architecture training was the next logical step towards Digital Construction. From \nfall semester 2021, all students in the construction courses worked with the CDE platform \nright from the first semester. The cloud solution is now used for submission and evaluation \nin all construction courses up to the bachelor thesis. Paper plans are no longer used as submissions. \n\nBIM4RainwaterManagement \n“Climate change is leading to heavier and more frequent precipitation. In urban areas, where \ndevelopment means the total impervious surface area is increasing, there is a growing risk of \nflooding from surface run-off after heavy rainfall. In climate-adapted and risk-based urban \ndevelopment,  there  is  an  increasing  need  to  manage  rainwater  resources  sustainably.  The \nconcept of 'sponge cities', which focus on increasing evaporation, infiltration, retention, controlled  temporary  flooding  and  providing  emergency  waterways,  is  a  planning  solution  to \nprevent damage from surface run-off and to reduce the effects of heat” (BAFU\/ARE 2022). \n\nLandscape Architects must take over a leading role in building 'sponge cities'. How can the \nprinciple of the sponge city be realized as part of Digital Construction? Although it belongs to  BIM  Construction,  this  very  important  topic  is  specifically  addressed  under  the  title \nBIM4RainWaterMangement. It is taught in the construction course in the 5th semester. The \nbasic goals of BIM4RainWaterManagement are: \nReturn of clean rainwater to the groundwater\nOptimization of a slow percolation\nUsage of a digital twin. \n\nWhen building the digital twin, the students apply the steps of the BIM4RainWaterManagement scheme (PETSCHEK 2019) and of course, they  use digital terrain  modelling. It is the \nbasis for quickly testing precise alternatives of retention and infiltration and thus find the \nideal solution for allowing rainwater percolation on site. The civil engineering software and \nthe  architecture  software,  combined  with  their  respective  strengths,  are  used  to  set  up  the \nBIM4RainWaterManagement project. \n\nThe 3D model has the following advantages: \nProof of retention areas in the event of heavy rain events. All water from roof tops and surfaces percolates on site, \nPrecise modeling of pavement surfaces and subsurface structures, \nParametric inlets, sludges collectors, manholes and pipes are included in the digital twin, \nClash detection between tree root balls and subsurface drainage elements, \nPrecise stakeout of all elements using BIM2Field, \nStudy of site grading alternatives with the help of automized grading (Grading Optimization in the civil engineering software). \n\nIn the next step, a link between the digital twin and numeric stormwater management soft-\nware will be established to validate the model and integrate it into a larger GIS analysis con-\ntext. Also extracting sustainability data from the digital twin will be an important topic. \n\nBIM4Trees \nStudents “plant” as part of the course described under point 2.3 BIMTrees. The trees were developed by Andreas Luka Consulting in close cooperation with Rapperswil, and the Swiss landscape contractor association Jardin Suisse, in which the Swiss tree nurseries are organized. \n\n3D trees are a major challenge for BIM in Landscape Architecture, as their geometry and \nproperties change significantly over the entire life cycle (LUKA & GUO 2021). Existing solutions did not adequately meet this challenge and could only insufficiently exploit the potential \nof BIM. Rapperswil therefore, supported the implementation of dynamic BIM trees with a \nresearch project. \n\nThe focus on the outer shells for crown, tree trunk and root, which are important for BIM, \nand their representation as solids allow both efficient clash detections and the extraction of \nvolumes  and  masses  for  further  analyses  (structural  engineering  calculations  and  shadow \ncasting). The tree size can be predicted interactively and quickly within the BIM software \nusing initial values for size when planting and growth functions for any point in time after \nplanting, complete with root in species, variety and age-specific shape and size. By simply \nlinking the very technical looking trees with Enscape3D, convincing visual representations \nof tree planting are created. \n\nThe feedback from independent study and bachelor projects flows directly into further development. There are currently 80 species\/varieties with the shapes and sizes according to \nthe Swiss quality regulations and the catalogue of a large German tree nursery. \n\nBIM2Field \nDigital Construction is based on digital data. In addition to the existing GIS data, one often \nneeds to collect his\/her own data. Point clouds from drone flights are a possibility. However, \nlandscape architects need height information below the tree and shrub layer. Drones cannot \nbe used here. The mobile laser scanner BLK2GO (LEICA Geosystems) is the latest generation of mobile laser scanning. A stationary device no longer has to be set up as before as the \nscanner can be used while walking through the site. This flexibility is extremely important in \nLandscape Architecture. The created point cloud is then post-processed and prepared for the \nBIM construction. The OST students use laser scanning as a regular tool in their projects. \n\nSince the fall semester of 2021, the surveying course has been renamed “BIM2Field”. The \napplication  of  one  person  tachymeter  stations  is  taught.  The  six  robotic  stations  use  the \ngeoreferenced  model loaded on the Construction  Cloud directly for stake out  without any \nintermediate steps. GNSS machine control systems in addition are presented in class by commercial companies. \n\nBIM2Cost \nThe central topics of the Landscape Architecture training in Rapperswil are cost calculations \nand construction specifications (specs). The 5th semester course, described under 2.3. is also \npioneering in this area. In Switzerland, the basis for efficient construction costs is the element-based  classification  eBKP-H,  which  was  developed  by  the  Swiss  Central  Office  for \nConstruction Rationalization CRB. The cost-relevant quantities are collected directly in the \ndigital twin. Automatically calculated dimensions and volumes result in more precise cost \nestimates. Due to clash detection, errors in the construction are detected early and thus in-\ncrease cost certainty. In the future, construction schedules will be displayed as 4D simulations \nusing the Common Data Environment ACC. In this way, the planned construction process \ncan be checked visually by the students and any contradictions can be solved. \n\nYouTube Channel \nThe YouTube Channel “Landscape Architecture Rapperswil” is the medium for the presentation of student independent study projects, thesis work and lectures on the topic. The following posts on building digital can be found on the constantly updated YouTube Channel: \nBIM2Field, laser scanner and robotic tachymeter: https:\/\/youtu.be\/icjaM3AoRa0 \nBIM2Field, 3D GNSS digger: https:\/\/youtu.be\/2MTnb7rV58o \nBIM Student independent study project: https:\/\/youtu.be\/q2SMcJ2knjg \nBIM Bachelor thesis: https:\/\/youtu.be\/0X8VUk-FyUM \n\nConclusion and Outlook \nDigitization in the Swiss construction industry is taking big steps forward; Landscape Architecture is not unaffected by this. Education in design, planting design, ecology and construction are the foundation of future Landscape Architects. In addition, skills in Digital Construction  must  be  integrated  today.  The  next  step  is  the  switch  to  Bring  Your  Own  Device \n(BYOD). From fall semester 2023, students are required to use their own devices in all Rapperswil courses. Computer labs will be no longer in use. It is also planned to integrate the \ndigital twin topic in the GIS teaching. In conclusion, OST Ostschweizer Fachhochschule in \nRapperswil acknowledges the challenges of Digital Construction and is riding along the digital wave.  

Digital Landscape Architecture Education – Where Do We Stand and Where Should We Go?  \n\nAbstract: Landscape architecture has a crucial role in designing landscapes to influence how they per-\nform in a desired manner and provide more resilient and adaptive environments. Sophisticated analyti-\ncal and design tools and techniques exist along with data from a range of allied disciplines that have \nthe capacity to inform and transform the way landscape design approaches are conceived. However, \nthese are not widely embraced across landscape architectural design schools as a status quo. This paper \naims to provide a prompt to initiate a critical theoretical discussion on the future pedagogical foci for \ndigital landscape architecture education discourse at the forthcoming DLA  conference in 2023. The \ncritical question is, what is the future direction of digital landscape architecture education to address \nthe pressing and complex challenges of the climate crisis? For the purpose of this paper and the confer-\nence, we have limited the focus to three streams of digital landscape architecture: approaches, tools, \nand techniques. These critical streams of the discipline are framed through a brief synopsis capturing \nlineages from the 1960s to identify their influence on landscape architecture design education. Patterns \nand processes that lead to shortcomings in implementing the approaches are discussed. This is con-\ncluded with a set of questions derived from identified gaps to stimulate a targeted discussion on the \nfuture trajectories of digital landscape architecture education. \n\nIntroduction \nIn the face of climate change, we are confronted with accelerated urbanization and environmental  degradation.  \nThe  transformation  of  our  landscape  and  urban  systems  toward  more \nequitable, resilient and adaptive environments is urgently required, imbuing the capacity to \nrepair  and  respond  to  future  crises  and  to  adapt  to  unpredictable  futures  (ELMQVIST et  al. \n2019, SHEARER et al. 2021, FRICKER 2022a). \n\nDigital design education in landscape architecture that considers scales of action from the \nplanetary to the regional and microbial, has a crucial role in equipping students with the design  capabilities to  generate  alternative  typologies  of  aesthetics  and  performance  (MEYER 2008, FRICKER et al. 2020). This includes landscape transformations that perform in a desired \nmanner  (STEINITZ 2012, URECH et  al. 2020, GRÊT-REGAMEY et  al. 2021). To  this  end,  the \ndiscipline has developed sophisticated design and analytical tools, such as 3D point clouds, \nas a basis for urban design and algorithmic analysis of energy absorption, wind flow, and \nshadow  provision  (URECH  et  al.  2020,  2022).  They  support  an  integrated  analysis  across \nscales and feedback loops, as evidenced in several recent projects, like the example of a river \nrehabilitation project at the local scale that consequently explores the larger catchment area \n(VOLLMER  et  al.  2015,  GRÊT-REGAMEY  2017).  An  illustrative  overview  of  tools  and  approaches for responsive \nlandscape design is provided by  WALLIS & RAHMANN (2016), as \nwell as by CANTRELL & HOLZMANN (2016). The publications provide a comprehensive overview of design projects and \nresponsive technologies that frame performance as a generative \ndesign approach. Furthermore, heterogeneous data on environmental and socio-economic as-\npects are available with unprecedented detail to inform design approaches. For example, ur-\nban sustainability transformation projects that use passively sensed geospatial data of land \nuse, service networks etc., may be augmented by active sensing of stakeholder perceptions \nand behaviour  with participatory  methods and technologies (GRÊT-REGAMEY et al. 2021). \nHowever, although increasingly more tools and datasets are developed, and the agency of \ntheir application is demonstrated in prototypes (CANTRELL & HOLZMAN 2015), they are not \nwidely used across landscape architectural design schools. We postulate that a critical dis-\ncussion on digital design education is lacking in the discipline of digital landscape architec-\nture  (FRICKER 2022b).  Therefore,  we  propose  to  investigate  this  in  the  forthcoming  2023 \nDigital Landscape Architecture conference. \n\nThis paper acts as a precursor for the future conference dialogue to interrogate where Digital \nDesign Education is positioned and how to advance the pedagogical approaches of digital \nlandscape architecture. For this,  we  want to highlight some of the  existing theories of the \ndiscipline in the discussion, describe the status quo, and point out recent  “streams of con-\nsciousness”. This demonstrates that the landscape architecture discipline has constantly been \ninfluenced by and porous to other disciplines, thinking, tools and techniques that have con-\nstructed amorphous streams and trajectories continually being made and positioned (FRICKER \n2021). A complete review of the theoretical streams in digital landscape architecture is be-\nyond the scope of this paper. However, we reflect on specific critical theories and associated \ntools and processes from the 1960s to today that have significantly influenced current educa-\ntional practice in digital landscape architecture. The intention is not to give a comprehensive \nhistory of digital landscape architecture, but a framing of various digital design approaches \nin landscape architecture as a departure point for a discussion on future tools and techniques. \nWe use this review to discuss recurring patterns and processes in how new approaches and \ntools are used and how the gap in implementation manifests (ERVIN 2018). This leads us to \nformulate concrete questions to specify further: How do students need to be taught digital \napproaches? Where should we focus on enhancing our students' teaching? Furthermore, what \nneeds to be taught in digital landscape architecture education? \n\nA Synopsis of Computational Lineages \nFrom System Thinking to Artificial Intelligence \nThis chapter aims to reflect on a selection of relevant concepts and  workflows developed \nmainly during the 1960s and 1970s, which strongly influenced a pedagogy for the computa-\ntional realm and demonstrated a radical approach to creatively interact with diverse data sets \nacross scales. The purpose of this brief historical reflection is to unveil concepts to be revisited within the current discussion on defining possible avenues for adjusting the present trajectory of the digital pedagogy in the field of landscape architecture. Due to the richness of \nhistorical  references,  the  discussion  is  focused  on  key  examples,  inviting  for  an  extended \ndiscussion towards the future of the digital landscape architecture education and implementation within practise. Note: the selected examples in this paper address only male scientists. \nWe want to acknowledge that in these known lineages, female leaders in the field often need \nto be discussed as being more instrumental to the development. We aim to capture and slowly \nrectify this familiar narrative in future discussions. \n\nAlready towards the end of the 60s, computational design thinking pioneers recognized the \npotential of machine-human interaction to sound out new potentials within architecture and \nlandscape architecture. Almost 25 years later, the integration of “computation” in teaching \nushered a fundamental pedagogic change in direction for design teaching, research, and a \nform making language. In addition, a parallel stream “Digital Design Education” established \nitself with a focus primarily on the visualization applications of digital tools and the teaching \nof new software (ERVIN & HASBROUCK 2001, FRICKER 2021). The presented historical overview allows for a discussion in order to shift the focus from a merely tool-based approach \ntowards holistic computational design thinking. \n\nThe history of computation goes far beyond the development of computing technology and \nrelates to the “interaction between internal rules and (morphogenetic) pressures that, themselves,  originate  in  other  adjacent  forms  (ecology)”  (MENGES & AHLQUIST 2011, 8). This \ncomplex theory and framework of relationships is based upon theories from disciplines like \nmathematics, computer science, cybernetics, biology and philosophy. The integration of in-\nformation technological developments into the landscape architectural curriculum accelerated especially during the 1960s and 1970s through an intensive exchange between cybernetics and its influence on architecture (MENGES & AHLQUIST 2011). This first manifestation \nwas driven by a deep theoretical discourse and led to the first integration of Artificial Intelligence (AI) in design methodology. The fusion of these two areas lay in new questions related \nto the rise of global ecological challenges, which also changed our relationship to data and \nour interaction with the information it contained (FULLER 1969, MEADOWS et al. 1972). The \ntheories developed in the area of cybernetics allowed a new computational design method to \nbe established mainly within architecture, which describes this complex network of relationships  through  the  integration  of  System  Theory  and  Patterns  (FRAZER  1993).  In  the  late \n1960s, Jay Forrester, a computer engineer and system  scientist by education, strongly engaged in describing the “systemic structure responsible for the dynamics of urban development and decay”, founded the Urban System Group at MIT (FORRESTER 1973). \n\nThe themes discussed between cybernetics and architecture influenced simultaneous developments in landscape architecture with respect to the domain of system thinking in the field \nof spatial data handling. This is because both the fields of architecture and landscape architecture  were called to address issues of rapid urbanization.  Though the field of landscape \narchitecture recognized the necessity of developing new approaches for handling data, it did \nnot develop meaningful questions or further research with AI. \n\nEmerging Pedagogical Principles \nOne of the pioneering academic institutions, introducing a new form of design education with \nspecial focus on computational design thinking, was the Ulm School of Design (Hochschule \nfür Gestaltung in Ulm, HfG), active from 1953 until 1968. Already 17 years before the foundation of the Architecture Machine Group by Nicholas Negroponte and Leon Groisser, at a time “computers were only available at a few research centres, (…) their capabilities were \nwidely recognised and the subject of much broader theorisation and influence, opening up \nthe field of logic and computer science to the social sciences and arts” (NEVES et al. 2013, \n292). The new pedagogical approach of the HfG is understood as a research-based activity, \nstrongly engaged in theoretical discourse focusing on a new understanding of design, which \nis based on thinking in connections and networks. \n\nThe “pioneered heuristic procedures that were related to the power of the new computational \nmethods” (NEVES et al. 2013, 299) developed at the HfG can be seen in strong relation to the \ncomputational  education  developed  by  Negroponte.  Negroponte  recognized  that  problem-based learning concepts and the opportunity to work together with the computer for direct \nfeedback  significantly  increased  students’  motivation.  Programming  was  understood  as  a \nnew way of thinking! Negroponte experimented with the potential of formal descriptions of \narchitectural solutions, implemented through a program and deployed as Computer  Aided \nParticipatory Design. Thus, he laid the foundation for current methods in the field of AI and \nemphasized, “However, remember that these systems assume the driver to be an architect” \n(NEGROPONTE 1975, 365). The influence of the early computational design development in \nthe education of architecture has had very little impact on the area of landscape architecture \neducation. The only traces of limited integration of computational design can be observed at \nthe newly founded Laboratory of Computer Graphics at Harvard Graduate School of Design \nin 1965. Contrary to the radical development and interaction with data for generative purposes at the Arch MAC Group at MIT, landscape architecture education at Harvard’s GSD \nconcentrated mainly on layered data-mapping methods. \n\nThe Evolution of Spatial Thinking: From GIS-based Layering towards Mapping \nThe field of landscape architecture focused its emerging computational possibilities on re-\nsearch and application in teaching during the 60s and 70s on problems related to Big Spatial \nData. The pressure to develop new methods to process the complex relations of nature-based \nprocesses was strengthened by the new arising “Ecological Awareness”. The idea of layering \nspatial information and its use for evaluating designs was presented 1971 in the book “Design \nwith Nature” by Ian McHarg (LEE et al. 2014). Based on this idea, Geographic Information \nSystems (GIS) originated largely at Harvard GSD enabled to geographically allocate digital \ndata and create maps (FOSTER 2016). Further developments in the 1970s and 1980s focused \non  spatially  analysing  the  system  from  different  aspects.  In  the  following  period  the  user \ninterfaces, data processing capabilities and data interoperability were enhanced, and with this, \nits  applicability  for  many  user  groups  (LEE at  al. 2014). This  development  enabled  easier \naccess to digital geodata and simulations for assisting in a design process, and in 2012, Carl \nSteinitz published a “Framework for Geodesign”, which presents an iterative process of integrating stakeholders’ knowledge, needs and desires, geospatial modelling, impact simulation and rapid feedback on the degree of achieving a desired goal to facilitate an informed, \nresponsive design (FOSTER 2016, STEINITZ 2012). \n\nCurrent “Streams of Consciousness” \nStreams of consciousness describe time infused recursively in the material reality of the landscape through states of formation, from those that signify stability to sequences that are predictable and observable processes of change to those that are uncertain and instantaneous. \nMASSUMI (2002) suggests that our own “human” sensing of the world experienced through \nsensation involves a “backward referral in time”. Therefore, a sensation is organised recursively prior to being part of our conscious chain or actions and reactions. In this process, the \nsmoothing over of the anomaly is made to fit our conscious requirements of continuity and \nlinear causality. \n\nThe act of measuring and making the landscape is not a neutral activity; therefore, the process,  techniques,  and  tools  of  representing  form  are  rooted  in  a  specific  understanding  of \necosystems and their processes. “Actant is a term from semiotics covering both humans and \nnonhumans; an actor is any entity that modifies another entity in a trial; of actors it can only \nbe said that they act; their competence is deduced from their performances; the action in turn \nis always recorded in the course of a trial and by an experimental protocol, elementary or \nnot” (LATOUR 2004). Tools for measuring the landscapes, and the techniques by which we \ndeploy them, have their own constraints that translate and transform information. The representations we make are constructed from a set of instruments, codes, techniques, and a lineage  of  conventions.  Consequently,  the  worlds  they  describe,  and  project  are derived  only \nfrom those aspects of reality susceptible to those techniques. These acts of measuring, anaysing and making the landscape can formulate a view of what already exists and set conditions for new worlds to emerge. Below are three examples of what we refer to as porous, \nconstantly evolving “streams of consciousness”. \n\nEntangled Knowledge Systems: STEINITZ’S (2012) framework provides a clear structure on \nhow to design a design process for multi-disciplinary collaboration to better address the complexity of environmental problems across scales (FOSTER 2016). Along with the emergence \nof the new field of Geodesign, geodesign education programs were launched (WILSON 2014) \nand today, universities worldwide participate in the International Geodesign Collaboration \n(https:\/\/www-igcollab.hub.arcgis.com).  A  major  challenge  in  the  education  of  Geodesign, \nhowever, are the strict disciplinary silos at the universities that hinder cross-disciplinary collaboration (WILSON 2014). Further, recent evaluation of geodesign processes reveal that not \nall projects implement the full structure and particularly the analysis of spatial relationships \nand impact analysis across scales are often not well performed (GU et al. 2020). \n\nThe emergence of geodesign and other GIS-based methodologies coincided with the critical \ndiscourse on big data and the development of open-source systems that enabled collective \ncontribution and alternative algorithms to reveal bias in large data sets. In landscape architecture education, students were educated on the ethical and responsible use of big data to \ncritically address the inherent power that data has had historically in producing unjust actions \nand policies on the oppressed. The emergence of “hacking” data approaches and the creation \nof alternative data sets as a public good and public service consequently emerged (GABRYS 2016, WILLIAMS & PROQUEST 2020). \n\nEmergent Patterns: In another stream, contemporary research in landscape architecture ad-\ndresses, in particular, the technical challenge of best-representing geo-data and environmen-\ntal factors to foster an understanding of information and making sense of it (URECH et al. \n2020). For example, a collection of drawing types, such as diagrams, axonometry and map-\npings, has been assembled (AMOROSO 2015). In response to more complex landscape rela-\ntionships and organizational patterns in landscape architecture education, digital syntax, such \nas codes and patterns, is used to establish quantitative correlations between the landscape and \ndata processing. These approaches are utilized as a generative component for design produc-\ntion (M’CLOSKEY & VANDERSYS 2017, CANTRELL & MEKIES 2018). \n\nInternational Fields: With the environment globally changing more rapidly than ever be-\nfore, in the first two decades of the 21st century the awareness of urgency for an immediate \nresponse for solving problems increased. This gave rise to the use of point clouds recorded \nin the field with a  terrestrial laser scanner to rapidly replicate the physical landscape with \nhigh resolution and fidelity and as basis for analysis and design (GIROT 2019, URECH et al.2020). The point cloud models provide a common ground between architects, engineers, and \nscientists to develop informed landscape design (GRÊT-REGAMEY et al. 2021, GRÊT-REGA-\nMEY 2017, VOLLMER et al. 2015). By performing geospatial analyses using the geometry of \nthe point cloud  model, spatial configuration parameters can be investigated and enhanced \nemploying simulation models, e. g., for improving climate conditions through altering build-\ning  and  vegetation  patterns  (URECH et  al. 2020).  In  this  way,  the  point  cloud  models  and \nimmersive data interaction allow for more dynamic and versatile forms of landscape design \nthrough all scales involving aesthetic and performance considerations (GIROT 2019, URECH \net al. 2022). But the approach is still very experimental and has not yet found widespread use \nin digital design education in landscape architecture. \n\nDiscussion and Conclusion: How to Consolidate the Gap? \nWhen we look at the outlined examples, there are some recurring patterns that suggest a gap \nin the implementation of tools and approaches. A major concern is that often the full understanding is left out of what the process behind a generated solution is. In particular, this is \nevident in three crucial pitfalls of tool implementation, which we exemplarily point out as: \n(1) using “black box” digital tools, (2) improper calibration, and linear processes (3) focusing \non single aspects rather than interactions and processes across systems. \n\nConcerning  the  first  pitfall  with  the  tremendously  fast  development  of  cutting-edge  tools, \ndesigners become mere users without an understanding of the underlying processes and the \ninherent critical distance to the results. Looking back in the history of digital landscape architecture, the invention and use of digital tools in the design process (such as Grasshopper) led to concerns of employing a “black-box” optimization, taking the output as a goal in itself \nand lacking a more holistic systems thinking (FRICKER et al. 2020). \n\nSecond, not understanding the complex relationships of the defined parameters of a model \nand making uninformed choices of input data can also lead to wrong design decisions and \noptimization processes. For example, a data set is assembled only in the beginning of a design \nproject  and  often  neither  updated  nor  further  data  is  collected  according  to  the  generated \nsimulation  outputs  (FRICKER 2021).  Overall,  a  critical  engagement  with  the  collected  and \ngenerated data across scale and fields is missing. \n\nThird, there is a risk of justifying a design through simulation results on single aspects or on \none specific scale while the design solution actually is not solving the problem when examined  at  a  large  scale  because  of  mutual  interactions  of  single  aspects  on  various  scales \n(FRICKER et al. 2020). Disregarding aspects can lead to undesired developments, for example, \nfocusing only on the design site for river rehabilitation one might overlook effects of developments in the catchment area still leading to severe flooding (VOLLMER et al. 2015). An urban densification that helps minimize urban sprawl can increase the urban heat island effect \nand negatively affect a series of services provided by the urban ecosystem such as the provi-\nsion of recreational area, storm water infiltration and retention, or habitat for species (GRÊT-\nREGAMEY 2017, WISSEN HAYEK & GRÊT-REGAMEY 2021). There is a lack of understanding \nof system dynamics, spatial patterns and relationships (WOOD 2017). \n\nLandscape architecture as a discipline is evolving rapidly as it responds to both broadening \nand intensifying changes in environmental, social and political conditions. These changing \nconditions require development and innovation in the digital competencies of landscape architects. What approaches, digital skills and technologies are needed by landscape architects \nto equip them to deal with the complexities brought forth by the climate crisis? Then comes \na  critical  consequential  question:  how  can  we  design  the  education  of  future  practitioners \n(MONACELLA & KEANE 2023). \n\nThe transformation of the digital landscape architectural education must involve profound \nreconfiguration  of,  and  innovation  in,  discrete  knowledge  systems  within  the  pedagogical \nframework of the curriculum, including the course’s techniques, approach and nature of the \nway students are taught and learn. In conclusion we posit the following questions for discussion: \nWhat is the current status of  pedagogical approaches to digital landscape architecture \ntechniques, tools and approaches? What are the former “streams of consciousness”? We \nargue that streams of consciousness are porous lineages and trajectories historically influenced by broader contextual innovations and pursuits. \n\nWhat are the recent critical developments in digital landscape architecture and related \napproaches? What are the current “streams of consciousness and potential challenges in \nrelation to emerging fields like Artificial Intelligence and Machine Learning”? \n\nWhat are the gaps in the technological-based technique developments in digital landcape architecture utilized to address the climate change related issues and their translation in advancing pedagogical approaches? \n

Enhancing Technical Grading Education: Finding the Right Tools for the Job \n\nIntroduction \nStated simply, grading design involves the alteration of the surface of a site to direct water \nflow. The reality of technical grading design is much more complex and involves the consideration of above- and below-ground, three-dimensional spatial relationships between people, \nvehicles, buildings, walls, pavements, utilities, plantings, and more. Considerable time and \nexpertise are required to develop the complex cognition necessary to produce complete and \ncorrect technical grading designs. Teaching technical grading skills to diverse groups of novice landscape architecture students is a difficult task for this reason – expertise and time are \nboth in short supply within four- or five-year undergraduate, and especially so within two-or three- year graduate academic programs.  \n\nIt  is  well-documented  that  learning  can  be  enhanced  by  using  both  static  and  dynamic \ngraphics (i. e., visualization tools) in instruction, see SCHNOTZ 2002 for a review. Learning \nenhancement can occur with the use of visualization tools both in external instruction and \ninternal learning processes. Teaching and especially learning of design skills heavily depends \non the use of visualization tools. In external instruction, design concepts (including technical \ngrading) are introduced and discussed, then modelled and practiced within a lecture\/studio \nenvironment using problems with varying degrees of application to “authentic” or real-world \nsites and problems. Students are expected to expand their learning of those concepts internally, by exploring design options and relationships with various graphic tools, such as drawing, modelling, rendering and\/or animation of views which they employ to visualize and understand the spatial relationships and tactile qualities of their design proposals.  \n\nGrading instruction necessarily relies on the use of two-dimensional visualization tools to \nboth explore design relationships and document grading changes. Sections and plans are two \ncommon visualization tools relied upon in grading instruction to foster design and documentation of grading plan proposals. Design grading, as a more conceptual, early-process activity, lends itself to design study via three-dimensional modelling. These models may be successfully used to rapidly understand initial conceptual or roughly detailed grading relationships and surface morphology. Technical grading cannot be easily or quickly explored with precision via complex three-dimensional modelling as the grading must first be completed before it can be modelled. This study hypothesizes that despite the use of complex external \nvisualization tools being less appropriate for use in technical grading design and communi-\ncation tasks, complex internal visualization operations must be utilized by learners to under-\nstand and manipulate the complex relationships among site design components in an efficient \nand confident manner. How, then, does an instructor best facilitate students’ internal visual-\nization skills without relying on the computer to visualize for them? Additionally, how does \nthe student avoid spending time developing complex digital models at the expense of devel-\noping the complex cognition required for technical grading competence? \n\nCognitive Load Theory \nThis study was initiated and informed by a literature review of Cognitive Load Theory (CLT) \nand through analysis of instructor responses to perceived student needs and direct student \nquestions during a semester-long design studio course. CLT was used as a lens through which \nto examine potential barriers to student development of the complex cognition required for \nindependent technical grading competence in the studio environment, and to inform instruc-\ntional changes to help promote higher degrees of learning. CLT assumes that two major goals \nof instruction are to facilitate the construction of internal schemas (models) and to automate \ntheir use to mitigate the significant impacts the limitations of human cognitive architecture \nhave on our ability to cognitively process complex learning (KALYUGA et al. 2003). In this \nauthor’s  opinion,  this  is  the  primary  goal  of  instruction  in  technical  grading  realms  –  the \ndevelopment of internal models, as opposed to external models (frequently manifesting as \nvisualizations and\/or displays), by which to process the complexity inherent in technical site \ndesign thinking quickly and efficiently. The limitations of human cognitive architecture may \nbe described in terms of three types of cognitive loads (for a more complete description, refer \nto RENKL & ATKINSON 2003):  \n\nIntrinsic Load refers to the complexity of the learning material itself. Technical grading \ninstruction may carry a high intrinsic load due to the complexity inherent in the interactivity  between  many  different  site  design  relationships.  Intrinsic  load  is  related  to  a \nlearner’s prior knowledge and should be expected to be at its highest levels with novice \nlearners. Intrinsic load may manifest as an information and\/or decision-making overload \n(too many requirements or too many relationships to attend to simultaneously). This load \ncan  be  decreased  with  experience  as  learners  develop  more  meaningful  information \nchunks which can be stored in long-term as opposed to working memory. \n“Germane Load refers to demands placed on  working  memory capacity that are imposed  by  mental  activities  that  contribute  directly  to  learning”  (RENKL  &  ATKINSON \n2003). This is the load learners should focus their cognitive resources on to facilitate \nlearning most successfully. \n“Extraneous Load is caused by mental activities during learning that do not contribute \ndirectly to learning” (RENKL & ATKINSON 2003). Due to the high intrinsic load inherent \nin technical grading tasks, it becomes very important for instruction to be designed spe-\ncifically to reduce extraneous loads. Considerable extraneous load is related to low levels \nof expertise. Low expertise can contribute to a simple lack of understanding of how to use available information and tools, and\/or inefficient use of the available information \nand tools. \n\nTo limit the impact of intrinsic and extraneous loads, an understanding of the technical grading expertise held by learners is critical to determine what information is relevant and how \nto present it to maximize the learner’s ability to attend to it. Novice learners generally learn \nbetter when given higher degrees of instructional guidance as they still need to develop their \navailable  schemas.  However,  more  knowledgeable  learners  (those  with  more  and\/or  more \ndetailed schemas) may require a different instructional approach that limits redundant information, otherwise they may experience cognitive overload and poor learning, despite their \nhigher level of expertise. This difference is termed the expertise reversal effect (KALYUGA et \nal 2003). It is theorized that this expertise reversal effect plays a role in the cognitive processes used by students to process technical design instruction activities and in the visualization tools and processes they use to supplement their learning. Therefore, it is important to develop instruction that recognizes and responds to the variable levels of expertise among \nthe students in a course, both related to the processes and visualization tools utilized to complete technical grading design. This study was undertaken to begin to understand the range \nof expertise variability and to theorize diagnostic tools which can be used in targeting instruction activities maximizing independence and development of expertise in the technical \ngrading design realm. \n\nInstructor Response Analysis \nThe experience of teaching this course over the past three years has been that the most educational impact (i. e. attention to germane load) comes from direct and personalized individual instructor interaction with students during their problem-solving process instead of group classroom interactions. Currently, the instructor must invest considerable time into individual \ninstruction to achieve this impact, so an analysis of instructor responses during these individual interactions was undertaken to balance effort and maximize learning. The analysis seeks \nto identify patterns among the actions or visualization tools recommended, the frequency of \nrecommendations and how those recommendations were accepted and implemented by the \nstudents. Additionally, the analysis sought to determine if there was any discernible impact \non the levels of independent thinking and use of visualization tools to enhance internal visualization processes. \n\nThe analysis focused on the following interactions due to their potential capacity to directly \nreduce intrinsic and extraneous loads. Intrinsic loads can be reduced by personalized discussion regarding  how to  use the information available, and  how to produce any lacking  but necessary information. Extraneous loads can be reduced by introducing and directly modelling the use of simple, abstract visualization tools to think and produce more complex internal \nvisualizations supporting technical grading design efforts. \n\nResponses were analyzed from interactions over three semesters of a studio course focused \non  the  technical  grading  design  of  a  complex  real-world  development  site.  The  fall  2020 studio (enrollment=18) considered a nearly 5-acre office development, fall 2021 studio (enrollment=23) focused on a 7-acre multi-family development and the fall 2022 studio (enrollment=19) designed a 5-acre office development. The course consists of a studio component with  460  minutes  (7.7  hours)  of  weekly  contact  time  (which  includes  lecture  time)  and  a separate  110-minute  (1.8  hours)  per  week  CAD  lab  component.  All  students  in  the  target course were novices with a negligible degree of variation among their prior grading expertise. All students were introduced to grading activities in an earlier course with a focused grading component where they were presented the grading process, techniques for visualizing landform and interpolating elevations, and developed grading skills via a grading design project. \n\nVariability of Student Expertise \nResults of the study identified potential barriers to learning situated within four pathways: \nLived Experience Variability: This pathway is defined as individual differences in recall\/codification (chunking) of actual human experiences, such as walking across surfaces,transitioning  grade-change  devices, noticing materials\/textures\/connections\/joints, etc. and linking or chunking those experiences together with technical grading skills in meaningful ways. \nCausal Chain Recognition: The skill to recognize critical relationships among existing \nand proposed component parts in the context of a technical grading design. \nInternal Animation: The ability to internally animate objects to transform them rotationally and\/or positionally  within the  site, or to animate and visualize  water  flowing across\/through elements of a site. \nDigital  Expertise  Variability:  This  pathway  defines  individual  differences  in  both \nknowledge of digital visualization tools (what they are and what they do) and how to \nmake them work to solve particular problems. This pathway refers both to simple inexperience\/lack of knowledge, and self-inflicted or self-limiting inexperience (such as refusal to spend the time needed to fully understand a software program). \n\nLearning activities in the first three of these pathways require the use of relatively simple external visualizations (such as diagrams, plans and sections) to support considerably more complex internal visualization and transformation operations such as flows and inferred motion – both of which represent aspects of mental animation (HEGARTY 1992).  \n\nCausal Chain Recognition supports the identification and documentation of critical relationships between site plan elements, and the visualization of responses to transformations \nof plan elements. CCR is the skill one would use to understand that as one corner of a flat \nrectangular pavement surface is depressed (lowered in elevation), the rest of the pavement \nsurface will tilt in that direction unless the surface is broken, creased, or otherwise deformed to accommodate multiple slopes. Thus, complex internal animation is required to mentally transform site objects and\/or surfaces with elevation differences efficiently without relying on an external visualizations to understand those transformations.  \n\nInternal  Animation  is  a  skill  utilized  when  considering  how  water  moves  across  and\/or through the system. Assuming water droplets remain intact from the moment they strike the surface until they leave the site at the outfall, technical graders should be able to trace a drop of water from the point it contacts the surface all the way to the site drainage outlet using internal animation. This skill requires the water to be mentally animated as it travels across surfaces and through conveyances. \n\nIt is hypothesized that Causal Chain Recognition, Internal Animation and, to an extent, Digital  Expertise  Variability  can  be  directly  influenced  via  instruction  emphasizing  germane loads, though this paper focuses only on addressing improvements to Causal Chain Recognition and Internal Animation. The study was conducted under the assumption that the creation  of  complex  external  visualizations,  such  as  detailed  3D  models,  would  contribute  to \nhigher  extraneous  loading  in  the  context  of  the  technical  grading  course,  so  instructor  responses were constrained to primarily 2D graphics, including static 3D views, but not models. Highly detailed 3D models of proposed grading solutions were not required or recommended by the instructor as a part of this course. However, TIN surfaces created from existing contours were required to be created using Civil 3D, and the use of the “Quick Profile” tool recommended for understanding existing topography and quickly testing proposed solutions and relationships. Additional solutions have been considered to address Lived Experience Variability, but those have yet to be implemented and tested in the course and will be addressed in a future paper. \n\nInstructional Methodologies \nFour  novel  technical  grading  instructional  methodologies  have  been  theorized  to  address learning improvements for each of the pathways mentioned in the previous section. Instructional methodologies were developed to both function as diagnostic tools to identify needed areas of focused instruction, and to facilitate the packaging or “chunking” of information to minimize  negative  cognitive  loads  and  enhance  development  of  technical  grading  design skills in novice learners.  \n\nSpot Skipping: a method of intentionally widespread, but very limited calculation of spot \nelevations early in the grading process which directly supports the recognition and calculation of critical grading relationships as a part of the Causal Chain Recognition pathway. \n\nFlow Branch Analysis: a method targeting spot elevations defining individual branches of \nthe site flow pattern to analyze flows and inform early technical grading design. This method of analysis is primarily concerned with flow lines and may be used independently or concurrently with Spot Skipping and primarily supports Internal Animation as water flows are visualized and defined across a site.  \n\nFlow Barrier Analysis: a method of analyzing site plan objects in terms of their impact on \nwater and\/or people flows. This method of analysis allows for the chunking of the site into \nflow barrier types and works to define and describe water flow patterns supporting Internal \nAnimation.  \n\nTransect Grading: a method of spot grading along discreet transects, usually drawn perpen-\ndicular to water, pedestrian and\/or vehicular flow paths, rather than at locations where spot \nelevations would be commonly calculated and included on a technical grading plan. Transect \nGrading  is  another  method  of  chunking  the  critical  relationships  between  elements  of  the grading plan into easy-to-understand sections, primarily supporting Causal Chain Recognition. Transect Grading may also be used in conjunction with Spot Skipping and Flow Branch Analysis. \n\nDiscussion and Conclusions \nEvidence from preliminary use of the four instructional methodologies described above in \nthe fall 2022 course seems to support the hypothesis that certain visualization tools may impose high extraneous loads on students. Their level of expertise in both interpreting critical grading design relationships and in the construction of suitably precise models is low enough that they don't  yet have the detailed schemas needed to develop efficient, low-extraneous-load processes. 3D model construction was deemphasized in the course and student outcomes seemed  to  improve.  Whether  the  improvement  was  related  to  the  lack  of  effort  spent  on model-building or simply more time developing grading skills has not yet been studied. However, CLT would support the notion that regardless of the reason, germane loads were prioritized and learning improved. \n\nResults suggest that, while digital drafting tools and Civil 3D can assist in drafting precision and in the process of working through the four methods, no complex visualization tools are required to achieve a high degree of expertise in technical grading (see Table 2). Even the 3D views may be sufficient if drawn inaccurately by hand or quickly and roughly modelled without any elevational precision in a program such as SketchUp (see Figure 3). Documentation and external communication of the grading solution may be best completed with sophisticated visualization tools, however this communication is secondary to the grading itself. The development of the grading design, to a high degree of detail, should be easily achieved using simple drafting tools and hand graphics if care is taken to do so with the required precision. This hypothesis must still be tested to confirm whether the use of complex external visualization tools  would be helpful in developing internal animation skills among novice technical graders.  \n\nThe production of a construction document quality grading plan has been a requirement for \neach iteration of this course and, given the complexity of the Civil 3D platform used to document those solutions, it is possible that some of the negative observations within the study may stem from extraneous loads imposed by the required documentation rather than issues regarding grading skills. The opinion of this author is that construction documentation should be an integral part of any technical grading plan. The primary purpose of the technical grading plan is to facilitate site construction and, learning to communicate design intent to the appropriate audience with the appropriate visualization tools should be the goal of any design education. Perhaps there should be a different focus on the documentation aspect of the grading plan, either concurrently or in a different semester. More work needs to be done to determine where any differences might exist between grading design skill and grading documentation skill. \n\nIt is important to note that the methodologies examined in this paper were applied to fine \ngrading of a site surface. Detailed considerations of mass grading and site stormwater management, such as balancing cut and fill and sizing stormwater management facilities were not included  as  a  part  of  the  target  course.  Accordingly,  additional  research  must  be  done  to examine the relationships between successful fine (surface) and mass grading activities while utilizing the methodologies described in this paper. \n\nThis study raises the question of which approach is the most appropriate for the most efficient transfer of knowledge and development of technical grading skill, the project-level approach, focusing  on  direct,  real-world  application  (as  presented  in  this  paper),  or  the  vignette  approach, focusing on individual skill development and repetition. The course within this study primarily relies upon the former, project-level approach, but does incorporate aspects of the vignette approach within the workshop and demonstration interventions, and the opinion of this author is that a combination is ideal. More work is required to answer the questions of what that combination should look like and how much time and effort should be spent by instructors and students within each. The four methodologies developed through this study should be developed into an online rapid diagnostic tool to identify the levels of technical grading expertise in a student population over time, and to match more detailed instructional methodologies to those students to help them overcome challenges to cognition and development of the expected technical grading competence. This study also suggests that additional  exploration  is  required  to  more  fully  understand  the  relationship  between  cognitive \nloading and the use of digital design skills and visualization tools versus analog design skills and visualization tools in an educational environment, especially in the realms of technically complex design tasks. \n

Future Resilient Landscape [Architects] \n\nAbstract: Parametric and computational design processes will evolve and inform the field of landscape \narchitecture. This paper investigates a bottom-up teaching approach about parametric design to novice \nlandscape architecture students as a viable method in their design pursuits. Using a case study, students \nexplored a translation of an intuitive approach to design into a parametric script, taking them through \nconcept ideation, fabrication, and ultimately informing implementation. \n\nIntroduction \nResilient landscape architects will be those who can anticipate, analyze, and address complex \nlandscapes, including those challenges yet to emerge. All professional fields are developing \ncutting-edge technologies to facilitate the analysis of complex issues and the implementation \nof viable solutions. The emergence of new technologies in landscape architecture has been a \nsignificant factor in the development of this discipline and has facilitated relevant research \nand design processes. Landscape architecture, now maturing with its own digital design practice  including  computational  design  (popularly  described  as  parametric  design)  is  gaining \nmomentum. The use of digital tools and techniques in the field of landscape architecture will \ncontinue to grow and evolve in the coming years (WALLIS & RAHMAN 2016).  \n\nFascinating  examples  of  new  computational  approaches  and  applications  are  emerging  in \nlandscape architectural projects. However, Bradley Cantrell and Adam Mekies believe that \nthe mechanism through which these applications are implemented remains obscure. This is a \nmissed opportunity since the logic, the thought process and the utilization of parametric design, could have been more evident to launch the complex execution (CANTRELL & MEKIES 2018). \n\nSince 1967, the MIT Media Lab has successfully “civilized” or “tamed” design and computer \ncode through years of effort. In 2003, the team designed the “Scratch” programing language \nso which began to employ a graphic interface rather than the laborious coding string (NAGLE \n2014). \n\nMitch Resnick, a computer scientist at the MIT Media Lab, conducts the “Lifelong Kindergarten”, where children learn to code and create from a very young age (RESNICK 2014). As \nResnick indicates, “When you learn to read (code), you can then read (code) to learn.” \n\nCoding identified as the core to parametric design describes parametric design thinking as a \nmethod, and not a tool. Do design school curricula or instructors provide effective strategies \nto  increase  the  broader  adaption  of  recent  technologies,  specifically  parametric  design, to \nfuture students?  \n\nIn recent years, the potential of computational media and its syntactical interface has been \nwidely explored by young designers through the GUI (Graphical User Interface) syntax of \nscripting. “How can we leverage this newly acquired foothold and understand better what we \nare gaining from parametric modeling\/visual programming\/coding as a design process and \nconceptual generator?” (CANTRELL & MEKIES 2018). \n\nIn this study, the authors investigated a kinaesthetic learning approach to cultivate a bottom-up understanding of the computational design process and engage students with advanced \ndigital tools. The goal was to encourage novice students to learn implicit knowledge of the \ncomputational design process first, and then learn explicit knowledge, in the following semesters. The emphasis was to employ parametric design tools in the design process rather \nthan limiting, or devaluing, their use to mere digital representation efforts. \n\nThe research team supervised a group of six (6) second-year Bachelor of Landscape Architecture students, interested in a public art competition, to utilize computational design tools \nin concept and design development of a public art piece, and subsequently, its off-site digital \nfabrication and production, and on-site implementation. Prior to this project, five of the six \nstudents had not utilized commercial 3D computer graphics and computer-aided design application software, such as the Rhinoceros 3D, as used for this project. The use of computational design tools  facilitated, and elevated, conventional design process activities into an ambitious design and implementation proposal.  \n\nAnalogue (Kinesthesia) to Digital (Parametric)  \nThe group of six (6) students enrolled in an independent course (design studio), co-taught by \ntwo faculty members, to prepare a design proposal for a public art design competition. Structured into three (3) phases, the studio included analogue rule sets, parametric\/digital rule sets, and fabrication. \n\nThe South Park project, by Fletcher Studio, inspired the method so that the computational tools test the resilience of analogue rules for spatial partitioning within a small park in San Francisco, CA. That project’s research was prepared for the Acadia 2014 exhibition, an annual parametric design conference (CANTRELL & MEKIES 2018). When Fletcher Studio first began work on San Francisco’s South Park, the initial design was developed “through iterative analogue diagramming” with a focus on “an intuitive understanding of the site and embedded in an analogue rule set” (FLETCHER 2021). \n\nCase Study: South Park, Fletcher Studio, 2017 \nFletcher Studio is a landscape architecture and urban design collaborative practice based in San Francisco, California. Fletcher Studio frequently uses parametric design software programs such ash such as Rhinoceros 3D, Grasshopper and Rhino script to test complex forms, \nfunctions, and site layout (Amoroso 2012). The Studio sought to reimagine San Francisco’s oldest public space (Figure 2) with a contemporary interpretation of the “picturesque style” landscape (CANTRELL & MEKIES 2018). The award-winning design transformed the site from an  English  strolling  garden  into  an  integrated  multi-purpose  communal  space  (FLETCHER 2021). \n\nAnalogue to Digital: The design intention sought to retain a hierarchy of circulation patterns, access points, social nodes, and existing trees and structures (CANTRELL & MEKIES 2018). “In the initial design phase, these decisions were made through an intuitive understanding of the parameters of the site and embedded in an analogue rule set that guided design decisions” \n(FLETCHER 2017). \n\nAnalogue rule sets require a considerable amount of testing time. “The same “idiosyncratic moments” that allow for the emergence of novel and intriguing design moves can also lead designers to overlook inconsistencies or flaws in their logic.” (FLETCHER 2017). By using a parametric  modelling  tool  in  the  Rhino  3D  software  program,  the  system  of  organization \ndeveloped in analogue (on paper), was translated into a Grasshopper digital script. The system  evaluated  “the  design  resiliency”  of  the  diagrammed  “tectonic  and  spatial  systems”(FLETCHER 2021). This enabled the designers to re-evaluate any flaws in their logic while also rapidly iterating upon the design in detail, without violating the previously established constraints of their design concept. \n\nTeaching Design Studio \nThe authors included kinaesthetic learning approaches in the phase of developing analogue rules associated with this studio. Kinaesthetic learning is a learning style in which individuals effectively “learn through doing”. Landscape architecture curricula historically include kinaesthetic learning approaches. Students increase understanding and testing of the products and  outcomes  of  design  exploration  by  touching  and  manipulating  them;  hence,  practical information is usually preferred over theoretical concepts. A kinesthetic learning experience can  aid  the  teaching  of  parametric  design;  one  can  read  about  it,  listen  to  instructions,  or watch videos of how to design parametrically – but deep learning occurs when one is physically involved with it. For their course, the instructors employed learning approaches including hand-sketching and model making to engage in an intuitive approach to design. These were “hands on” ways of exploring, developing and testing design concepts, aligning with the theme for a public art competition. \n\nCompetition Overview: The Winter Stations design competition is an open, single-stage, international design competition held annually in Toronto, Ontario. Guided by a provided theme, participants submit design proposals of temporary winter art installations incorporating the existing lifeguard towers situated along Toronto’s Woodbine Beach, on Lake Ontario. \nThe OneCanada project, informed under the competition’s provided theme of “Resiliency”, and designed and installed by six studio-course students, represents one of several submissions from artists and designers, worldwide, and was the only representation from landscape architecture, let alone an undergraduate student cohort. \n\nAnalogue to Digital  \nThe following phases characterize the study undertaken: \n\nPHASE 1: Developing Analogue Rule Set [Concept] \nStudents  were  asked  to  develop  a  concept  based  on  the  competition  theme  of  Resiliency. Their concept sought to interpret, appreciate, and promote the inspirational example of resilience of the Indigenous peoples of Canada, who continue to withstand adversity and persevere through generations of oppressive colonial policies. The concept also sought to bridge a gap between Indigenous and non-Indigenous peoples through an opportunity of “gathering” among the layering of the seven grandfather teachings (wisdom, love, respect, bravery, honesty, humility, and truth). The students envisioned the teachings to represent seven  white, \nand stacked circular forms, with a situational siting around a Woodbine Beach lifeguard station, representing the collective responsibility in the “guarding of life.” As an obvious beacon along the waterfront, art patrons, guests, and peoples from all backgrounds, could gather at \nthe  installation.  The  seven  teachings,  originating  with  the  Anishinaabeg,  and  have  been passed down from generation to generation ensuring the survival for all Indigenous peoples. \n\nPHASE 1: Developing Analogue Rule Set [Hand Sketching and Model Making]  \n\nBased on the initial concept, students generated ideas and imagined the form of the installation. Due to the lack of experience with 3D modeling software programs, students explored multiple design iterations through hand sketching and physical model making. As a result, the team developed analogue rule sets or design principles that guided design decisions: \n\n1.  Using circle as the prime form of installation. Circle is a sacred symbol of the interdependence of all forms of life in Indigenous culture (Stevenson 1999)  \n\n2.  Represent the seven grandfather teachings in minimum seven independent layers: wisdom, love, respect, bravery, honesty, humility, and truth. \n\n3.  Demonstrate unity in a sequence to symbolize bridging the gap between indigenous and non-indigenous people \n\n4.  Using a pattern to attach the separate layer which represents strengthening of relationships, and the protection of culture through the gathering and unity between people \n\nThese analogue rule sets, developed on paper and through model  making,  were translated into a parametric script using the Grasshopper plugin for the Rhino 3D software program.  \n\nPHASE 2: Developing Digital Ruleset [Parametric Script] \n\nWithout guiding the students through the complexity of learning algorithms or the coding behind the scripts, three algorithms or scripts developed in Grasshopper and were provided in a ready-to-use format to the students. The four (4) rule sets translated to ‘input parameters’ \nfollowed by multiple components in the Grasshopper plugin to rationalise the design process and to operationalise the principles. Using a ‘parametric lens’, the students could experiment, test, and generate design iterations and several design alternatives which allowed rule-based \nthree-dimensional platform to inform the decision making.  \n\nThe  final  iteration and  parametric  script,  for  the  competition  submission,  were determined from the various alternatives generated. \n\nPHASE 3: Digital Fabrication [Construction]  \nWith the rising presence of digital modeling in the field of landscape architecture, and accessibility to requisite equipment, digital fabrication has become a major facilitator in the development of research and design, in both professional practice and academia. As described by \nAndrew Madl “Professional design firms and universities providing use of digital fabrication in-house is becoming increasingly common. How to exploit such equipment is now taught in academic settings as skillset that is in line with traditional model making.” (MADL 2022). \n\nTeaching digital fabrication techniques requires significant amounts of time and resources. The intention of this phase was to develop a general introduction and awareness by providing a glimpse into the advantages of parametric design tools. \n\nFollowing the previous phases, students were required to prepare construction documentation or  “shop  drawings”  suitable  for  a  professional  fabricator.  Utilizing  computational  design tools developed in the previous phases, and through ongoing consultation with CNC fabrication  professionals,  students  learned  to  prepare  the  fabrication  files  and  facilitate  the  CNC cutting process. The goal was to encourage students to experiment with digital \nmodeling and file preparation, suitable to fabrication. \n\nFinally, the project’s implementation occurred through a team effort, ranging from detailed off-site work including material determination, metal welding, support strut wrapping, CNC-cut wood panel painting, transport, etc., to on-site assembly and construction. \n\nDiscussion \nIn the discourse of architectural fields, the term parametric design is associated with a particular attitude, aesthetic, and theory. Typically, one envisions the outcome as extraordinary and \nprovocative designs that inspire a set of  morphological principles (MADL 2022). The first perception of parametric design is limited to contorted formal expressions and the over-sophistication of geometry, which need to be deciphered. While this study emphasizes teaching \nthe  process  of  generating  complex  formal  expressions  for  a  public  art  installation,  the  research team addressed the potential of the method for future discoveries more specific to the field of landscape architecture. \n\nIn this course, some students gained the full understanding of the potential parametric design thinking offers at the end while a few had difficulties in developing a logic string of design steps that relate to the parametric approach, they preferred or felt back to intuitive or conventional  designing.  However,  the  later  group  was  interested  to  work  within  the  parametric framework if there is a team member managing the scripting part. This might inform an indication of the future of design so that the analogue embraces digital rather than introducing an absolute departure from analogue to digital. While parametric design offered a palette of \npossibilities, students got exposed to the realities of budget constraints and current limitations of digital fabrication, which eventually reduced the range of possibilities. \n\nRegardless of understanding the details behind the script, the “end product” and the process was well received by the students involved and has encouraged other students, privy to the course, to pursue “script” moving forward.  \n\nConclusion and Outlook \nImagined to provide interested students with an implicit understanding of the parametric process and to motivate them to create scripts unique to a project in future, this course enabled students to look outside the box, and even produce their own tool sets. Caroline Westort of Iowa State University explains that future landscape architects will not be only tool users but \nrather toolmakers. She indicates: “I actually think we do lose something by not training or teaching students the basic building blocks of what’s behind the black box, what’s behind the software . . . we are an information technology discipline, whether we like it or not.” (Bentley 2016). This indicates the need of training future resilient landscape architects, adept at creating script. \n\nParametric design can be difficult  for students  who  may  not have a strong background  in computer science or programming. It can also be time-consuming and challenging to learn and use these tools effectively, especially for those who are already comfortable with tradi-\ntional design approaches and intuition. Many designers will not engage at the high level of syntactical  knowledge  necessary  for  scripting  given  time  constraints  as  one  of  significant barriers. However, Grasshopper, Rhino, other GUI-based scripting allows designers to more readily connect the outcome of code with the formal representation without having to know how to write code (CANTRELL & MEKIES 2018). \n\nContemporary landscape architecture theory and practice necessitate the processing and design of data connected with complex systems in order to accurately reflect composite and emergent scenarios (MADL 2022). The field of landscape architecture, along with other design disciplines, are undoubtedly evolving through computational discovery.  \n\nLandscape architects and landscape architecture itself can respond to ever-evolving nature of practice and their resulting consequences. The outcomes of this design studio proved that parametric design permits a level of ambiguity, inquiry, discovery, confidence, and execution expected in creative and learning environments. \n\nBy training  future resilient landscape architects  with computational tools, universities and educational institutions can make a significant contribution in keeping pace with evolving principles. It is expected that these skilled professional practitioners and researchers will be \nintroduced to the community, adequately versed, and improve the model of practice-based research, which ultimately improves conventional and speculative design workflows. \n

Geodesign as Online Teaching Method – Lessons from a Multiple Case Study \n\nAbstract: This study analyses the geodesign workshop as a method for the online teaching of group \nwork methods in the context of geoinformation systems (GIS) in planning and design. In order to assess the learning outcome, four workshops with international landscape architecture students at master level were conducted over a period of four years (2018-2021) and compared in a qualitative multiple-case study. In times of Covid-19 and the need for remote workshop methods, the geodesign workshops seem well suited for online learning and teaching. The results show that the learning goals were achieved, that new ideas were created and stakeholder expectations reflected and challenged. In individual cases, the lack of on-site knowledge led to mistakes though, and online group work had different group dynamics  than  in-person  negotiations.  Vocal  and  well-organised  students  seem  to  engage  even  more whereas quiet students more easily disengage, as seen in a bimodal distribution of participation grades in the online class. In conclusion, geodesign workshops may be recommended as an online method for teaching GIS and group work methods such as brainstorming, consensus building and stakeholder-role play but a hybrid format or new virtual field trip techniques are preferable when familiarizing students with the case study site. The teaching of group work methods as part of planning and design may be transferred from geodesign to teaching building information models, which is also an information-based digitally facilitated collaboration process. \n\nIntroduction \nGeodesign has been included in many university curricula around the world. The International Geodesign Collaboration (IGC) introduced a standardized geodesign process, which \nhas been conducted by hundreds of universities around the world. WARREN-KRETZSCHMAR \net al. (2016) already demonstrated the benefits of geodesign as a teaching method in planning \nand design classes. Building on their insights, this paper further explores whether geodesign \nis also a suitable method for the teaching of group work methods, and how geodesign classes \nadapted to online teaching during the Covid-19 pandemic.  \n\nIn  short,  STEINITZ  (2012)  defines  geodesign  as  planning  geography  through  design.  In  a \nlonger  definition,  FLAXMAN  (2010)  defines  geodesign  as  “a  design  and  planning  method \nwhich tightly couples the creation of a design proposal with impact simulations informed by \ngeographic context and systems thinking normally supported by digital technology.” Among \nother methods, geodesign utilizes the scenario  method (BISHOP et al. 2007), which is also \npart of many university programs. \n\nHence, a common misconception is that geodesign is only about technology. Although ge-\nodesign is characterised by the integrated use of GIS tools and geodata as the basis for an \ninformed  design  and  decision-making  process  (CAMPAGNA  2014),  it  is  generally  a  group \nwork process. In this context, several group work methods correspond well with the geodesign process. These are brainstorming, stakeholder role-play, and collaborative negotiation \nmethods.  \n\nBrainstorming is a method for the quick generation of ideas (JONES 1992). In the first step, \nparticipants have to write down as many ideas as possible during a limited amount of time. \nSince this step is about the creation of ideas, no weighting, discussion or filtering takes place \nyet. In a second step, the ideas are discussed in the group, clustered thematically and redundant or unsuitable ideas are sorted out. DOMINGO et al. (2021) demonstrate how brainstorming can also be applied in remote settings to facilitate collaborative work.  \n\nAt the same time, geodesign addresses complex multi-stakeholder planning and negotiation \nprocesses. PETTIT et al. (2019) suggest collaborative negotiations and consensus-building as \npart of the geodesign process. Starting with an even number of stakeholder groups, e. g., eight \ngroups with one planning proposal each, these groups meet with the closest other group, e. g., \ngovernment and business, and negotiate a consensus between their two proposals. Then, the \nremaining four proposals are narrowed down to two and the two to a final one. Because the \nprocess is mediated through digital means, PETTIT et al. (2020) also call it digital negotiations. \nThey conclude that such digital negotiations are an effective planning method. \n\nSuch processes embody underlying roles and often hidden agendas and conflicts. LIGTENBERG et al. (2010) used a role-playing approach in which students took on the roles of local \ncitizens, farmers and nature conservationists together with an agent-based model for simulating a multi-actor spatial planning process. In the IGC process, the role-playing approach \nlends  itself  to  have  students  represent  different  stakeholder  groups.  Common  stakeholder \ngroups are local citizens, local businesses, local government, youth organisations or environmental NGOs. Research goals are to assess whether:  \nLearning goals were achieved; \nThe quality of the results changes between online and in-person geodesign workshops; \nGeodesign workshops as learning and teaching method for group work are transferable to other programs at Master level. \n\nMethods: Multiple Case Study Comparison  \nThe research design is based on the multiple case study method (see 2.2.) by YIN (2014). The \ncontext for the workshops is kept consistent and comparable by following the recommendations and templates of the International Geodesign Collaboration IGC (see 2.2.): scale, group \nsize, underlying global assumptions, time-frame, and range of scenarios do not change across \nworkshops. The workshops are informed by open data from the EU Copernicus programme, \nOpenStreetMap  and  local  environmental  agencies  (2.3.)  All  workshops  use  geodesignhub \n(www.geodesignhub.com) as online platform to facilitate the process (2.4.). In the comparison, quantitative data such as average  grades for participation and outcome are compared \ntogether with qualitative observations, i. e., data triangulation in the words of YIN (2014). \n\nInternational Geodesign Collaboration IGC Template  \nORLAND & STEINITZ (2019) describe the International Geodesign Collaboration IGC, a col-\nlaborative  project of  more  than  120  universities,  research  institutions  and  public  \/  private stakeholders across the world. In order to facilitate research into geodesign, the collaboration organizes annual workshops and provides a template to make the diverse geodesign projects comparable.  The  IGC  template  (https:\/\/www.igc-geodesign.org\/presentation-formats)  provides the following:  \nCommon geodesign systems (water, green infrastructure, energy, transport, agriculture, \nindustry and commerce, institutional, residential and two flexible systems) and a common colour palette to easier identify and compare land use patterns and alternative design scenarios.  \nGlobal assumptions and a library of geodesign innovations, such as new renewable energy solutions, transport innovations etc., which IGC participants are encouraged to apply in their individual projects.  \nCommon scenarios and timeframes at 2035 and 2050, and paths to achieve scenarios for \nthose: “Early Adopters” initiate design interventions in 2020; “Late Adopters” in 2035; \nand “Non-Adopters” continue with business-as-usual.  \nTemplates for common reporting formats as presentations and posters. \n\nThe geodesign projects compared here dropped the 5km and added a spatial extent at 40km \nbut adhered to the IGC systems, innovations, common timeframes and poster templates.  \n\nMultiple Case Study Design  \nThe basic concept of  this  multiple case-study is  to conduct the  workshops as similarly  as \npossible by referring to the IGC standard templates for participating projects. The four workshops (see Tab. 1) were embedded in a GIS module in the second year of an international \nMaster´s degree in landscape architecture. Student backgrounds were very diverse, with students from different Bachelor´s degrees and more than 20 different nationalities. Working \nlanguage  was English. Each  workshop had one day of preparation plus individual student \nhomework and three days of the actual workshop. Results were documented on two A2 posters per workshop. \n\nGeodata-Based Process \nFor each workshop, suitability analyses were run ahead of the workshop in ArcGIS Pro and \nsummarized  in  so-called  evaluation  maps.  The  suitability  analyses  were  mainly  based  on \nopen geodata from the Urban Atlas, which are derived from Copernicus satellite data (European Union, Copernicus Land Monitoring Service, European Environment Agency (EEA)),map data from OpenStreetMap and protected areas provided by the Bayerisches Landesamt \nfür Umwelt LfU and the Geoportal Baden-Württemberg.  \n\nOnline Platform \nAll workshops were conducted through the online platform geodesignhub, which uses maps \nand  diagrams  to  facilitate  the  negotiation  process.  FLINT & STEINLAUF-MILLO  (2021)  describe geodesignhub as “an interactive design method that uses stakeholder input, real-time \nfeedback, geospatial modelling and impact simulations to facilitate the development of an \neffective management strategy and smart decisions.” By presenting two maps with individual \ndiagrams of projects and policies, and adding functions for filtering and visual comparison \n(Fig. 2), geodesignhub provides the tools to reach an informed consensus. \n\nCase Descriptions \nAll four workshops correspond with local planning topics, i. e., Munich Parkmiles is elaborating the open space concept of the City of Munich; Regional Garden Festival Stuttgart is \ncontributing  to  the  International  Building  Exhibition  Stuttgart,  Heidelberg  Green  Belt  responded to the invitation by the City of Heidelberg to develop ideas for a green belt and the \nlast project is contributing to the forthcoming IBA Munich. The four geodesign workshops, \npresented here, share the same learning goals:  \nAddressing a planning question at city to regional scale  \nApplication of GIS skills and demonstration of geodata capacity  \nDeveloping group work skills  \n\nCase Study 2018\/19: Munich Parkmiles \nIn a competition of ideas, 30 international students drafted the 2035 and 2050 scenarios in \nparallel working teams. Nevertheless, the results are surprisingly consistent. The common \nidea is that green infrastructure innovations are concentrated in the „Park Mile” green corridors. Housing is mainly accommodated in mixed-used zoning. For example, the 2050 early \nadopters’ scenario is presented in Figure 1, which extends the high-density mixed-use areas \nalong the  major public transport lines towards the city´s edge. In this case, the colours  in \ngeodesignhub indicate different types of zoning policies. The green spaces in between, including urban forestry in the south and valuable farm land in the northwest, are put under \nprotection  protected  from  further  development.  The  large  inner-city  yellow  policy  zone \nmarks low-density laneway housing in the otherwise high-density neighborhoods.  \n\nCase Study 2019\/20: Regional Garden Festival Stuttgart  \n\nGerman garden festivals have become a powerful driver for sustainable urban development. \nThe focus of the student proposals is on a positive impact on the climate. The approach in \nthe 2035 and 2050 scenarios complement each other progressively to implement policies on \nrenewable energy combined with blue and green infrastructure. Land use is planned strategically to mitigate urban sprawl, reduce the urban heat island effect, and increase rainwater \ncollection.  Housing  is  addressed  through  high-rise  developments  by  converting  redundant \nindustrial areas into mixed land use with a focus on bringing in a large “breathing” space in \nthe form of a park that Nürtingen does not currently have (see Fig. 2). Renewable energy \nprojects introduce solar farms, solar surfaces on highways, and policies that require residential and industrial zones to contribute local solar energy.  \n\nCase Study 2020\/21: Heidelberg Green Belt \nThe City of Heidelberg and its neighbouring cities, most importantly the City of Mannheim \nnorthwest of Heidelberg, have already launched a number of landscape development projects \nfor ecological restoration. At the time of this workshop, the city council had asked the planning department to develop ideas for a multi-functional “green belt” between Heidelberg and \nMannheim. Please note that the term “green belt” has been discussed controversially in different contexts. In the context of this project, the “green belt” is supposed to integrate ecological and physical landscape characteristics with multiple land uses (protected natural areas, agriculture, infrastructure, recreation...) in a multifunctional landscape.  \n\nFigure 3 is showing the early adopters' scheme for 2050 with green and blue infrastructure \ncorridors visible west of Heidelberg, i. e. along the area adjacent to the Mannheim urban area. \nIn addition to introducing new blue infrastructure, the students suggested links to the strong \nmedical sector in Heidelberg by introducing therapeutic gardens and other forms of restorative landscapes. Interestingly, the seemingly novel idea of creating new blue infrastructure \ncorresponded with a local proposal for an artificial lake.  \n\nCase Study 2021\/22: Munich International Building Exhibition \nSimilar to regional garden shows, the regularly held Internationale Bauausstellung (IBA) is \na key driver of national building and planning culture in Germany. It has played an important \nrole in cooperation, innovation, participation, experimentation, and visualization of 10 years \nof planning and design. Since Munich was awarded the next IBA on the topic of mobility, \nstudents were encouraged to envision a regional IBA providing new sustainable approaches \nto mobility landscapes. The City of Munich IBA team supported the workshop.  \n\nThe first day mainly focused on learning about the area of Munich and analysing where pos-\nsible improvements could be made based on suggested systems such as: transport infrastruc-\nture, industry and commerce, mixed residential, tourism, blue and green infrastructure, en-\nergy infrastructure, climate, and agriculture. One key instrument was the further development \nof the “park miles”, seen in green Figure 4, which had already been addressed in the first \nworkshop by a different group of students.  \n\nCross-Case Comparison \nIn all four cases, the students achieved the learning goals. Comparing the four cases, there \nare commonalities but also differences between the in-person and the online settings:  \n\nStatistical Comparison \n\nThe students received grades for 1) participation in the workshops and 2) the quality of the \noutcome, i. e., the content of the resulting scenarios and their presentation on the posters. \nStudent numbers were supposed to be around 30, but actually varied between 23 and 36 depending on factors out of our control such as visa issues or Covid-19.  \n\nA simple descriptive analysis of the average mean grades across the four workshops is presented in Table 2. In general, grades are rather good (with 1.0 the best possible grade). The \nbest participation was recorded during the first in-person workshop in 2018\/19, whereas the \nsecond online workshop in 2021\/22 had the poorest participation. If you look closer at the \ngrades, participation in the last workshop shows a trend towards a bipolar distribution: quite \na few students participated very well in the online workshop, but in contrast, a large number \nof students participated poorly or dropped out. \n\nCross-Case Observations \nIn both the in-person and online settings, large numbers of diagrams were created, and both \nsettings led to comparable results in terms of quantity and diversity. With regard to the IGC \nframework, three scenarios were derived from the diagrams: early adopters, late adopters, \nand non-adopters. The geodesign process of narrowing down the scenarios to a smaller number of consensus scenarios also succeeded in both settings. For teaching purposes, the scenario process was combined with exercises in negotiation and students “role-played” different stakeholder groups, such as young people, government, business representatives or environmental NGOs. Some students fully embodied their roles and took on a new perspective, \nleading to interesting discussions, such as proposing affordable housing versus the provision \nof additional green space.  \n\nThe online platform geodesignhub facilitated the documentation of the process in both settings, online and in-person. Especially in a teaching environment, it is of great help for the \nteacher during assessment and grading that all ideas and the scenario building process are \narchived in geodesignhub.  \n\nDifferences between In-person and Online Settings  \nThe online setting can facilitate a broader geographical range of case study topics and locations, although it seemed to come at the costs of sometimes lacking understanding of the site. \nOne group was obviously not aware of local characteristics and depicted high-rises, which \nwere completely out of context.  \n\nIn  terms  of  organisation,  the  online  workshop  made  it  easier  for  international  students  to discuss with local stakeholders than organising such a session in person. Like an in-person setting, the online discussion inspired both groups, students and local stakeholders. \n\nHowever, the grading showed a lower grade in participation, particularly for the last work-\nshop. From observation, more vocal students tended to engage even more in the online set-\nting, whereas it was much harder than in-person to motivate quiet or disengaged students. \nNevertheless, the online setting was a suitable remote learning tool during Covid-19 times, \nand the geodesign workshop method proved to be well suited for online teaching.  \n\nConclusion and Outlook \n\nIn conclusion, the learning goals were achieved. Therefore, geodesign workshops are generally recommended for teaching group work methods such as brainstorming, consensus building, and stakeholder-roleplay in GIS-based planning and design. In times of Covid-19 and \nthe need for remote workshop methods, the geodesign workshops were also well-suited for \nonline learning and teaching although participation was slightly lower during the online sessions. These observations are consistent, though, with other classes that were taught online \nduring Covid-19 and could point to a certain online “fatigue”.  \n\nRegarding the quality of results, the online setting  might come at the cost of the students \nfamiliarizing themselves with the case study area. It is recommended to further develop hybrid  settings,  e. g.,  collaborations  with  local  experts  or  the  development  of  remote  or  VR enabled field trip techniques to facilitate a better understanding of the site (HASBROUK & \nSTEPNOSKI 2022).  \n\nFindings and group teaching methods from this multiple case study could be transferred to \nteaching Building Information Modeling BIM. Like geodesign, BIM is a collaborative process rather than a software. In a BIM class, the role-play could simulate the different stakeholders in a BIM process, from surveyor to architect and client, and the BIM model may be used to facilitate negotiations among these stakeholders. \n\nFor future geodesign research, it is suggested to focus further on the evaluation of scenarios. \nPeer review through the students themselves might contribute to the learning and teaching \nprocess. In addition, GIS-based or even artificial intelligence (AI) based methods might facilitate new learning and teaching methods by providing real-time quantitative and qualitative \nfeedback. It will have to be seen how the geodesign process is further developing and which \nrole, if any, AI will play in it.  \n

BIM Education in Landscape Architecture: The Rapperswil Model \nAbstract\nIn 2016, Switzerland decided to embrace digitization in every industry, in all sectors, and at \r\nall  levels.  Within  the  Landscape  Architecture  program  at  the  OST  University  of  Applied  Sciences, teaching and research with strong emphasis on Digital Construction had already been carried out for years. In view of the country’s vigorous drive towards digitization and being the only bachelor's pro-\r\ngram in the German-speaking part of Switzerland, Rapperswil Landscape Architecture is committed to \r\npartake and to aid in this digitization process. The paper gives an overview of Digital Construction in \r\nLandscape Architecture education in Rapperswil, status 2022.\n\nIntroduction \nIn the coming years, the construction industry worldwide will undergo digital transformation. \nBuilding Information Modeling (BIM) plays a central role with the digital twin and with a \nclearly defined process. The strategy of the Swiss Federal Council from 2016 for digital Swit-\nzerland (SCHWEIZERISCHE EIDGENOSSENSCHAFT 2016) and the establishment of the frame-\nwork “Bauen Digital Schweiz – Digital Construction  Switzerland”, the country chapter of \nbuildingSMART International, gave the Swiss construction industry a big boost in the direc-\ntion of digitization The Swiss government  even  went one step further and defined a clear \ntime frame. By 2025, Switzerland will implement the BIM process not only in architecture, \nbut in all infrastructure construction projects. The Swiss Federal railway company Schwei-\nzerische Bundesbahnen (SBB), a government-owned company, must apply it in all projects \nby then. SBB is also a big player in real estate architecture projects where greenspaces are \nalways required. Therefore, this is not only applicable to engineers, but also landscape archi-\ntects have to get ready for digital construction. As result, Rapperswil is consistently pursuing \nthe goal of implementing “Digital Construction” in Landscape Architecture education. \n\nDigital Construction \nDigital Construction is the general term for using different digital technologies to build more \nefficiently. The below methods and processes belong to Digital Construction and are taught \nat Rapperswil. \n\nBIM Construction \nRapperswil students work three-dimensionally from day one. In the first semester, the BIM \narchitecture construction software (Revit) and the principle of a digital twin are taught. The \nstudents  are  required  to  build  an  existing  structure  (pavilion,  pergola,  water  feature,  etc.). \nThis approach has the following advantages: \nFast learning of architecture representation principles (floor plans, elevations, sections, 3D views), \n“One single source of truth” – the 3D model is the basis for all (representations, schedules\/quantities, etc.),\nObject oriented construction only with 3D objects, which belong to building categories, \nVery structured modelling with parametric objects (standard families, external families and project families), The model has container function for fundamental construction data. It is used for structural engineering (formwork\/reinforcement) and for MEP (Mechanical, Electric, Plumbing) modelling. \n\nIn the 2nd semester, the students integrate a building into an existing site based on GIS data \nwith  civil  engineering  programs  (InfraWorks  \/  Civil  3D).  They  locate  driveways,  parking \nlots, retention\/infiltration basins in the project. Students get to know the 3D Global Naviga-\ntion Satellite System (GNSS) excavator control system and learn what to look out for when \npreparing data for it. In principal students learn to use the correct tools for different chal-\nlenges, as BIM construction in Landscape Architecture consists of tools for architecture pro-\njects and tools for civil engineering projects. The scheme BIM4RainWaterManament (PET-\nSCHEK 2019) gives a good overview of the Rapperswil teaching in Digital Construction. \n\nBefore the students model the terrain digitally, they learn the craft by hand for one semester. \nIn the construction course in the first semester, the students have to solve numerous small \ntasks on terrain modeling with elevation points\/contour lines and prove their skills in a 1 ½ \nhour exam at the end of the semester. The exercises are based on U.S. grading courses, which \nare common at every north American landscape architecture program. Richard Untermann, \nwith the book “Grade Easy” (UNTERMANN 1972), was an important pioneer for several text-\nbooks on the English-language book market on terrain modelling and serves as the basis for \nthe Rapperwil grading education. \n\nMore complex architectural constructions, which serve as the basis for structural calculations, \nare the subject of the “Constructive Design” module in the 4th semester. This is also where \nthe cooperation with the civil engineers of the newly formed School of Architecture, Civil \nEngineering, Landscape Architecture, Spatial Planning of the OST is practiced for the first \ntime. \n\nThe previously often time-consuming visualizations are becoming a sideshow thanks to the \nBIM construction training. Software like Enscape3D or Twinmotion enables the virtual real-\nity (VR) inspection of the model with a headset or on the screen. Individual images in differ-\nent resolutions can be created from any point. Students can check out headsets and VR capa-\nble computers from a central IT service at OST. \n\nCommon Data Environment (CDE) \nIn addition to the 3D model, the management of processes and information is central to Digital Construction. Internet-based platforms, called Common Data Environment (CDE), are \nresponsible for data exchange, collaboration on a model, costs, quantities, materials, delivery, \ntesting and acceptance processes in all life cycle phases of the structure. \n\nIn the spring semester of 2020, like the other Swiss universities, all of Rapperswil’s landscape \narchitecture courses took place online. Since the first wave of the pandemic, Teams \/ Zoom \nconferences had been part of everyday life for all students. However, Rapperswil went a step \nfurther. It was made mandatory for all students to submit their BIM construction projects via \nthe CDE Autodesk Construction Cloud (ACC). A project folder is dedicated to each course, with student subfolders. There the students store their models, photos, sketches and text. The \nlecturers evaluate the work digitally, with the 3D model being the starting point. \n\nThomas  Putscher,  lecturer  at  OST,  writes,  “I  consider  the  submission  to  the  Construction \nCloud to be a good thing. The students found their way around quickly and it went smoothly. \nMeetings took place directly via Teams with the open 3D cloud model. The corrections to \nthe  model  were very easy  for me because I could do them directly online. I uploaded my \nevaluation sheets and informed all students via email about their grades. If necessary, there \nwere debriefings online with the open 3D model. All in all, the construction cloud has saved \nme a lot of time.” For Rapperswil, the full integration of the Common Data Environment into \nlandscape architecture training was the next logical step towards Digital Construction. From \nfall semester 2021, all students in the construction courses worked with the CDE platform \nright from the first semester. The cloud solution is now used for submission and evaluation \nin all construction courses up to the bachelor thesis. Paper plans are no longer used as submissions. \n\nBIM4RainwaterManagement \n“Climate change is leading to heavier and more frequent precipitation. In urban areas, where \ndevelopment means the total impervious surface area is increasing, there is a growing risk of \nflooding from surface run-off after heavy rainfall. In climate-adapted and risk-based urban \ndevelopment,  there  is  an  increasing  need  to  manage  rainwater  resources  sustainably.  The \nconcept of 'sponge cities', which focus on increasing evaporation, infiltration, retention, controlled  temporary  flooding  and  providing  emergency  waterways,  is  a  planning  solution  to \nprevent damage from surface run-off and to reduce the effects of heat” (BAFU\/ARE 2022). \n\nLandscape Architects must take over a leading role in building 'sponge cities'. How can the \nprinciple of the sponge city be realized as part of Digital Construction? Although it belongs to  BIM  Construction,  this  very  important  topic  is  specifically  addressed  under  the  title \nBIM4RainWaterMangement. It is taught in the construction course in the 5th semester. The \nbasic goals of BIM4RainWaterManagement are: \nReturn of clean rainwater to the groundwater\nOptimization of a slow percolation\nUsage of a digital twin. \n\nWhen building the digital twin, the students apply the steps of the BIM4RainWaterManagement scheme (PETSCHEK 2019) and of course, they  use digital terrain  modelling. It is the \nbasis for quickly testing precise alternatives of retention and infiltration and thus find the \nideal solution for allowing rainwater percolation on site. The civil engineering software and \nthe  architecture  software,  combined  with  their  respective  strengths,  are  used  to  set  up  the \nBIM4RainWaterManagement project. \n\nThe 3D model has the following advantages: \nProof of retention areas in the event of heavy rain events. All water from roof tops and surfaces percolates on site, \nPrecise modeling of pavement surfaces and subsurface structures, \nParametric inlets, sludges collectors, manholes and pipes are included in the digital twin, \nClash detection between tree root balls and subsurface drainage elements, \nPrecise stakeout of all elements using BIM2Field, \nStudy of site grading alternatives with the help of automized grading (Grading Optimization in the civil engineering software). \n\nIn the next step, a link between the digital twin and numeric stormwater management soft-\nware will be established to validate the model and integrate it into a larger GIS analysis con-\ntext. Also extracting sustainability data from the digital twin will be an important topic. \n\nBIM4Trees \nStudents “plant” as part of the course described under point 2.3 BIMTrees. The trees were developed by Andreas Luka Consulting in close cooperation with Rapperswil, and the Swiss landscape contractor association Jardin Suisse, in which the Swiss tree nurseries are organized. \n\n3D trees are a major challenge for BIM in Landscape Architecture, as their geometry and \nproperties change significantly over the entire life cycle (LUKA & GUO 2021). Existing solutions did not adequately meet this challenge and could only insufficiently exploit the potential \nof BIM. Rapperswil therefore, supported the implementation of dynamic BIM trees with a \nresearch project. \n\nThe focus on the outer shells for crown, tree trunk and root, which are important for BIM, \nand their representation as solids allow both efficient clash detections and the extraction of \nvolumes  and  masses  for  further  analyses  (structural  engineering  calculations  and  shadow \ncasting). The tree size can be predicted interactively and quickly within the BIM software \nusing initial values for size when planting and growth functions for any point in time after \nplanting, complete with root in species, variety and age-specific shape and size. By simply \nlinking the very technical looking trees with Enscape3D, convincing visual representations \nof tree planting are created. \n\nThe feedback from independent study and bachelor projects flows directly into further development. There are currently 80 species\/varieties with the shapes and sizes according to \nthe Swiss quality regulations and the catalogue of a large German tree nursery. \n\nBIM2Field \nDigital Construction is based on digital data. In addition to the existing GIS data, one often \nneeds to collect his\/her own data. Point clouds from drone flights are a possibility. However, \nlandscape architects need height information below the tree and shrub layer. Drones cannot \nbe used here. The mobile laser scanner BLK2GO (LEICA Geosystems) is the latest generation of mobile laser scanning. A stationary device no longer has to be set up as before as the \nscanner can be used while walking through the site. This flexibility is extremely important in \nLandscape Architecture. The created point cloud is then post-processed and prepared for the \nBIM construction. The OST students use laser scanning as a regular tool in their projects. \n\nSince the fall semester of 2021, the surveying course has been renamed “BIM2Field”. The \napplication  of  one  person  tachymeter  stations  is  taught.  The  six  robotic  stations  use  the \ngeoreferenced  model loaded on the Construction  Cloud directly for stake out  without any \nintermediate steps. GNSS machine control systems in addition are presented in class by commercial companies. \n\nBIM2Cost \nThe central topics of the Landscape Architecture training in Rapperswil are cost calculations \nand construction specifications (specs). The 5th semester course, described under 2.3. is also \npioneering in this area. In Switzerland, the basis for efficient construction costs is the element-based  classification  eBKP-H,  which  was  developed  by  the  Swiss  Central  Office  for \nConstruction Rationalization CRB. The cost-relevant quantities are collected directly in the \ndigital twin. Automatically calculated dimensions and volumes result in more precise cost \nestimates. Due to clash detection, errors in the construction are detected early and thus in-\ncrease cost certainty. In the future, construction schedules will be displayed as 4D simulations \nusing the Common Data Environment ACC. In this way, the planned construction process \ncan be checked visually by the students and any contradictions can be solved. \n\nYouTube Channel \nThe YouTube Channel “Landscape Architecture Rapperswil” is the medium for the presentation of student independent study projects, thesis work and lectures on the topic. The following posts on building digital can be found on the constantly updated YouTube Channel: \nBIM2Field, laser scanner and robotic tachymeter: https:\/\/youtu.be\/icjaM3AoRa0 \nBIM2Field, 3D GNSS digger: https:\/\/youtu.be\/2MTnb7rV58o \nBIM Student independent study project: https:\/\/youtu.be\/q2SMcJ2knjg \nBIM Bachelor thesis: https:\/\/youtu.be\/0X8VUk-FyUM \n\nConclusion and Outlook \nDigitization in the Swiss construction industry is taking big steps forward; Landscape Architecture is not unaffected by this. Education in design, planting design, ecology and construction are the foundation of future Landscape Architects. In addition, skills in Digital Construction  must  be  integrated  today.  The  next  step  is  the  switch  to  Bring  Your  Own  Device \n(BYOD). From fall semester 2023, students are required to use their own devices in all Rapperswil courses. Computer labs will be no longer in use. It is also planned to integrate the \ndigital twin topic in the GIS teaching. In conclusion, OST Ostschweizer Fachhochschule in \nRapperswil acknowledges the challenges of Digital Construction and is riding along the digital wave.  \n\nDigital Landscape Architecture Education – Where Do We Stand and Where Should We Go?  \n\nAbstract: Landscape architecture has a crucial role in designing landscapes to influence how they per-\nform in a desired manner and provide more resilient and adaptive environments. Sophisticated analyti-\ncal and design tools and techniques exist along with data from a range of allied disciplines that have \nthe capacity to inform and transform the way landscape design approaches are conceived. However, \nthese are not widely embraced across landscape architectural design schools as a status quo. This paper \naims to provide a prompt to initiate a critical theoretical discussion on the future pedagogical foci for \ndigital landscape architecture education discourse at the forthcoming DLA  conference in 2023. The \ncritical question is, what is the future direction of digital landscape architecture education to address \nthe pressing and complex challenges of the climate crisis? For the purpose of this paper and the confer-\nence, we have limited the focus to three streams of digital landscape architecture: approaches, tools, \nand techniques. These critical streams of the discipline are framed through a brief synopsis capturing \nlineages from the 1960s to identify their influence on landscape architecture design education. Patterns \nand processes that lead to shortcomings in implementing the approaches are discussed. This is con-\ncluded with a set of questions derived from identified gaps to stimulate a targeted discussion on the \nfuture trajectories of digital landscape architecture education. \n\nIntroduction \nIn the face of climate change, we are confronted with accelerated urbanization and environmental  degradation.  \nThe  transformation  of  our  landscape  and  urban  systems  toward  more \nequitable, resilient and adaptive environments is urgently required, imbuing the capacity to \nrepair  and  respond  to  future  crises  and  to  adapt  to  unpredictable  futures  (ELMQVIST et  al. \n2019, SHEARER et al. 2021, FRICKER 2022a). \n\nDigital design education in landscape architecture that considers scales of action from the \nplanetary to the regional and microbial, has a crucial role in equipping students with the design  capabilities to  generate  alternative  typologies  of  aesthetics  and  performance  (MEYER 2008, FRICKER et al. 2020). This includes landscape transformations that perform in a desired \nmanner  (STEINITZ 2012, URECH et  al. 2020, GRÊT-REGAMEY et  al. 2021). To  this  end,  the \ndiscipline has developed sophisticated design and analytical tools, such as 3D point clouds, \nas a basis for urban design and algorithmic analysis of energy absorption, wind flow, and \nshadow  provision  (URECH  et  al.  2020,  2022).  They  support  an  integrated  analysis  across \nscales and feedback loops, as evidenced in several recent projects, like the example of a river \nrehabilitation project at the local scale that consequently explores the larger catchment area \n(VOLLMER  et  al.  2015,  GRÊT-REGAMEY  2017).  An  illustrative  overview  of  tools  and  approaches for responsive \nlandscape design is provided by  WALLIS & RAHMANN (2016), as \nwell as by CANTRELL & HOLZMANN (2016). The publications provide a comprehensive overview of design projects and \nresponsive technologies that frame performance as a generative \ndesign approach. Furthermore, heterogeneous data on environmental and socio-economic as-\npects are available with unprecedented detail to inform design approaches. For example, ur-\nban sustainability transformation projects that use passively sensed geospatial data of land \nuse, service networks etc., may be augmented by active sensing of stakeholder perceptions \nand behaviour  with participatory  methods and technologies (GRÊT-REGAMEY et al. 2021). \nHowever, although increasingly more tools and datasets are developed, and the agency of \ntheir application is demonstrated in prototypes (CANTRELL & HOLZMAN 2015), they are not \nwidely used across landscape architectural design schools. We postulate that a critical dis-\ncussion on digital design education is lacking in the discipline of digital landscape architec-\nture  (FRICKER 2022b).  Therefore,  we  propose  to  investigate  this  in  the  forthcoming  2023 \nDigital Landscape Architecture conference. \n\nThis paper acts as a precursor for the future conference dialogue to interrogate where Digital \nDesign Education is positioned and how to advance the pedagogical approaches of digital \nlandscape architecture. For this,  we  want to highlight some of the  existing theories of the \ndiscipline in the discussion, describe the status quo, and point out recent  “streams of con-\nsciousness”. This demonstrates that the landscape architecture discipline has constantly been \ninfluenced by and porous to other disciplines, thinking, tools and techniques that have con-\nstructed amorphous streams and trajectories continually being made and positioned (FRICKER \n2021). A complete review of the theoretical streams in digital landscape architecture is be-\nyond the scope of this paper. However, we reflect on specific critical theories and associated \ntools and processes from the 1960s to today that have significantly influenced current educa-\ntional practice in digital landscape architecture. The intention is not to give a comprehensive \nhistory of digital landscape architecture, but a framing of various digital design approaches \nin landscape architecture as a departure point for a discussion on future tools and techniques. \nWe use this review to discuss recurring patterns and processes in how new approaches and \ntools are used and how the gap in implementation manifests (ERVIN 2018). This leads us to \nformulate concrete questions to specify further: How do students need to be taught digital \napproaches? Where should we focus on enhancing our students' teaching? Furthermore, what \nneeds to be taught in digital landscape architecture education? \n\nA Synopsis of Computational Lineages \nFrom System Thinking to Artificial Intelligence \nThis chapter aims to reflect on a selection of relevant concepts and  workflows developed \nmainly during the 1960s and 1970s, which strongly influenced a pedagogy for the computa-\ntional realm and demonstrated a radical approach to creatively interact with diverse data sets \nacross scales. The purpose of this brief historical reflection is to unveil concepts to be revisited within the current discussion on defining possible avenues for adjusting the present trajectory of the digital pedagogy in the field of landscape architecture. Due to the richness of \nhistorical  references,  the  discussion  is  focused  on  key  examples,  inviting  for  an  extended \ndiscussion towards the future of the digital landscape architecture education and implementation within practise. Note: the selected examples in this paper address only male scientists. \nWe want to acknowledge that in these known lineages, female leaders in the field often need \nto be discussed as being more instrumental to the development. We aim to capture and slowly \nrectify this familiar narrative in future discussions. \n\nAlready towards the end of the 60s, computational design thinking pioneers recognized the \npotential of machine-human interaction to sound out new potentials within architecture and \nlandscape architecture. Almost 25 years later, the integration of “computation” in teaching \nushered a fundamental pedagogic change in direction for design teaching, research, and a \nform making language. In addition, a parallel stream “Digital Design Education” established \nitself with a focus primarily on the visualization applications of digital tools and the teaching \nof new software (ERVIN & HASBROUCK 2001, FRICKER 2021). The presented historical overview allows for a discussion in order to shift the focus from a merely tool-based approach \ntowards holistic computational design thinking. \n\nThe history of computation goes far beyond the development of computing technology and \nrelates to the “interaction between internal rules and (morphogenetic) pressures that, themselves,  originate  in  other  adjacent  forms  (ecology)”  (MENGES & AHLQUIST 2011, 8). This \ncomplex theory and framework of relationships is based upon theories from disciplines like \nmathematics, computer science, cybernetics, biology and philosophy. The integration of in-\nformation technological developments into the landscape architectural curriculum accelerated especially during the 1960s and 1970s through an intensive exchange between cybernetics and its influence on architecture (MENGES & AHLQUIST 2011). This first manifestation \nwas driven by a deep theoretical discourse and led to the first integration of Artificial Intelligence (AI) in design methodology. The fusion of these two areas lay in new questions related \nto the rise of global ecological challenges, which also changed our relationship to data and \nour interaction with the information it contained (FULLER 1969, MEADOWS et al. 1972). The \ntheories developed in the area of cybernetics allowed a new computational design method to \nbe established mainly within architecture, which describes this complex network of relationships  through  the  integration  of  System  Theory  and  Patterns  (FRAZER  1993).  In  the  late \n1960s, Jay Forrester, a computer engineer and system  scientist by education, strongly engaged in describing the “systemic structure responsible for the dynamics of urban development and decay”, founded the Urban System Group at MIT (FORRESTER 1973). \n\nThe themes discussed between cybernetics and architecture influenced simultaneous developments in landscape architecture with respect to the domain of system thinking in the field \nof spatial data handling. This is because both the fields of architecture and landscape architecture  were called to address issues of rapid urbanization.  Though the field of landscape \narchitecture recognized the necessity of developing new approaches for handling data, it did \nnot develop meaningful questions or further research with AI. \n\nEmerging Pedagogical Principles \nOne of the pioneering academic institutions, introducing a new form of design education with \nspecial focus on computational design thinking, was the Ulm School of Design (Hochschule \nfür Gestaltung in Ulm, HfG), active from 1953 until 1968. Already 17 years before the foundation of the Architecture Machine Group by Nicholas Negroponte and Leon Groisser, at a time “computers were only available at a few research centres, (…) their capabilities were \nwidely recognised and the subject of much broader theorisation and influence, opening up \nthe field of logic and computer science to the social sciences and arts” (NEVES et al. 2013, \n292). The new pedagogical approach of the HfG is understood as a research-based activity, \nstrongly engaged in theoretical discourse focusing on a new understanding of design, which \nis based on thinking in connections and networks. \n\nThe “pioneered heuristic procedures that were related to the power of the new computational \nmethods” (NEVES et al. 2013, 299) developed at the HfG can be seen in strong relation to the \ncomputational  education  developed  by  Negroponte.  Negroponte  recognized  that  problem-based learning concepts and the opportunity to work together with the computer for direct \nfeedback  significantly  increased  students’  motivation.  Programming  was  understood  as  a \nnew way of thinking! Negroponte experimented with the potential of formal descriptions of \narchitectural solutions, implemented through a program and deployed as Computer  Aided \nParticipatory Design. Thus, he laid the foundation for current methods in the field of AI and \nemphasized, “However, remember that these systems assume the driver to be an architect” \n(NEGROPONTE 1975, 365). The influence of the early computational design development in \nthe education of architecture has had very little impact on the area of landscape architecture \neducation. The only traces of limited integration of computational design can be observed at \nthe newly founded Laboratory of Computer Graphics at Harvard Graduate School of Design \nin 1965. Contrary to the radical development and interaction with data for generative purposes at the Arch MAC Group at MIT, landscape architecture education at Harvard’s GSD \nconcentrated mainly on layered data-mapping methods. \n\nThe Evolution of Spatial Thinking: From GIS-based Layering towards Mapping \nThe field of landscape architecture focused its emerging computational possibilities on re-\nsearch and application in teaching during the 60s and 70s on problems related to Big Spatial \nData. The pressure to develop new methods to process the complex relations of nature-based \nprocesses was strengthened by the new arising “Ecological Awareness”. The idea of layering \nspatial information and its use for evaluating designs was presented 1971 in the book “Design \nwith Nature” by Ian McHarg (LEE et al. 2014). Based on this idea, Geographic Information \nSystems (GIS) originated largely at Harvard GSD enabled to geographically allocate digital \ndata and create maps (FOSTER 2016). Further developments in the 1970s and 1980s focused \non  spatially  analysing  the  system  from  different  aspects.  In  the  following  period  the  user \ninterfaces, data processing capabilities and data interoperability were enhanced, and with this, \nits  applicability  for  many  user  groups  (LEE at  al. 2014). This  development  enabled  easier \naccess to digital geodata and simulations for assisting in a design process, and in 2012, Carl \nSteinitz published a “Framework for Geodesign”, which presents an iterative process of integrating stakeholders’ knowledge, needs and desires, geospatial modelling, impact simulation and rapid feedback on the degree of achieving a desired goal to facilitate an informed, \nresponsive design (FOSTER 2016, STEINITZ 2012). \n\nCurrent “Streams of Consciousness” \nStreams of consciousness describe time infused recursively in the material reality of the landscape through states of formation, from those that signify stability to sequences that are predictable and observable processes of change to those that are uncertain and instantaneous. \nMASSUMI (2002) suggests that our own “human” sensing of the world experienced through \nsensation involves a “backward referral in time”. Therefore, a sensation is organised recursively prior to being part of our conscious chain or actions and reactions. In this process, the \nsmoothing over of the anomaly is made to fit our conscious requirements of continuity and \nlinear causality. \n\nThe act of measuring and making the landscape is not a neutral activity; therefore, the process,  techniques,  and  tools  of  representing  form  are  rooted  in  a  specific  understanding  of \necosystems and their processes. “Actant is a term from semiotics covering both humans and \nnonhumans; an actor is any entity that modifies another entity in a trial; of actors it can only \nbe said that they act; their competence is deduced from their performances; the action in turn \nis always recorded in the course of a trial and by an experimental protocol, elementary or \nnot” (LATOUR 2004). Tools for measuring the landscapes, and the techniques by which we \ndeploy them, have their own constraints that translate and transform information. The representations we make are constructed from a set of instruments, codes, techniques, and a lineage  of  conventions.  Consequently,  the  worlds  they  describe,  and  project  are derived  only \nfrom those aspects of reality susceptible to those techniques. These acts of measuring, anaysing and making the landscape can formulate a view of what already exists and set conditions for new worlds to emerge. Below are three examples of what we refer to as porous, \nconstantly evolving “streams of consciousness”. \n\nEntangled Knowledge Systems: STEINITZ’S (2012) framework provides a clear structure on \nhow to design a design process for multi-disciplinary collaboration to better address the complexity of environmental problems across scales (FOSTER 2016). Along with the emergence \nof the new field of Geodesign, geodesign education programs were launched (WILSON 2014) \nand today, universities worldwide participate in the International Geodesign Collaboration \n(https:\/\/www-igcollab.hub.arcgis.com).  A  major  challenge  in  the  education  of  Geodesign, \nhowever, are the strict disciplinary silos at the universities that hinder cross-disciplinary collaboration (WILSON 2014). Further, recent evaluation of geodesign processes reveal that not \nall projects implement the full structure and particularly the analysis of spatial relationships \nand impact analysis across scales are often not well performed (GU et al. 2020). \n\nThe emergence of geodesign and other GIS-based methodologies coincided with the critical \ndiscourse on big data and the development of open-source systems that enabled collective \ncontribution and alternative algorithms to reveal bias in large data sets. In landscape architecture education, students were educated on the ethical and responsible use of big data to \ncritically address the inherent power that data has had historically in producing unjust actions \nand policies on the oppressed. The emergence of “hacking” data approaches and the creation \nof alternative data sets as a public good and public service consequently emerged (GABRYS 2016, WILLIAMS & PROQUEST 2020). \n\nEmergent Patterns: In another stream, contemporary research in landscape architecture ad-\ndresses, in particular, the technical challenge of best-representing geo-data and environmen-\ntal factors to foster an understanding of information and making sense of it (URECH et al. \n2020). For example, a collection of drawing types, such as diagrams, axonometry and map-\npings, has been assembled (AMOROSO 2015). In response to more complex landscape rela-\ntionships and organizational patterns in landscape architecture education, digital syntax, such \nas codes and patterns, is used to establish quantitative correlations between the landscape and \ndata processing. These approaches are utilized as a generative component for design produc-\ntion (M’CLOSKEY & VANDERSYS 2017, CANTRELL & MEKIES 2018). \n\nInternational Fields: With the environment globally changing more rapidly than ever be-\nfore, in the first two decades of the 21st century the awareness of urgency for an immediate \nresponse for solving problems increased. This gave rise to the use of point clouds recorded \nin the field with a  terrestrial laser scanner to rapidly replicate the physical landscape with \nhigh resolution and fidelity and as basis for analysis and design (GIROT 2019, URECH et al.2020). The point cloud models provide a common ground between architects, engineers, and \nscientists to develop informed landscape design (GRÊT-REGAMEY et al. 2021, GRÊT-REGA-\nMEY 2017, VOLLMER et al. 2015). By performing geospatial analyses using the geometry of \nthe point cloud  model, spatial configuration parameters can be investigated and enhanced \nemploying simulation models, e. g., for improving climate conditions through altering build-\ning  and  vegetation  patterns  (URECH et  al. 2020).  In  this  way,  the  point  cloud  models  and \nimmersive data interaction allow for more dynamic and versatile forms of landscape design \nthrough all scales involving aesthetic and performance considerations (GIROT 2019, URECH \net al. 2022). But the approach is still very experimental and has not yet found widespread use \nin digital design education in landscape architecture. \n\nDiscussion and Conclusion: How to Consolidate the Gap? \nWhen we look at the outlined examples, there are some recurring patterns that suggest a gap \nin the implementation of tools and approaches. A major concern is that often the full understanding is left out of what the process behind a generated solution is. In particular, this is \nevident in three crucial pitfalls of tool implementation, which we exemplarily point out as: \n(1) using “black box” digital tools, (2) improper calibration, and linear processes (3) focusing \non single aspects rather than interactions and processes across systems. \n\nConcerning  the  first  pitfall  with  the  tremendously  fast  development  of  cutting-edge  tools, \ndesigners become mere users without an understanding of the underlying processes and the \ninherent critical distance to the results. Looking back in the history of digital landscape architecture, the invention and use of digital tools in the design process (such as Grasshopper) led to concerns of employing a “black-box” optimization, taking the output as a goal in itself \nand lacking a more holistic systems thinking (FRICKER et al. 2020). \n\nSecond, not understanding the complex relationships of the defined parameters of a model \nand making uninformed choices of input data can also lead to wrong design decisions and \noptimization processes. For example, a data set is assembled only in the beginning of a design \nproject  and  often  neither  updated  nor  further  data  is  collected  according  to  the  generated \nsimulation  outputs  (FRICKER 2021).  Overall,  a  critical  engagement  with  the  collected  and \ngenerated data across scale and fields is missing. \n\nThird, there is a risk of justifying a design through simulation results on single aspects or on \none specific scale while the design solution actually is not solving the problem when examined  at  a  large  scale  because  of  mutual  interactions  of  single  aspects  on  various  scales \n(FRICKER et al. 2020). Disregarding aspects can lead to undesired developments, for example, \nfocusing only on the design site for river rehabilitation one might overlook effects of developments in the catchment area still leading to severe flooding (VOLLMER et al. 2015). An urban densification that helps minimize urban sprawl can increase the urban heat island effect \nand negatively affect a series of services provided by the urban ecosystem such as the provi-\nsion of recreational area, storm water infiltration and retention, or habitat for species (GRÊT-\nREGAMEY 2017, WISSEN HAYEK & GRÊT-REGAMEY 2021). There is a lack of understanding \nof system dynamics, spatial patterns and relationships (WOOD 2017). \n\nLandscape architecture as a discipline is evolving rapidly as it responds to both broadening \nand intensifying changes in environmental, social and political conditions. These changing \nconditions require development and innovation in the digital competencies of landscape architects. What approaches, digital skills and technologies are needed by landscape architects \nto equip them to deal with the complexities brought forth by the climate crisis? Then comes \na  critical  consequential  question:  how  can  we  design  the  education  of  future  practitioners \n(MONACELLA & KEANE 2023). \n\nThe transformation of the digital landscape architectural education must involve profound \nreconfiguration  of,  and  innovation  in,  discrete  knowledge  systems  within  the  pedagogical \nframework of the curriculum, including the course’s techniques, approach and nature of the \nway students are taught and learn. In conclusion we posit the following questions for discussion: \nWhat is the current status of  pedagogical approaches to digital landscape architecture \ntechniques, tools and approaches? What are the former “streams of consciousness”? We \nargue that streams of consciousness are porous lineages and trajectories historically influenced by broader contextual innovations and pursuits. \n\nWhat are the recent critical developments in digital landscape architecture and related \napproaches? What are the current “streams of consciousness and potential challenges in \nrelation to emerging fields like Artificial Intelligence and Machine Learning”? \n\nWhat are the gaps in the technological-based technique developments in digital landcape architecture utilized to address the climate change related issues and their translation in advancing pedagogical approaches? \n\nEnhancing Technical Grading Education: Finding the Right Tools for the Job \n\nIntroduction \nStated simply, grading design involves the alteration of the surface of a site to direct water \nflow. The reality of technical grading design is much more complex and involves the consideration of above- and below-ground, three-dimensional spatial relationships between people, \nvehicles, buildings, walls, pavements, utilities, plantings, and more. Considerable time and \nexpertise are required to develop the complex cognition necessary to produce complete and \ncorrect technical grading designs. Teaching technical grading skills to diverse groups of novice landscape architecture students is a difficult task for this reason – expertise and time are \nboth in short supply within four- or five-year undergraduate, and especially so within two-or three- year graduate academic programs.  \n\nIt  is  well-documented  that  learning  can  be  enhanced  by  using  both  static  and  dynamic \ngraphics (i. e., visualization tools) in instruction, see SCHNOTZ 2002 for a review. Learning \nenhancement can occur with the use of visualization tools both in external instruction and \ninternal learning processes. Teaching and especially learning of design skills heavily depends \non the use of visualization tools. In external instruction, design concepts (including technical \ngrading) are introduced and discussed, then modelled and practiced within a lecture\/studio \nenvironment using problems with varying degrees of application to “authentic” or real-world \nsites and problems. Students are expected to expand their learning of those concepts internally, by exploring design options and relationships with various graphic tools, such as drawing, modelling, rendering and\/or animation of views which they employ to visualize and understand the spatial relationships and tactile qualities of their design proposals.  \n\nGrading instruction necessarily relies on the use of two-dimensional visualization tools to \nboth explore design relationships and document grading changes. Sections and plans are two \ncommon visualization tools relied upon in grading instruction to foster design and documentation of grading plan proposals. Design grading, as a more conceptual, early-process activity, lends itself to design study via three-dimensional modelling. These models may be successfully used to rapidly understand initial conceptual or roughly detailed grading relationships and surface morphology. Technical grading cannot be easily or quickly explored with precision via complex three-dimensional modelling as the grading must first be completed before it can be modelled. This study hypothesizes that despite the use of complex external \nvisualization tools being less appropriate for use in technical grading design and communi-\ncation tasks, complex internal visualization operations must be utilized by learners to under-\nstand and manipulate the complex relationships among site design components in an efficient \nand confident manner. How, then, does an instructor best facilitate students’ internal visual-\nization skills without relying on the computer to visualize for them? Additionally, how does \nthe student avoid spending time developing complex digital models at the expense of devel-\noping the complex cognition required for technical grading competence? \n\nCognitive Load Theory \nThis study was initiated and informed by a literature review of Cognitive Load Theory (CLT) \nand through analysis of instructor responses to perceived student needs and direct student \nquestions during a semester-long design studio course. CLT was used as a lens through which \nto examine potential barriers to student development of the complex cognition required for \nindependent technical grading competence in the studio environment, and to inform instruc-\ntional changes to help promote higher degrees of learning. CLT assumes that two major goals \nof instruction are to facilitate the construction of internal schemas (models) and to automate \ntheir use to mitigate the significant impacts the limitations of human cognitive architecture \nhave on our ability to cognitively process complex learning (KALYUGA et al. 2003). In this \nauthor’s  opinion,  this  is  the  primary  goal  of  instruction  in  technical  grading  realms  –  the \ndevelopment of internal models, as opposed to external models (frequently manifesting as \nvisualizations and\/or displays), by which to process the complexity inherent in technical site \ndesign thinking quickly and efficiently. The limitations of human cognitive architecture may \nbe described in terms of three types of cognitive loads (for a more complete description, refer \nto RENKL & ATKINSON 2003):  \n\nIntrinsic Load refers to the complexity of the learning material itself. Technical grading \ninstruction may carry a high intrinsic load due to the complexity inherent in the interactivity  between  many  different  site  design  relationships.  Intrinsic  load  is  related  to  a \nlearner’s prior knowledge and should be expected to be at its highest levels with novice \nlearners. Intrinsic load may manifest as an information and\/or decision-making overload \n(too many requirements or too many relationships to attend to simultaneously). This load \ncan  be  decreased  with  experience  as  learners  develop  more  meaningful  information \nchunks which can be stored in long-term as opposed to working memory. \n“Germane Load refers to demands placed on  working  memory capacity that are imposed  by  mental  activities  that  contribute  directly  to  learning”  (RENKL  &  ATKINSON \n2003). This is the load learners should focus their cognitive resources on to facilitate \nlearning most successfully. \n“Extraneous Load is caused by mental activities during learning that do not contribute \ndirectly to learning” (RENKL & ATKINSON 2003). Due to the high intrinsic load inherent \nin technical grading tasks, it becomes very important for instruction to be designed spe-\ncifically to reduce extraneous loads. Considerable extraneous load is related to low levels \nof expertise. Low expertise can contribute to a simple lack of understanding of how to use available information and tools, and\/or inefficient use of the available information \nand tools. \n\nTo limit the impact of intrinsic and extraneous loads, an understanding of the technical grading expertise held by learners is critical to determine what information is relevant and how \nto present it to maximize the learner’s ability to attend to it. Novice learners generally learn \nbetter when given higher degrees of instructional guidance as they still need to develop their \navailable  schemas.  However,  more  knowledgeable  learners  (those  with  more  and\/or  more \ndetailed schemas) may require a different instructional approach that limits redundant information, otherwise they may experience cognitive overload and poor learning, despite their \nhigher level of expertise. This difference is termed the expertise reversal effect (KALYUGA et \nal 2003). It is theorized that this expertise reversal effect plays a role in the cognitive processes used by students to process technical design instruction activities and in the visualization tools and processes they use to supplement their learning. Therefore, it is important to develop instruction that recognizes and responds to the variable levels of expertise among \nthe students in a course, both related to the processes and visualization tools utilized to complete technical grading design. This study was undertaken to begin to understand the range \nof expertise variability and to theorize diagnostic tools which can be used in targeting instruction activities maximizing independence and development of expertise in the technical \ngrading design realm. \n\nInstructor Response Analysis \nThe experience of teaching this course over the past three years has been that the most educational impact (i. e. attention to germane load) comes from direct and personalized individual instructor interaction with students during their problem-solving process instead of group classroom interactions. Currently, the instructor must invest considerable time into individual \ninstruction to achieve this impact, so an analysis of instructor responses during these individual interactions was undertaken to balance effort and maximize learning. The analysis seeks \nto identify patterns among the actions or visualization tools recommended, the frequency of \nrecommendations and how those recommendations were accepted and implemented by the \nstudents. Additionally, the analysis sought to determine if there was any discernible impact \non the levels of independent thinking and use of visualization tools to enhance internal visualization processes. \n\nThe analysis focused on the following interactions due to their potential capacity to directly \nreduce intrinsic and extraneous loads. Intrinsic loads can be reduced by personalized discussion regarding  how to  use the information available, and  how to produce any lacking  but necessary information. Extraneous loads can be reduced by introducing and directly modelling the use of simple, abstract visualization tools to think and produce more complex internal \nvisualizations supporting technical grading design efforts. \n\nResponses were analyzed from interactions over three semesters of a studio course focused \non  the  technical  grading  design  of  a  complex  real-world  development  site.  The  fall  2020 studio (enrollment=18) considered a nearly 5-acre office development, fall 2021 studio (enrollment=23) focused on a 7-acre multi-family development and the fall 2022 studio (enrollment=19) designed a 5-acre office development. The course consists of a studio component with  460  minutes  (7.7  hours)  of  weekly  contact  time  (which  includes  lecture  time)  and  a separate  110-minute  (1.8  hours)  per  week  CAD  lab  component.  All  students  in  the  target course were novices with a negligible degree of variation among their prior grading expertise. All students were introduced to grading activities in an earlier course with a focused grading component where they were presented the grading process, techniques for visualizing landform and interpolating elevations, and developed grading skills via a grading design project. \n\nVariability of Student Expertise \nResults of the study identified potential barriers to learning situated within four pathways: \nLived Experience Variability: This pathway is defined as individual differences in recall\/codification (chunking) of actual human experiences, such as walking across surfaces,transitioning  grade-change  devices, noticing materials\/textures\/connections\/joints, etc. and linking or chunking those experiences together with technical grading skills in meaningful ways. \nCausal Chain Recognition: The skill to recognize critical relationships among existing \nand proposed component parts in the context of a technical grading design. \nInternal Animation: The ability to internally animate objects to transform them rotationally and\/or positionally  within the  site, or to animate and visualize  water  flowing across\/through elements of a site. \nDigital  Expertise  Variability:  This  pathway  defines  individual  differences  in  both \nknowledge of digital visualization tools (what they are and what they do) and how to \nmake them work to solve particular problems. This pathway refers both to simple inexperience\/lack of knowledge, and self-inflicted or self-limiting inexperience (such as refusal to spend the time needed to fully understand a software program). \n\nLearning activities in the first three of these pathways require the use of relatively simple external visualizations (such as diagrams, plans and sections) to support considerably more complex internal visualization and transformation operations such as flows and inferred motion – both of which represent aspects of mental animation (HEGARTY 1992).  \n\nCausal Chain Recognition supports the identification and documentation of critical relationships between site plan elements, and the visualization of responses to transformations \nof plan elements. CCR is the skill one would use to understand that as one corner of a flat \nrectangular pavement surface is depressed (lowered in elevation), the rest of the pavement \nsurface will tilt in that direction unless the surface is broken, creased, or otherwise deformed to accommodate multiple slopes. Thus, complex internal animation is required to mentally transform site objects and\/or surfaces with elevation differences efficiently without relying on an external visualizations to understand those transformations.  \n\nInternal  Animation  is  a  skill  utilized  when  considering  how  water  moves  across  and\/or through the system. Assuming water droplets remain intact from the moment they strike the surface until they leave the site at the outfall, technical graders should be able to trace a drop of water from the point it contacts the surface all the way to the site drainage outlet using internal animation. This skill requires the water to be mentally animated as it travels across surfaces and through conveyances. \n\nIt is hypothesized that Causal Chain Recognition, Internal Animation and, to an extent, Digital  Expertise  Variability  can  be  directly  influenced  via  instruction  emphasizing  germane loads, though this paper focuses only on addressing improvements to Causal Chain Recognition and Internal Animation. The study was conducted under the assumption that the creation  of  complex  external  visualizations,  such  as  detailed  3D  models,  would  contribute  to \nhigher  extraneous  loading  in  the  context  of  the  technical  grading  course,  so  instructor  responses were constrained to primarily 2D graphics, including static 3D views, but not models. Highly detailed 3D models of proposed grading solutions were not required or recommended by the instructor as a part of this course. However, TIN surfaces created from existing contours were required to be created using Civil 3D, and the use of the “Quick Profile” tool recommended for understanding existing topography and quickly testing proposed solutions and relationships. Additional solutions have been considered to address Lived Experience Variability, but those have yet to be implemented and tested in the course and will be addressed in a future paper. \n\nInstructional Methodologies \nFour  novel  technical  grading  instructional  methodologies  have  been  theorized  to  address learning improvements for each of the pathways mentioned in the previous section. Instructional methodologies were developed to both function as diagnostic tools to identify needed areas of focused instruction, and to facilitate the packaging or “chunking” of information to minimize  negative  cognitive  loads  and  enhance  development  of  technical  grading  design skills in novice learners.  \n\nSpot Skipping: a method of intentionally widespread, but very limited calculation of spot \nelevations early in the grading process which directly supports the recognition and calculation of critical grading relationships as a part of the Causal Chain Recognition pathway. \n\nFlow Branch Analysis: a method targeting spot elevations defining individual branches of \nthe site flow pattern to analyze flows and inform early technical grading design. This method of analysis is primarily concerned with flow lines and may be used independently or concurrently with Spot Skipping and primarily supports Internal Animation as water flows are visualized and defined across a site.  \n\nFlow Barrier Analysis: a method of analyzing site plan objects in terms of their impact on \nwater and\/or people flows. This method of analysis allows for the chunking of the site into \nflow barrier types and works to define and describe water flow patterns supporting Internal \nAnimation.  \n\nTransect Grading: a method of spot grading along discreet transects, usually drawn perpen-\ndicular to water, pedestrian and\/or vehicular flow paths, rather than at locations where spot \nelevations would be commonly calculated and included on a technical grading plan. Transect \nGrading  is  another  method  of  chunking  the  critical  relationships  between  elements  of  the grading plan into easy-to-understand sections, primarily supporting Causal Chain Recognition. Transect Grading may also be used in conjunction with Spot Skipping and Flow Branch Analysis. \n\nDiscussion and Conclusions \nEvidence from preliminary use of the four instructional methodologies described above in \nthe fall 2022 course seems to support the hypothesis that certain visualization tools may impose high extraneous loads on students. Their level of expertise in both interpreting critical grading design relationships and in the construction of suitably precise models is low enough that they don't  yet have the detailed schemas needed to develop efficient, low-extraneous-load processes. 3D model construction was deemphasized in the course and student outcomes seemed  to  improve.  Whether  the  improvement  was  related  to  the  lack  of  effort  spent  on model-building or simply more time developing grading skills has not yet been studied. However, CLT would support the notion that regardless of the reason, germane loads were prioritized and learning improved. \n\nResults suggest that, while digital drafting tools and Civil 3D can assist in drafting precision and in the process of working through the four methods, no complex visualization tools are required to achieve a high degree of expertise in technical grading (see Table 2). Even the 3D views may be sufficient if drawn inaccurately by hand or quickly and roughly modelled without any elevational precision in a program such as SketchUp (see Figure 3). Documentation and external communication of the grading solution may be best completed with sophisticated visualization tools, however this communication is secondary to the grading itself. The development of the grading design, to a high degree of detail, should be easily achieved using simple drafting tools and hand graphics if care is taken to do so with the required precision. This hypothesis must still be tested to confirm whether the use of complex external visualization tools  would be helpful in developing internal animation skills among novice technical graders.  \n\nThe production of a construction document quality grading plan has been a requirement for \neach iteration of this course and, given the complexity of the Civil 3D platform used to document those solutions, it is possible that some of the negative observations within the study may stem from extraneous loads imposed by the required documentation rather than issues regarding grading skills. The opinion of this author is that construction documentation should be an integral part of any technical grading plan. The primary purpose of the technical grading plan is to facilitate site construction and, learning to communicate design intent to the appropriate audience with the appropriate visualization tools should be the goal of any design education. Perhaps there should be a different focus on the documentation aspect of the grading plan, either concurrently or in a different semester. More work needs to be done to determine where any differences might exist between grading design skill and grading documentation skill. \n\nIt is important to note that the methodologies examined in this paper were applied to fine \ngrading of a site surface. Detailed considerations of mass grading and site stormwater management, such as balancing cut and fill and sizing stormwater management facilities were not included  as  a  part  of  the  target  course.  Accordingly,  additional  research  must  be  done  to examine the relationships between successful fine (surface) and mass grading activities while utilizing the methodologies described in this paper. \n\nThis study raises the question of which approach is the most appropriate for the most efficient transfer of knowledge and development of technical grading skill, the project-level approach, focusing  on  direct,  real-world  application  (as  presented  in  this  paper),  or  the  vignette  approach, focusing on individual skill development and repetition. The course within this study primarily relies upon the former, project-level approach, but does incorporate aspects of the vignette approach within the workshop and demonstration interventions, and the opinion of this author is that a combination is ideal. More work is required to answer the questions of what that combination should look like and how much time and effort should be spent by instructors and students within each. The four methodologies developed through this study should be developed into an online rapid diagnostic tool to identify the levels of technical grading expertise in a student population over time, and to match more detailed instructional methodologies to those students to help them overcome challenges to cognition and development of the expected technical grading competence. This study also suggests that additional  exploration  is  required  to  more  fully  understand  the  relationship  between  cognitive \nloading and the use of digital design skills and visualization tools versus analog design skills and visualization tools in an educational environment, especially in the realms of technically complex design tasks. \n\nFuture Resilient Landscape [Architects] \n\nAbstract: Parametric and computational design processes will evolve and inform the field of landscape \narchitecture. This paper investigates a bottom-up teaching approach about parametric design to novice \nlandscape architecture students as a viable method in their design pursuits. Using a case study, students \nexplored a translation of an intuitive approach to design into a parametric script, taking them through \nconcept ideation, fabrication, and ultimately informing implementation. \n\nIntroduction \nResilient landscape architects will be those who can anticipate, analyze, and address complex \nlandscapes, including those challenges yet to emerge. All professional fields are developing \ncutting-edge technologies to facilitate the analysis of complex issues and the implementation \nof viable solutions. The emergence of new technologies in landscape architecture has been a \nsignificant factor in the development of this discipline and has facilitated relevant research \nand design processes. Landscape architecture, now maturing with its own digital design practice  including  computational  design  (popularly  described  as  parametric  design)  is  gaining \nmomentum. The use of digital tools and techniques in the field of landscape architecture will \ncontinue to grow and evolve in the coming years (WALLIS & RAHMAN 2016).  \n\nFascinating  examples  of  new  computational  approaches  and  applications  are  emerging  in \nlandscape architectural projects. However, Bradley Cantrell and Adam Mekies believe that \nthe mechanism through which these applications are implemented remains obscure. This is a \nmissed opportunity since the logic, the thought process and the utilization of parametric design, could have been more evident to launch the complex execution (CANTRELL & MEKIES 2018). \n\nSince 1967, the MIT Media Lab has successfully “civilized” or “tamed” design and computer \ncode through years of effort. In 2003, the team designed the “Scratch” programing language \nso which began to employ a graphic interface rather than the laborious coding string (NAGLE \n2014). \n\nMitch Resnick, a computer scientist at the MIT Media Lab, conducts the “Lifelong Kindergarten”, where children learn to code and create from a very young age (RESNICK 2014). As \nResnick indicates, “When you learn to read (code), you can then read (code) to learn.” \n\nCoding identified as the core to parametric design describes parametric design thinking as a \nmethod, and not a tool. Do design school curricula or instructors provide effective strategies \nto  increase  the  broader  adaption  of  recent  technologies,  specifically  parametric  design, to \nfuture students?  \n\nIn recent years, the potential of computational media and its syntactical interface has been \nwidely explored by young designers through the GUI (Graphical User Interface) syntax of \nscripting. “How can we leverage this newly acquired foothold and understand better what we \nare gaining from parametric modeling\/visual programming\/coding as a design process and \nconceptual generator?” (CANTRELL & MEKIES 2018). \n\nIn this study, the authors investigated a kinaesthetic learning approach to cultivate a bottom-up understanding of the computational design process and engage students with advanced \ndigital tools. The goal was to encourage novice students to learn implicit knowledge of the \ncomputational design process first, and then learn explicit knowledge, in the following semesters. The emphasis was to employ parametric design tools in the design process rather \nthan limiting, or devaluing, their use to mere digital representation efforts. \n\nThe research team supervised a group of six (6) second-year Bachelor of Landscape Architecture students, interested in a public art competition, to utilize computational design tools \nin concept and design development of a public art piece, and subsequently, its off-site digital \nfabrication and production, and on-site implementation. Prior to this project, five of the six \nstudents had not utilized commercial 3D computer graphics and computer-aided design application software, such as the Rhinoceros 3D, as used for this project. The use of computational design tools  facilitated, and elevated, conventional design process activities into an ambitious design and implementation proposal.  \n\nAnalogue (Kinesthesia) to Digital (Parametric)  \nThe group of six (6) students enrolled in an independent course (design studio), co-taught by \ntwo faculty members, to prepare a design proposal for a public art design competition. Structured into three (3) phases, the studio included analogue rule sets, parametric\/digital rule sets, and fabrication. \n\nThe South Park project, by Fletcher Studio, inspired the method so that the computational tools test the resilience of analogue rules for spatial partitioning within a small park in San Francisco, CA. That project’s research was prepared for the Acadia 2014 exhibition, an annual parametric design conference (CANTRELL & MEKIES 2018). When Fletcher Studio first began work on San Francisco’s South Park, the initial design was developed “through iterative analogue diagramming” with a focus on “an intuitive understanding of the site and embedded in an analogue rule set” (FLETCHER 2021). \n\nCase Study: South Park, Fletcher Studio, 2017 \nFletcher Studio is a landscape architecture and urban design collaborative practice based in San Francisco, California. Fletcher Studio frequently uses parametric design software programs such ash such as Rhinoceros 3D, Grasshopper and Rhino script to test complex forms, \nfunctions, and site layout (Amoroso 2012). The Studio sought to reimagine San Francisco’s oldest public space (Figure 2) with a contemporary interpretation of the “picturesque style” landscape (CANTRELL & MEKIES 2018). The award-winning design transformed the site from an  English  strolling  garden  into  an  integrated  multi-purpose  communal  space  (FLETCHER 2021). \n\nAnalogue to Digital: The design intention sought to retain a hierarchy of circulation patterns, access points, social nodes, and existing trees and structures (CANTRELL & MEKIES 2018). “In the initial design phase, these decisions were made through an intuitive understanding of the parameters of the site and embedded in an analogue rule set that guided design decisions” \n(FLETCHER 2017). \n\nAnalogue rule sets require a considerable amount of testing time. “The same “idiosyncratic moments” that allow for the emergence of novel and intriguing design moves can also lead designers to overlook inconsistencies or flaws in their logic.” (FLETCHER 2017). By using a parametric  modelling  tool  in  the  Rhino  3D  software  program,  the  system  of  organization \ndeveloped in analogue (on paper), was translated into a Grasshopper digital script. The system  evaluated  “the  design  resiliency”  of  the  diagrammed  “tectonic  and  spatial  systems”(FLETCHER 2021). This enabled the designers to re-evaluate any flaws in their logic while also rapidly iterating upon the design in detail, without violating the previously established constraints of their design concept. \n\nTeaching Design Studio \nThe authors included kinaesthetic learning approaches in the phase of developing analogue rules associated with this studio. Kinaesthetic learning is a learning style in which individuals effectively “learn through doing”. Landscape architecture curricula historically include kinaesthetic learning approaches. Students increase understanding and testing of the products and  outcomes  of  design  exploration  by  touching  and  manipulating  them;  hence,  practical information is usually preferred over theoretical concepts. A kinesthetic learning experience can  aid  the  teaching  of  parametric  design;  one  can  read  about  it,  listen  to  instructions,  or watch videos of how to design parametrically – but deep learning occurs when one is physically involved with it. For their course, the instructors employed learning approaches including hand-sketching and model making to engage in an intuitive approach to design. These were “hands on” ways of exploring, developing and testing design concepts, aligning with the theme for a public art competition. \n\nCompetition Overview: The Winter Stations design competition is an open, single-stage, international design competition held annually in Toronto, Ontario. Guided by a provided theme, participants submit design proposals of temporary winter art installations incorporating the existing lifeguard towers situated along Toronto’s Woodbine Beach, on Lake Ontario. \nThe OneCanada project, informed under the competition’s provided theme of “Resiliency”, and designed and installed by six studio-course students, represents one of several submissions from artists and designers, worldwide, and was the only representation from landscape architecture, let alone an undergraduate student cohort. \n\nAnalogue to Digital  \nThe following phases characterize the study undertaken: \n\nPHASE 1: Developing Analogue Rule Set [Concept] \nStudents  were  asked  to  develop  a  concept  based  on  the  competition  theme  of  Resiliency. Their concept sought to interpret, appreciate, and promote the inspirational example of resilience of the Indigenous peoples of Canada, who continue to withstand adversity and persevere through generations of oppressive colonial policies. The concept also sought to bridge a gap between Indigenous and non-Indigenous peoples through an opportunity of “gathering” among the layering of the seven grandfather teachings (wisdom, love, respect, bravery, honesty, humility, and truth). The students envisioned the teachings to represent seven  white, \nand stacked circular forms, with a situational siting around a Woodbine Beach lifeguard station, representing the collective responsibility in the “guarding of life.” As an obvious beacon along the waterfront, art patrons, guests, and peoples from all backgrounds, could gather at \nthe  installation.  The  seven  teachings,  originating  with  the  Anishinaabeg,  and  have  been passed down from generation to generation ensuring the survival for all Indigenous peoples. \n\nPHASE 1: Developing Analogue Rule Set [Hand Sketching and Model Making]  \n\nBased on the initial concept, students generated ideas and imagined the form of the installation. Due to the lack of experience with 3D modeling software programs, students explored multiple design iterations through hand sketching and physical model making. As a result, the team developed analogue rule sets or design principles that guided design decisions: \n\n1.  Using circle as the prime form of installation. Circle is a sacred symbol of the interdependence of all forms of life in Indigenous culture (Stevenson 1999)  \n\n2.  Represent the seven grandfather teachings in minimum seven independent layers: wisdom, love, respect, bravery, honesty, humility, and truth. \n\n3.  Demonstrate unity in a sequence to symbolize bridging the gap between indigenous and non-indigenous people \n\n4.  Using a pattern to attach the separate layer which represents strengthening of relationships, and the protection of culture through the gathering and unity between people \n\nThese analogue rule sets, developed on paper and through model  making,  were translated into a parametric script using the Grasshopper plugin for the Rhino 3D software program.  \n\nPHASE 2: Developing Digital Ruleset [Parametric Script] \n\nWithout guiding the students through the complexity of learning algorithms or the coding behind the scripts, three algorithms or scripts developed in Grasshopper and were provided in a ready-to-use format to the students. The four (4) rule sets translated to ‘input parameters’ \nfollowed by multiple components in the Grasshopper plugin to rationalise the design process and to operationalise the principles. Using a ‘parametric lens’, the students could experiment, test, and generate design iterations and several design alternatives which allowed rule-based \nthree-dimensional platform to inform the decision making.  \n\nThe  final  iteration and  parametric  script,  for  the  competition  submission,  were determined from the various alternatives generated. \n\nPHASE 3: Digital Fabrication [Construction]  \nWith the rising presence of digital modeling in the field of landscape architecture, and accessibility to requisite equipment, digital fabrication has become a major facilitator in the development of research and design, in both professional practice and academia. As described by \nAndrew Madl “Professional design firms and universities providing use of digital fabrication in-house is becoming increasingly common. How to exploit such equipment is now taught in academic settings as skillset that is in line with traditional model making.” (MADL 2022). \n\nTeaching digital fabrication techniques requires significant amounts of time and resources. The intention of this phase was to develop a general introduction and awareness by providing a glimpse into the advantages of parametric design tools. \n\nFollowing the previous phases, students were required to prepare construction documentation or  “shop  drawings”  suitable  for  a  professional  fabricator.  Utilizing  computational  design tools developed in the previous phases, and through ongoing consultation with CNC fabrication  professionals,  students  learned  to  prepare  the  fabrication  files  and  facilitate  the  CNC cutting process. The goal was to encourage students to experiment with digital \nmodeling and file preparation, suitable to fabrication. \n\nFinally, the project’s implementation occurred through a team effort, ranging from detailed off-site work including material determination, metal welding, support strut wrapping, CNC-cut wood panel painting, transport, etc., to on-site assembly and construction. \n\nDiscussion \nIn the discourse of architectural fields, the term parametric design is associated with a particular attitude, aesthetic, and theory. Typically, one envisions the outcome as extraordinary and \nprovocative designs that inspire a set of  morphological principles (MADL 2022). The first perception of parametric design is limited to contorted formal expressions and the over-sophistication of geometry, which need to be deciphered. While this study emphasizes teaching \nthe  process  of  generating  complex  formal  expressions  for  a  public  art  installation,  the  research team addressed the potential of the method for future discoveries more specific to the field of landscape architecture. \n\nIn this course, some students gained the full understanding of the potential parametric design thinking offers at the end while a few had difficulties in developing a logic string of design steps that relate to the parametric approach, they preferred or felt back to intuitive or conventional  designing.  However,  the  later  group  was  interested  to  work  within  the  parametric framework if there is a team member managing the scripting part. This might inform an indication of the future of design so that the analogue embraces digital rather than introducing an absolute departure from analogue to digital. While parametric design offered a palette of \npossibilities, students got exposed to the realities of budget constraints and current limitations of digital fabrication, which eventually reduced the range of possibilities. \n\nRegardless of understanding the details behind the script, the “end product” and the process was well received by the students involved and has encouraged other students, privy to the course, to pursue “script” moving forward.  \n\nConclusion and Outlook \nImagined to provide interested students with an implicit understanding of the parametric process and to motivate them to create scripts unique to a project in future, this course enabled students to look outside the box, and even produce their own tool sets. Caroline Westort of Iowa State University explains that future landscape architects will not be only tool users but \nrather toolmakers. She indicates: “I actually think we do lose something by not training or teaching students the basic building blocks of what’s behind the black box, what’s behind the software . . . we are an information technology discipline, whether we like it or not.” (Bentley 2016). This indicates the need of training future resilient landscape architects, adept at creating script. \n\nParametric design can be difficult  for students  who  may  not have a strong background  in computer science or programming. It can also be time-consuming and challenging to learn and use these tools effectively, especially for those who are already comfortable with tradi-\ntional design approaches and intuition. Many designers will not engage at the high level of syntactical  knowledge  necessary  for  scripting  given  time  constraints  as  one  of  significant barriers. However, Grasshopper, Rhino, other GUI-based scripting allows designers to more readily connect the outcome of code with the formal representation without having to know how to write code (CANTRELL & MEKIES 2018). \n\nContemporary landscape architecture theory and practice necessitate the processing and design of data connected with complex systems in order to accurately reflect composite and emergent scenarios (MADL 2022). The field of landscape architecture, along with other design disciplines, are undoubtedly evolving through computational discovery.  \n\nLandscape architects and landscape architecture itself can respond to ever-evolving nature of practice and their resulting consequences. The outcomes of this design studio proved that parametric design permits a level of ambiguity, inquiry, discovery, confidence, and execution expected in creative and learning environments. \n\nBy training  future resilient landscape architects  with computational tools, universities and educational institutions can make a significant contribution in keeping pace with evolving principles. It is expected that these skilled professional practitioners and researchers will be \nintroduced to the community, adequately versed, and improve the model of practice-based research, which ultimately improves conventional and speculative design workflows. \n\nGeodesign as Online Teaching Method – Lessons from a Multiple Case Study \n\nAbstract: This study analyses the geodesign workshop as a method for the online teaching of group \nwork methods in the context of geoinformation systems (GIS) in planning and design. In order to assess the learning outcome, four workshops with international landscape architecture students at master level were conducted over a period of four years (2018-2021) and compared in a qualitative multiple-case study. In times of Covid-19 and the need for remote workshop methods, the geodesign workshops seem well suited for online learning and teaching. The results show that the learning goals were achieved, that new ideas were created and stakeholder expectations reflected and challenged. In individual cases, the lack of on-site knowledge led to mistakes though, and online group work had different group dynamics  than  in-person  negotiations.  Vocal  and  well-organised  students  seem  to  engage  even  more whereas quiet students more easily disengage, as seen in a bimodal distribution of participation grades in the online class. In conclusion, geodesign workshops may be recommended as an online method for teaching GIS and group work methods such as brainstorming, consensus building and stakeholder-role play but a hybrid format or new virtual field trip techniques are preferable when familiarizing students with the case study site. The teaching of group work methods as part of planning and design may be transferred from geodesign to teaching building information models, which is also an information-based digitally facilitated collaboration process. \n\nIntroduction \nGeodesign has been included in many university curricula around the world. The International Geodesign Collaboration (IGC) introduced a standardized geodesign process, which \nhas been conducted by hundreds of universities around the world. WARREN-KRETZSCHMAR \net al. (2016) already demonstrated the benefits of geodesign as a teaching method in planning \nand design classes. Building on their insights, this paper further explores whether geodesign \nis also a suitable method for the teaching of group work methods, and how geodesign classes \nadapted to online teaching during the Covid-19 pandemic.  \n\nIn  short,  STEINITZ  (2012)  defines  geodesign  as  planning  geography  through  design.  In  a \nlonger  definition,  FLAXMAN  (2010)  defines  geodesign  as  “a  design  and  planning  method \nwhich tightly couples the creation of a design proposal with impact simulations informed by \ngeographic context and systems thinking normally supported by digital technology.” Among \nother methods, geodesign utilizes the scenario  method (BISHOP et al. 2007), which is also \npart of many university programs. \n\nHence, a common misconception is that geodesign is only about technology. Although ge-\nodesign is characterised by the integrated use of GIS tools and geodata as the basis for an \ninformed  design  and  decision-making  process  (CAMPAGNA  2014),  it  is  generally  a  group \nwork process. In this context, several group work methods correspond well with the geodesign process. These are brainstorming, stakeholder role-play, and collaborative negotiation \nmethods.  \n\nBrainstorming is a method for the quick generation of ideas (JONES 1992). In the first step, \nparticipants have to write down as many ideas as possible during a limited amount of time. \nSince this step is about the creation of ideas, no weighting, discussion or filtering takes place \nyet. In a second step, the ideas are discussed in the group, clustered thematically and redundant or unsuitable ideas are sorted out. DOMINGO et al. (2021) demonstrate how brainstorming can also be applied in remote settings to facilitate collaborative work.  \n\nAt the same time, geodesign addresses complex multi-stakeholder planning and negotiation \nprocesses. PETTIT et al. (2019) suggest collaborative negotiations and consensus-building as \npart of the geodesign process. Starting with an even number of stakeholder groups, e. g., eight \ngroups with one planning proposal each, these groups meet with the closest other group, e. g., \ngovernment and business, and negotiate a consensus between their two proposals. Then, the \nremaining four proposals are narrowed down to two and the two to a final one. Because the \nprocess is mediated through digital means, PETTIT et al. (2020) also call it digital negotiations. \nThey conclude that such digital negotiations are an effective planning method. \n\nSuch processes embody underlying roles and often hidden agendas and conflicts. LIGTENBERG et al. (2010) used a role-playing approach in which students took on the roles of local \ncitizens, farmers and nature conservationists together with an agent-based model for simulating a multi-actor spatial planning process. In the IGC process, the role-playing approach \nlends  itself  to  have  students  represent  different  stakeholder  groups.  Common  stakeholder \ngroups are local citizens, local businesses, local government, youth organisations or environmental NGOs. Research goals are to assess whether:  \nLearning goals were achieved; \nThe quality of the results changes between online and in-person geodesign workshops; \nGeodesign workshops as learning and teaching method for group work are transferable to other programs at Master level. \n\nMethods: Multiple Case Study Comparison  \nThe research design is based on the multiple case study method (see 2.2.) by YIN (2014). The \ncontext for the workshops is kept consistent and comparable by following the recommendations and templates of the International Geodesign Collaboration IGC (see 2.2.): scale, group \nsize, underlying global assumptions, time-frame, and range of scenarios do not change across \nworkshops. The workshops are informed by open data from the EU Copernicus programme, \nOpenStreetMap  and  local  environmental  agencies  (2.3.)  All  workshops  use  geodesignhub \n(www.geodesignhub.com) as online platform to facilitate the process (2.4.). In the comparison, quantitative data such as average  grades for participation and outcome are compared \ntogether with qualitative observations, i. e., data triangulation in the words of YIN (2014). \n\nInternational Geodesign Collaboration IGC Template  \nORLAND & STEINITZ (2019) describe the International Geodesign Collaboration IGC, a col-\nlaborative  project of  more  than  120  universities,  research  institutions  and  public  \/  private stakeholders across the world. In order to facilitate research into geodesign, the collaboration organizes annual workshops and provides a template to make the diverse geodesign projects comparable.  The  IGC  template  (https:\/\/www.igc-geodesign.org\/presentation-formats)  provides the following:  \nCommon geodesign systems (water, green infrastructure, energy, transport, agriculture, \nindustry and commerce, institutional, residential and two flexible systems) and a common colour palette to easier identify and compare land use patterns and alternative design scenarios.  \nGlobal assumptions and a library of geodesign innovations, such as new renewable energy solutions, transport innovations etc., which IGC participants are encouraged to apply in their individual projects.  \nCommon scenarios and timeframes at 2035 and 2050, and paths to achieve scenarios for \nthose: “Early Adopters” initiate design interventions in 2020; “Late Adopters” in 2035; \nand “Non-Adopters” continue with business-as-usual.  \nTemplates for common reporting formats as presentations and posters. \n\nThe geodesign projects compared here dropped the 5km and added a spatial extent at 40km \nbut adhered to the IGC systems, innovations, common timeframes and poster templates.  \n\nMultiple Case Study Design  \nThe basic concept of  this  multiple case-study is  to conduct the  workshops as similarly  as \npossible by referring to the IGC standard templates for participating projects. The four workshops (see Tab. 1) were embedded in a GIS module in the second year of an international \nMaster´s degree in landscape architecture. Student backgrounds were very diverse, with students from different Bachelor´s degrees and more than 20 different nationalities. Working \nlanguage  was English. Each  workshop had one day of preparation plus individual student \nhomework and three days of the actual workshop. Results were documented on two A2 posters per workshop. \n\nGeodata-Based Process \nFor each workshop, suitability analyses were run ahead of the workshop in ArcGIS Pro and \nsummarized  in  so-called  evaluation  maps.  The  suitability  analyses  were  mainly  based  on \nopen geodata from the Urban Atlas, which are derived from Copernicus satellite data (European Union, Copernicus Land Monitoring Service, European Environment Agency (EEA)),map data from OpenStreetMap and protected areas provided by the Bayerisches Landesamt \nfür Umwelt LfU and the Geoportal Baden-Württemberg.  \n\nOnline Platform \nAll workshops were conducted through the online platform geodesignhub, which uses maps \nand  diagrams  to  facilitate  the  negotiation  process.  FLINT & STEINLAUF-MILLO  (2021)  describe geodesignhub as “an interactive design method that uses stakeholder input, real-time \nfeedback, geospatial modelling and impact simulations to facilitate the development of an \neffective management strategy and smart decisions.” By presenting two maps with individual \ndiagrams of projects and policies, and adding functions for filtering and visual comparison \n(Fig. 2), geodesignhub provides the tools to reach an informed consensus. \n\nCase Descriptions \nAll four workshops correspond with local planning topics, i. e., Munich Parkmiles is elaborating the open space concept of the City of Munich; Regional Garden Festival Stuttgart is \ncontributing  to  the  International  Building  Exhibition  Stuttgart,  Heidelberg  Green  Belt  responded to the invitation by the City of Heidelberg to develop ideas for a green belt and the \nlast project is contributing to the forthcoming IBA Munich. The four geodesign workshops, \npresented here, share the same learning goals:  \nAddressing a planning question at city to regional scale  \nApplication of GIS skills and demonstration of geodata capacity  \nDeveloping group work skills  \n\nCase Study 2018\/19: Munich Parkmiles \nIn a competition of ideas, 30 international students drafted the 2035 and 2050 scenarios in \nparallel working teams. Nevertheless, the results are surprisingly consistent. The common \nidea is that green infrastructure innovations are concentrated in the „Park Mile” green corridors. Housing is mainly accommodated in mixed-used zoning. For example, the 2050 early \nadopters’ scenario is presented in Figure 1, which extends the high-density mixed-use areas \nalong the  major public transport lines towards the city´s edge. In this case, the colours  in \ngeodesignhub indicate different types of zoning policies. The green spaces in between, including urban forestry in the south and valuable farm land in the northwest, are put under \nprotection  protected  from  further  development.  The  large  inner-city  yellow  policy  zone \nmarks low-density laneway housing in the otherwise high-density neighborhoods.  \n\nCase Study 2019\/20: Regional Garden Festival Stuttgart  \n\nGerman garden festivals have become a powerful driver for sustainable urban development. \nThe focus of the student proposals is on a positive impact on the climate. The approach in \nthe 2035 and 2050 scenarios complement each other progressively to implement policies on \nrenewable energy combined with blue and green infrastructure. Land use is planned strategically to mitigate urban sprawl, reduce the urban heat island effect, and increase rainwater \ncollection.  Housing  is  addressed  through  high-rise  developments  by  converting  redundant \nindustrial areas into mixed land use with a focus on bringing in a large “breathing” space in \nthe form of a park that Nürtingen does not currently have (see Fig. 2). Renewable energy \nprojects introduce solar farms, solar surfaces on highways, and policies that require residential and industrial zones to contribute local solar energy.  \n\nCase Study 2020\/21: Heidelberg Green Belt \nThe City of Heidelberg and its neighbouring cities, most importantly the City of Mannheim \nnorthwest of Heidelberg, have already launched a number of landscape development projects \nfor ecological restoration. At the time of this workshop, the city council had asked the planning department to develop ideas for a multi-functional “green belt” between Heidelberg and \nMannheim. Please note that the term “green belt” has been discussed controversially in different contexts. In the context of this project, the “green belt” is supposed to integrate ecological and physical landscape characteristics with multiple land uses (protected natural areas, agriculture, infrastructure, recreation...) in a multifunctional landscape.  \n\nFigure 3 is showing the early adopters' scheme for 2050 with green and blue infrastructure \ncorridors visible west of Heidelberg, i. e. along the area adjacent to the Mannheim urban area. \nIn addition to introducing new blue infrastructure, the students suggested links to the strong \nmedical sector in Heidelberg by introducing therapeutic gardens and other forms of restorative landscapes. Interestingly, the seemingly novel idea of creating new blue infrastructure \ncorresponded with a local proposal for an artificial lake.  \n\nCase Study 2021\/22: Munich International Building Exhibition \nSimilar to regional garden shows, the regularly held Internationale Bauausstellung (IBA) is \na key driver of national building and planning culture in Germany. It has played an important \nrole in cooperation, innovation, participation, experimentation, and visualization of 10 years \nof planning and design. Since Munich was awarded the next IBA on the topic of mobility, \nstudents were encouraged to envision a regional IBA providing new sustainable approaches \nto mobility landscapes. The City of Munich IBA team supported the workshop.  \n\nThe first day mainly focused on learning about the area of Munich and analysing where pos-\nsible improvements could be made based on suggested systems such as: transport infrastruc-\nture, industry and commerce, mixed residential, tourism, blue and green infrastructure, en-\nergy infrastructure, climate, and agriculture. One key instrument was the further development \nof the “park miles”, seen in green Figure 4, which had already been addressed in the first \nworkshop by a different group of students.  \n\nCross-Case Comparison \nIn all four cases, the students achieved the learning goals. Comparing the four cases, there \nare commonalities but also differences between the in-person and the online settings:  \n\nStatistical Comparison \n\nThe students received grades for 1) participation in the workshops and 2) the quality of the \noutcome, i. e., the content of the resulting scenarios and their presentation on the posters. \nStudent numbers were supposed to be around 30, but actually varied between 23 and 36 depending on factors out of our control such as visa issues or Covid-19.  \n\nA simple descriptive analysis of the average mean grades across the four workshops is presented in Table 2. In general, grades are rather good (with 1.0 the best possible grade). The \nbest participation was recorded during the first in-person workshop in 2018\/19, whereas the \nsecond online workshop in 2021\/22 had the poorest participation. If you look closer at the \ngrades, participation in the last workshop shows a trend towards a bipolar distribution: quite \na few students participated very well in the online workshop, but in contrast, a large number \nof students participated poorly or dropped out. \n\nCross-Case Observations \nIn both the in-person and online settings, large numbers of diagrams were created, and both \nsettings led to comparable results in terms of quantity and diversity. With regard to the IGC \nframework, three scenarios were derived from the diagrams: early adopters, late adopters, \nand non-adopters. The geodesign process of narrowing down the scenarios to a smaller number of consensus scenarios also succeeded in both settings. For teaching purposes, the scenario process was combined with exercises in negotiation and students “role-played” different stakeholder groups, such as young people, government, business representatives or environmental NGOs. Some students fully embodied their roles and took on a new perspective, \nleading to interesting discussions, such as proposing affordable housing versus the provision \nof additional green space.  \n\nThe online platform geodesignhub facilitated the documentation of the process in both settings, online and in-person. Especially in a teaching environment, it is of great help for the \nteacher during assessment and grading that all ideas and the scenario building process are \narchived in geodesignhub.  \n\nDifferences between In-person and Online Settings  \nThe online setting can facilitate a broader geographical range of case study topics and locations, although it seemed to come at the costs of sometimes lacking understanding of the site. \nOne group was obviously not aware of local characteristics and depicted high-rises, which \nwere completely out of context.  \n\nIn  terms  of  organisation,  the  online  workshop  made  it  easier  for  international  students  to discuss with local stakeholders than organising such a session in person. Like an in-person setting, the online discussion inspired both groups, students and local stakeholders. \n\nHowever, the grading showed a lower grade in participation, particularly for the last work-\nshop. From observation, more vocal students tended to engage even more in the online set-\nting, whereas it was much harder than in-person to motivate quiet or disengaged students. \nNevertheless, the online setting was a suitable remote learning tool during Covid-19 times, \nand the geodesign workshop method proved to be well suited for online teaching.  \n\nConclusion and Outlook \n\nIn conclusion, the learning goals were achieved. Therefore, geodesign workshops are generally recommended for teaching group work methods such as brainstorming, consensus building, and stakeholder-roleplay in GIS-based planning and design. In times of Covid-19 and \nthe need for remote workshop methods, the geodesign workshops were also well-suited for \nonline learning and teaching although participation was slightly lower during the online sessions. These observations are consistent, though, with other classes that were taught online \nduring Covid-19 and could point to a certain online “fatigue”.  \n\nRegarding the quality of results, the online setting  might come at the cost of the students \nfamiliarizing themselves with the case study area. It is recommended to further develop hybrid  settings,  e. g.,  collaborations  with  local  experts  or  the  development  of  remote  or  VR enabled field trip techniques to facilitate a better understanding of the site (HASBROUK & \nSTEPNOSKI 2022).  \n\nFindings and group teaching methods from this multiple case study could be transferred to \nteaching Building Information Modeling BIM. Like geodesign, BIM is a collaborative process rather than a software. In a BIM class, the role-play could simulate the different stakeholders in a BIM process, from surveyor to architect and client, and the BIM model may be used to facilitate negotiations among these stakeholders. \n\nFor future geodesign research, it is suggested to focus further on the evaluation of scenarios. \nPeer review through the students themselves might contribute to the learning and teaching \nprocess. In addition, GIS-based or even artificial intelligence (AI) based methods might facilitate new learning and teaching methods by providing real-time quantitative and qualitative \nfeedback. It will have to be seen how the geodesign process is further developing and which \nrole, if any, AI will play in it.  \n\n“Open Access” Climate Resilience Tools for Landscape Architects  \n\nAbstract: The devastating effects of climate change we are witnessing, such as the floods throughout Germany in 2022, are placing more pressure on designers to predict and mitigate such events while designing various sites. Greenskinslab’s researchers at the University of British Columbia, Canada have \nspent many years developing digital tools to predict, mitigate and provide design suggestions on how to manage increasing human risk to natural hazards, focusing particularly on flooding and more recently landslides. These globally “open access” and user-friendly digital tools support both students and professionals in the early site planning and design phase of projects to calculate the risks of landslides and flooding.  This  article  briefly  highlights  two  “open  access”  climate  resilience  tools.  These  are:  1)  a stormwater calculation (LID) application that dimensions the correct LID strategies (living roof, retention pond, swale) needed as a holistic system to manage rainwater on new and existing sites, published in  2021,  and  2)  a  landslide  susceptibility  toolkit  for  landscape  architects  comprised  of  a  GIS-based \nanalysis tutorial and multi-sensorial on-site analysis instructions, developed in 2022 by a multi-disciplinary UBC student team. These tools are based on computer software which is widely accessible and affordable and analog methods of investigation. Greenskinslab’s mandate is to combat climate change \nby supporting designers’ planning processes with digital and analog tools to assist them to better envision a more climate resilient future. \n\nIntroduction \nThe global Covid 19 pandemic in early 2020 initiated academia to learn digital communication and teaching tools at lightning speed to continue teaching at a satisfactory standard in landscape architectural programs around the world. Suddenly instructors had to depend on computers to deliver lectures and provide design reviews, demonstrating to academics and students the potential of online communication software. In my case it confirmed the teaching effectiveness to include instantly recorded ‘digital’ hand drawn three-dimensional visualizations in teaching. It confirmed how versatile and fast the tablet is in recording how environmental holistic systems functioned, in landscape architectural design. Additionally, it allowed \nfor animations of diagrams and audio explanations of the process shown. \n\nThis online teaching experience led to two areas of research focus: 1) to include the tablet \nand smart phone as observation and recoding tools when teaching my multisensory landscape \ndesign method, described in my second book: Multisensory Landscape Design: A Designer’s \nGuide for Seeing, (2022), and 2) in creating “open access” climate resilience tools in my lab \nto mitigate or predict global destructive climate change effects such as floods and landslides. \nThese tools are partially based on the research of my first co-authored book: Living Roofs in \nIntegrated Urban Water Systems (2015). The book describes the effective combination of \nLID tools (retention pond and swales) at grade with living roofs to manage urban flooding. \n\nIn order to manage the ongoing impacts of climate change, evidenced through the deadly \n2021 heat dome in British Columbia, the floods and landslides in British Columbia later the \nsame year and the ‘biblical’ Flood in Pakistan in 2022, I propose to increase applied on site \nquantitative and qualitative research to mitigate current climate change effects in landscape \narchitecture. Extensive research is currently being carried out to determine climate change \npredictions and how to manage the postulated effects. However, we are already witnessing \nan increasing magnitude and frequency of natural hazards due to climate change that is causing devastating impacts. Therefore, landscape architects and researchers should contribute \nmore to mitigate current climate change effects through their work. I propose “open access” \ntools for landscape architects to enhance their site analysis investigation and design process. \nThese tools help determine potential risk in the landscape (i. e. landslides) prior to development of a site, or measure the size and suggest LID interventions needed to mitigate future \nfloods in the preliminary design phase. These analysis and preliminary design calculations \nwill strengthen the initial design proposal and contribute to climate resilience in the planning \nprocess of landscape architectural design. Two “open access” tools created in Greenskinslab \nare presented here. It is anticipated that these tools increase professional analysis and design \npractice, and should also be incorporated into landscape architecture design education. “Open \naccess” tools enhance design teaching. \n\n“Open Access” Tools \nThe more tools are available online, the higher are the opportunities they are used. At Green-skinslab they are developed by a team comprised of both students and alumni that are inter-\nested in focused research opportunities against climate change. The inclusion of alumni provides them with an opportunity to integrate their professional office experience into the creation of the tools they are interested in to refine and use for their design process. The tools \nare created firstly for British Columbia’s local use and then expanded for global use (This \nwas also done because of the extensive data available online in BC on precipitation, soil types \netc.). For all the tools created, the premise was to be able to use affordable and easily available \nhard- and software, to allow access and use in regions with limited resources. The tools are \nuser-friendly and self-explanatory in layout and operation and accessible to students and professionals. An overarching goal is to encourage the next generation of landscape architects \nto co-lead ideas and research tools, to empower them to design for society and the environment in a climate resilient impactful way. In recent years digital visualization of designs in \nlandscape architecture schools has experienced a boost and focused often on learning sophisticated three-dimensional rendering tools. These renderings and video animations created a \nmore and more realistic spatial design narrative. The open access tools presented are enabling \nadditional  design  rigour  to  advance  the  technical  and  scientific  skills  to  combat  climate \nchange on site. They include digital and analog components. \n\nThe landslide tool uses user-friendly (free trial) ArcGIS software and access free data from \nCopernicus Access Open Hub, LiDAR BC, and Fresh Atlas Stream Network BC to locate \nmass movement areas at a map scale determined by the grid size. In a second field investigation phase, ‘multisensory’ applications (sight, touch, smell) are used to investigate the land \nform, geological processes, soil profile, texture, geological processes, hydrological characteristics and vegetation. The students and practitioners are instructed through a field guide \nposted on the blog how to examine the site. This tool allows landscape architects, architects \nand urban planners to develop a deeper understanding and awareness of mass movements \nphenomena, and eventually prevent these hazards on site and around it. It is an additional site \ninvestigation tool in the preliminary design phase to reduce the risks of destruction due to \nclimate change. \n\nThe stormwater calculation (Low Impact Development LID) application focuses on estimating the size and types of LID tools needed to manage stormwater on site of a new development. “Water drives design” was the strategy in mind when designing it (1). When designing a new site, the LID application uses the current local climate data (supplied by the airports close to future design project), to calculate the LID tool dimensions and types needed.  \n\nThis application has been created for the preliminary design phase of a project to enhance \nclimate resilience strategies such as stormwater management on site. This tool can also be \nused to design and dimension LID strategies in existing blocks of cities (2). \n\nBoth tools attempt to inspire and lay a foundation for other researchers to develop open access \ntools with their students and alumni for their area of expertise. Landscape architecture is a \nland-based profession, the design impact is “outside” in the environment, landscape architecture designs are exposed and constantly changing. More ‘applied research’ should be carried \nout in design school, to increase evidence-based designing with quantitative and qualitative \ndata. Landscape architects have a responsibility to design all projects with climate resiliency \nin mind today.  \n\nConclusion \nI believe that multidisciplinary applied research contributions such as the open access tool \nexamples above can support climate change resilience effectively. They can be adapted to \nlocal needs and expertise. Not only such tools are, in most cases, easily adaptable to local \nneeds and expertise, they can often be used immediately by the public, rather than depending \non time-consuming grant funding process. In the instances where funding is necessary, the \nstudents involved in the projects may subsequently support them as alumni.  \n\nI also suggest further that all landscape architecture students should learn basic ‘coding’, best \napplied directly in a research project or class exercises which involves the creation of a small \napplication which can be used in landscape architecture, for example a cut and fill calculator \nfor grading (3). This applied teaching will encourage and inspire the next generation (students \nand graduates) to co-lead ideas to implementation, and empower them to act for their future. \nStudents need to be provided a research platform to experiment and shape the environmental \nfuture.  Landscape  architecture  students  are  often  thinking  idealistic  in  “saving  the  world” \nthrough  designing.  This  positive  energy  should  be  channeled  into  the  “shaping”  or  land \nscapeing − the environment with more applied research driven projects and tools, helping \nothers. \n\nUncovering the Visibility of Blue Spaces: Design-oriented Methods for Analysing Water Elements and Maximizing Their Potential \n\nAbstract:  Existing  studies  indicate  that  a  direct  view  of  aquatic  elements  benefits  well-being,  and \nhouses  with  blue  views  are  often  associated  with  higher  prices.  Therefore,  developing  analysis  and \ndesign  methods  for  visibility  research  of  blue  spaces  are  crucial  to  advance  spatial  design  practice. \nEspecially  digital  methods  for  analysing  blue  visibility  and their potential  in design  still need  to be \nidentified and explored. This study explores the application potential of some powerful digital visibility \nanalysis methods for blue space design. Specifically, this research first provides an overview of poten-\ntial methods for analysing the visibility of water. Next, two practical design-oriented digital methods \nare briefly elaborated and illustrated by cases in Rotterdam (the Netherlands). Meanwhile, the study \nexplores how the analysis results support spatial design practice. Last, the study discusses the potential \nof integrating blue visibility analysis methods into the iterative design process and makes prospects for \nfuture research. \n\nIntroduction \nWith the prevalence of chronic lifestyle-related diseases and rapid urbanization, health issues \nhave received increasing attention. The health benefits of natural environments as a practical \nsolution to current health issues have been widely recognized, especially for green spaces. \nRecently, the health benefits of blue spaces have been identified, and many studies suggest that a direct view of aquatic elements (e. g. rivers, lakes, and oceans) benefits psychophysiological states and reduces stress (GRELLIER et al. 2017, HARTIG et al. 2014, ZHANG et al. 2022). Houses with blue views are associated with higher attractiveness and price (QIANG et al. 2019). Therefore, it is necessary to consider blue visibility in spatial planning or design process of urban environments, which could provide multiple benefits. On the other hand, current studies  mainly  focus  on  combining  blue  visibility  with  health  data  to  explore  the  relationship between them for developing health evidence. However, only limited studies focus on integrating this health evidence into practical spatial design or policymaking, especially in guiding the design processes, which could be regarded as a huge vacuum in the existing research \n(ZHANG et al. 2022). \n\nKnowledge\/evidence-based design approach and design research provide a solid foundation and  potential  for  filling  this  vacuum,  as  well  as  extend  scientific  understanding  of  design processes that were previously regarded as a black box (JONES 1992, OZTURK 2020). Specifically, spatial design is a core activity in landscape architecture and its related disciplines to provide solutions for urban or rural areas to achieve desired social, cultural, and ecological outcomes (NIJHUIS & DE VRIES 2019). According to the ASE paradigm, design could be regarded as an integrative practice consisting of three interrelated phases: analysis, synthesis, and evaluation. In these three phases, blue visibility analysis methods could be applied to the analysis and evaluation phases to identify site limitations and potentials of design proposals, as well as provide solid support for assisting designers in the synthesis phase. For designers, the integration and utilizing of these methods, especially innovative digital ones, have greatly aided the spatial design practice (LIU & NIJHUIS 2020a). In other words, these methods can \nhelp translate and apply research evidence in the design practice. However, only a limited \nnumber of studies have offered some available methods or tools to analyse the visibility of \nblue spaces and explore their design potential (LIU & NIJHUIS 2020b, NIJHUIS, 2011). To sum \nup, there is a need to identify practical digital visibility analysis methods that support design \nresearch and design for the development of effective blue spaces in the urban environment. \n\nThis paper aims first to provide an overview of potential methods for analysing the visibility \nof water from a design perspective. Also, two practical design-oriented digital methods are \nbriefly elaborated and illustrated by cases in Rotterdam (the Netherlands). The paper ends \nwith a discussion on the potential of integrating blue visibility analysis methods into the iterative design process and provides an outlook for future research. \n\nMethods \nDigital Methods for Analysing Blue Space Visibility \nReviewing the current research and practice on landscape visibility, there are six representative practical  methods suitable for analyzing blue  visibility, including the statistical  index \napproach, (Cumulative) viewshed analysis, (3D) Isovist analysis, segmentation analysis, eye-\ntracking analysis, and 3D landscape analysis (HELBICH et al. 2019, KIM et al. 2019, LIU & \nNIJHUIS 2020b, NIJHUIS 2015, PALMER 2022a and 2022b, PUSPITASARI & KWON 2020). Spe-\ncifically, the statistical index analysis uses alternative indicators, such as the number, total\/ \nmean area, or density, to measure blue visibility. It is mainly applied in spatial design projects \nat the regional scale and contains the advantage of simple and rapid calculation. (Cumulative) \nviewshed analysis adopts the continuous digital landscape model to calculate and visualize \nthe surfaces that are visible to specific observer features. Since it is integrated into GIS software, it could be applied in regional\/intermediate projects where computing power is sufficient. Due to the input data and used analysing tools, the way in which the above two methods \nare  integrated into the design process to assist design decisions is to allow comparison  of \nchanges pre\/post spatial design interventions. On the other hand, (3D) isovist analysis shares \na similar calculation logic with viewshed analysis, while the precision and ease of modelling \nallow it to be applied to projects at the individual scale by simulating blue visibility changes \nduring people’s movements. Segmentation analysis and eye-tracking analysis both borrow \nthe theory or techniques from computer vision to describe the visibility of blue space at the \nindividual scale through the analysis of characteristics in specific scenes quantitatively. The \neye-tracking analysis attempts to describe people’s perception of blue  spaces  more objectively by measuring observers’ eye movements and associating them with spatial characteristics. Last, 3D landscape analysis is widely used in designers’ daily practice to identify the characteristics  of  specific  spatial  arrangements  using  2\/3D  visualisations  (LIU  &  NIJHUIS 2020b). Unlike the two blue visibility analysis methods at the regional scale, the four methods at intermediate\/individual scales, when integrated into the design process, allow rapid simu-\nlation of the post-intervention scenario to help designers test and visualize different design intentions. Table 1 lists the existing blue visibility analysis methods with detailed information.  \n\nAfter reviewing the methods, it is important to assess their potential for integration into the \ndesign process and to select the representative and novel ones to demonstrate their application. There are four criteria to identify their potential in the design process. Specifically, the \nmethods should first allow implementation in designer-friendly software. Most of the methods listed could be integrated and run in existing and easy-learning software environments, \nincluding GIS, Rhino, SketchUp, Photoshop, and Excel. Only the segmentation analysis needs \nto  be  run  in  Python  directly  via  existing  deep-learning  packages  and  pre-training  models, \nwhich  may  be  unfamiliar  to  designers.  Therefore,  it  is  worth  showing  its  application  and \ndiscussing its design potential in this study. Second, the methods should be adaptive to the \ninput data with multiple precision and sources. Since eye-tracking analysis relies heavily on \nuser participation, the requirements for input data are relatively strict. In other words, it describes blue visibility subjectively from a non-designer’s point of view and therefore is not \nincluded in this study. Third, the method should understand the eye-level visibility of blue \nspaces since it is closely related to spatial design rather than planning and is currently receiving growing attention. Accordingly, the intermediate\/individual-level methods are selected, \nas the regional scale methods are closely related to landscape planning. Last, the methods \nneed to be integrated into design iterations, allowing quick changes to represent and test designers’ new ideas. Thus, the scenario-based methods indicated in the last column of Table 1 will  be  chosen.  Based  on  the  above  criteria  and  the  novelty  of  the  methods,  (3D)  Isovist analysis  and  segmentation  analysis  are  chosen  in  this  research  for  investigation,  and  their \ndesign possibilities are examined. \n\nStudy Area and Materials \nTo show the application of the two selected methods, a part of the Rotte River in Rotterdam \nis used as the study site. There are three reasons for choosing the Rotte River as the \ncase. First, the Rote River is located in Rotterdam, the second largest city in the Netherlands, \nwhich is rich in blue space resources. Rotterdam’s urban living is closely related to the water, \nand blue visibility plays an important role in the spatial design of the urban environments. \nSecond, the Rotte River used to be a major transport artery of the city in the past, and industrial products and vegetables were taken to the markets and auctions via it. Nowadays, the \nRotte River has been transformed into a public space which is closely related to the daily life \nof the public and provides multiple benefits. Last, as an essential urban river in Rotterdam, \ndata availability and physical accessibility (i. e. field survey) helped to evaluate and refine \nthe results of method applications. \n\nAs mentioned above, two methods for analyzing blue visibility are used to show their appli-\ncations and explore their design potential. Considering that each method has its unique char-\nacteristics, Table 2 lists the details of the tools and data required for the two methods. \n\nResults \nThree situations are presented to illustrate the application of the two methods and the design \npotential of their analysis results. Specifically, route-based visibility analysis adopts the 3D \nIsovist analysis method to calculate the visibility of water bodies under people’s movements. \nBuilding-based visibility analysis also adopts the 3D Isovist analysis method, taking the building as the analysis object to calculate the visible proportion of blue space in different areas of \nthe building surface. Moreover, the segmentation analysis method is incorporated into scene-\nbased visibility analysis to obtain the visual features of typical scenes in selected area. \n\nSituation 1: Route-based Visibility Analysis \n3D Isovist analysis is used in route-based visibility analysis via Rhino-Grasshopper environ-\nment to calculate the water visibility of people alongside the specific route (Fig. 2). The process consists of the following steps: (a) divide the selected route into several parts; (b) generate original view sphere based on horizontal and vertical FOV (field of view); (c) construct \nand compute the Isovist Rays by setting the obstacles and analyzing radius; (d) calculate the \nproportion of Isovist Rays contacting the water surfaces for each part of the route; € visualize \nthe  analyzing  results  into  chart  diagrams.  Three  transportation  modes,  including  walking, \njogging, and cycling, and two directions, including North-South and South-North, are conducted in the calculation, and detailed analysis parameters are shown in Table 3.  On the other hand, during the movements on the selected route, the overall patterns of blue visibility among the three transportation modes are similar, especially for jogging and cycling. This could be due to the lack of clear route classification and design between the different transportation modes in the study area. Accordingly, the analysis can be applied to the planning and design of different routes by simulating the people’s blue visibility of different traffic behaviours, such as the blue visibility of cycling routes at intersections could be lower to prevent distraction. \n\nSituation 2: Building-based Visibility Analysis \nBuilding-based  visibility  analysis  also  conducts  3D  Isovist  analysis  to  calculate  the  water \nvisibility of building surfaces located near the Rotte River (Fig. 4). The analysis process consists of the following steps: (a) divide the building surfaces into the small matrix; (b) set the \ncenter point of each small cell as the input for 3D Isovist analysis; (c) conduct the 3D Isovist \nanalysis as mentioned above; (d) calculate the proportion of visible water bodies in each cell \nof building surfaces; € visualize the results on buildings in an interactive way; (f) calculate \nmean blue visibility of each building and visualize it on map (optional). Detailed parameters \nfor analysis are shown in Table 4. \n\nThe left graph of Figure 4 presents the analysis results directly on building surfaces, where \nthe surfaces with blue-side colours indicate higher blue visibility. In comparison, the surface \nwith red-side colours shows lower blue visibility. Even for the same building, the outcome \ninteractively  represents  the  varying  degrees  of  blue  visibility  at  different  points.  The blue \nvisibility of two adjacent rooms can be varied, which may lead to completely different con-\nsequences, as ULRICH’s (1984) famous experiment demonstrated that a ward with a natural \nview could have a positive influence on the recovery of the patients living in it. The result \ncan help designers in architecture or vegetation design, in adjusting the layout of buildings \nor vegetation and repositioning the building windows or vegetation to increase blue visibility. \n\nOn the other hand, the analysis results could provide evidence for planning and policy-mak-\ning on the intermediate scale. Specifically, the study further calculated the average blue visibility of each building surface cell and visualized the results on the map. The results show \nthat the middle three buildings have higher blue visibility, which provides the potential for \nevaluating  the  differences  in  blue  visibility  among  several  buildings  (Fig.  4  [right]).  This \nresearch merely uses a few riverside buildings for testing. In the future, the analysis can be \nextended to the buildings within a specific area to support the planning of neighbourhood \nspatial layout and strategies for pricing housing units. \n\nSituation 3: Scene-based Visibility Analysis \nThe machine learning-based segmentation analysis method is used in scene-based visibility \nanalysis. Following the procedures in  HELBICH et al.’s (2019) research, the fully convolutional neural network for semantic segmentation (FCN-8s) model is trained by the ADE20K \nscene parsing and segmentation databases. A total of 208 photos taken based on the on-site \ninvestigation were used as input images for segmentation (Fig. 5). Next, the number of elements in scenes and the ratio of different element groups to total pixels are calculated. \n\nOn the other hand, the statistical analysis of the segmentation results can quantitatively describe the landscape element characteristics in scenes. The three graphs in the first row of \nFigure 7 demonstrate the distribution of the number of elements in each scene and the average \nproportion of area occupied by the main landscape element groups in all scenes. The number \nof elements in the current scenes is concentrated in 20-30, and the number of elements whose \nfield of view accounts for more than 5% is concentrated in 6-9. Vegetation, water, and sky \nare the main landscape element groups, while facilities only occupy a limited proportion. The \nthree graphs in the second row of Figure 7 compare the element characteristics of typical \nscenes among three sections of the river. From the results on the number of elements, the \nvalue in section 3 is higher than the other two sections, showing that it has relatively high \nvisual complexity. The value of section 1 is more concentrated and less distributed in large \nvalues, demonstrating that its visual complexity is stable and relatively easy to understand. \nHowever, the value of section 2 presents more scattered patterns than the others, indicating \nthat people’s visual perception changes in this section are more significant. In addition, according to the results on the proportion of main landscape element groups, it is obvious that \nthe proportion of vegetation in scenes of section 2 is less than in the other two sections, and \nthe proportion of buildings is higher. More buildings in scenes could also prove that the visual \nperception of this section is dynamic and varied. Accordingly, segmentation analysis could \nbe regarded as a powerful tool for designers to describe the landscape elements and the spatial-visual characteristics in design. Visual complexity, openness, naturalness and other indicators calculated by segmentation results can provide quantitative evidence for designers to \ncompare different design schemes or intentions and then make final decisions. \n\nDiscussion and Conclusion \n\nAs exemplified by the presented applications, three situations of using two methods not only \nhelp to get a grip on the different characteristics of blue visibility of Rotter River, but also \nexplore the possibilities in assisting multi-scale spatial design to improve it. In other words, \ntwo practical and design-oriented digital methods, including (3D) Isovist analysis and seg-\nmentation analysis, could facilitate a comprehensive understanding of the site’s restrictions, \nlimitations, and potentials on blue visibility, and provide clues for future design interventions. \nOn the other hand, these methods are complementary and can be combined together in some \ncircumstances.  For  instance,  segmentation  analysis  could  also  be  applied  in  situation  1  to \noffer an understanding of various landscape elements and their organizations during movements beyond the Isovist analysis only focusing on water bodies. \n\nThis  study  does  not  provide  the  complete  process  of  applying  the  two  methods  to  spatial \ndesign, but only shows the possibility of their design potential in a highly simplified form \nthrough three application situations. However, based on the ASE paradigm of design pro-\ncesses mentioned in section 1, it is evident that they could be parts of the design iterations, \nincluding analysis, synthesis (design), and evaluation (Figure 8). Here, designers could use \nthem to analyze and understand the existing situation, test and evaluate ideas or intentions, \nand compare different options to make final decisions. \n\nNowadays, with the advancement of technology, digital methods and tools are being widely \ninvestigated and introduced into spatial design practices, greatly expanding the toolbox of \ndesigners. The two methods presented in this study could serve as an inspiration to encourage \nexploration of the potential of multi-disciplinary methods to be incorporated into design processes. However, the traditional means (e. g. sketches or models) cannot be overlooked and \nshould be combined with the digital methods to achieve design objectives better and improve \nthe development of the knowledge\/evidence-based design approach. In addition, this study \nhas several limitations. First, this study cannot include all possible methods and only provides \nlimited applications to inspire future research. Second, the landscape is dynamic and greatly \naffected  by  time  or  season,  especially  for  water  bodies  and  vegetation.  People  may  have \ngreater blue visibility in winter since the leaves are gone. Last, the data acquisition or precisions, quantity of site photos, processing power or time, etc, may influence the results. Future \nresearch  can  optimize  these  factors  to  improve  the  effectiveness  and  practicability  of  the \nmethods. \n

“Open Access” Climate Resilience Tools for Landscape Architects  \n\nAbstract: The devastating effects of climate change we are witnessing, such as the floods throughout Germany in 2022, are placing more pressure on designers to predict and mitigate such events while designing various sites. Greenskinslab’s researchers at the University of British Columbia, Canada have \nspent many years developing digital tools to predict, mitigate and provide design suggestions on how to manage increasing human risk to natural hazards, focusing particularly on flooding and more recently landslides. These globally “open access” and user-friendly digital tools support both students and professionals in the early site planning and design phase of projects to calculate the risks of landslides and flooding.  This  article  briefly  highlights  two  “open  access”  climate  resilience  tools.  These  are:  1)  a stormwater calculation (LID) application that dimensions the correct LID strategies (living roof, retention pond, swale) needed as a holistic system to manage rainwater on new and existing sites, published in  2021,  and  2)  a  landslide  susceptibility  toolkit  for  landscape  architects  comprised  of  a  GIS-based \nanalysis tutorial and multi-sensorial on-site analysis instructions, developed in 2022 by a multi-disciplinary UBC student team. These tools are based on computer software which is widely accessible and affordable and analog methods of investigation. Greenskinslab’s mandate is to combat climate change \nby supporting designers’ planning processes with digital and analog tools to assist them to better envision a more climate resilient future. \n\nIntroduction \nThe global Covid 19 pandemic in early 2020 initiated academia to learn digital communication and teaching tools at lightning speed to continue teaching at a satisfactory standard in landscape architectural programs around the world. Suddenly instructors had to depend on computers to deliver lectures and provide design reviews, demonstrating to academics and students the potential of online communication software. In my case it confirmed the teaching effectiveness to include instantly recorded ‘digital’ hand drawn three-dimensional visualizations in teaching. It confirmed how versatile and fast the tablet is in recording how environmental holistic systems functioned, in landscape architectural design. Additionally, it allowed \nfor animations of diagrams and audio explanations of the process shown. \n\nThis online teaching experience led to two areas of research focus: 1) to include the tablet \nand smart phone as observation and recoding tools when teaching my multisensory landscape \ndesign method, described in my second book: Multisensory Landscape Design: A Designer’s \nGuide for Seeing, (2022), and 2) in creating “open access” climate resilience tools in my lab \nto mitigate or predict global destructive climate change effects such as floods and landslides. \nThese tools are partially based on the research of my first co-authored book: Living Roofs in \nIntegrated Urban Water Systems (2015). The book describes the effective combination of \nLID tools (retention pond and swales) at grade with living roofs to manage urban flooding. \n\nIn order to manage the ongoing impacts of climate change, evidenced through the deadly \n2021 heat dome in British Columbia, the floods and landslides in British Columbia later the \nsame year and the ‘biblical’ Flood in Pakistan in 2022, I propose to increase applied on site \nquantitative and qualitative research to mitigate current climate change effects in landscape \narchitecture. Extensive research is currently being carried out to determine climate change \npredictions and how to manage the postulated effects. However, we are already witnessing \nan increasing magnitude and frequency of natural hazards due to climate change that is causing devastating impacts. Therefore, landscape architects and researchers should contribute \nmore to mitigate current climate change effects through their work. I propose “open access” \ntools for landscape architects to enhance their site analysis investigation and design process. \nThese tools help determine potential risk in the landscape (i. e. landslides) prior to development of a site, or measure the size and suggest LID interventions needed to mitigate future \nfloods in the preliminary design phase. These analysis and preliminary design calculations \nwill strengthen the initial design proposal and contribute to climate resilience in the planning \nprocess of landscape architectural design. Two “open access” tools created in Greenskinslab \nare presented here. It is anticipated that these tools increase professional analysis and design \npractice, and should also be incorporated into landscape architecture design education. “Open \naccess” tools enhance design teaching. \n\n“Open Access” Tools \nThe more tools are available online, the higher are the opportunities they are used. At Green-skinslab they are developed by a team comprised of both students and alumni that are inter-\nested in focused research opportunities against climate change. The inclusion of alumni provides them with an opportunity to integrate their professional office experience into the creation of the tools they are interested in to refine and use for their design process. The tools \nare created firstly for British Columbia’s local use and then expanded for global use (This \nwas also done because of the extensive data available online in BC on precipitation, soil types \netc.). For all the tools created, the premise was to be able to use affordable and easily available \nhard- and software, to allow access and use in regions with limited resources. The tools are \nuser-friendly and self-explanatory in layout and operation and accessible to students and professionals. An overarching goal is to encourage the next generation of landscape architects \nto co-lead ideas and research tools, to empower them to design for society and the environment in a climate resilient impactful way. In recent years digital visualization of designs in \nlandscape architecture schools has experienced a boost and focused often on learning sophisticated three-dimensional rendering tools. These renderings and video animations created a \nmore and more realistic spatial design narrative. The open access tools presented are enabling \nadditional  design  rigour  to  advance  the  technical  and  scientific  skills  to  combat  climate \nchange on site. They include digital and analog components. \n\nThe landslide tool uses user-friendly (free trial) ArcGIS software and access free data from \nCopernicus Access Open Hub, LiDAR BC, and Fresh Atlas Stream Network BC to locate \nmass movement areas at a map scale determined by the grid size. In a second field investigation phase, ‘multisensory’ applications (sight, touch, smell) are used to investigate the land \nform, geological processes, soil profile, texture, geological processes, hydrological characteristics and vegetation. The students and practitioners are instructed through a field guide \nposted on the blog how to examine the site. This tool allows landscape architects, architects \nand urban planners to develop a deeper understanding and awareness of mass movements \nphenomena, and eventually prevent these hazards on site and around it. It is an additional site \ninvestigation tool in the preliminary design phase to reduce the risks of destruction due to \nclimate change. \n\nThe stormwater calculation (Low Impact Development LID) application focuses on estimating the size and types of LID tools needed to manage stormwater on site of a new development. “Water drives design” was the strategy in mind when designing it (1). When designing a new site, the LID application uses the current local climate data (supplied by the airports close to future design project), to calculate the LID tool dimensions and types needed.  \n\nThis application has been created for the preliminary design phase of a project to enhance \nclimate resilience strategies such as stormwater management on site. This tool can also be \nused to design and dimension LID strategies in existing blocks of cities (2). \n\nBoth tools attempt to inspire and lay a foundation for other researchers to develop open access \ntools with their students and alumni for their area of expertise. Landscape architecture is a \nland-based profession, the design impact is “outside” in the environment, landscape architecture designs are exposed and constantly changing. More ‘applied research’ should be carried \nout in design school, to increase evidence-based designing with quantitative and qualitative \ndata. Landscape architects have a responsibility to design all projects with climate resiliency \nin mind today.  \n\nConclusion \nI believe that multidisciplinary applied research contributions such as the open access tool \nexamples above can support climate change resilience effectively. They can be adapted to \nlocal needs and expertise. Not only such tools are, in most cases, easily adaptable to local \nneeds and expertise, they can often be used immediately by the public, rather than depending \non time-consuming grant funding process. In the instances where funding is necessary, the \nstudents involved in the projects may subsequently support them as alumni.  \n\nI also suggest further that all landscape architecture students should learn basic ‘coding’, best \napplied directly in a research project or class exercises which involves the creation of a small \napplication which can be used in landscape architecture, for example a cut and fill calculator \nfor grading (3). This applied teaching will encourage and inspire the next generation (students \nand graduates) to co-lead ideas to implementation, and empower them to act for their future. \nStudents need to be provided a research platform to experiment and shape the environmental \nfuture.  Landscape  architecture  students  are  often  thinking  idealistic  in  “saving  the  world” \nthrough  designing.  This  positive  energy  should  be  channeled  into  the  “shaping”  or  land \nscapeing − the environment with more applied research driven projects and tools, helping \nothers. \n

Uncovering the Visibility of Blue Spaces: Design-oriented Methods for Analysing Water Elements and Maximizing Their Potential \n\nAbstract:  Existing  studies  indicate  that  a  direct  view  of  aquatic  elements  benefits  well-being,  and \nhouses  with  blue  views  are  often  associated  with  higher  prices.  Therefore,  developing  analysis  and \ndesign  methods  for  visibility  research  of  blue  spaces  are  crucial  to  advance  spatial  design  practice. \nEspecially  digital  methods  for  analysing  blue  visibility  and their potential  in design  still need  to be \nidentified and explored. This study explores the application potential of some powerful digital visibility \nanalysis methods for blue space design. Specifically, this research first provides an overview of poten-\ntial methods for analysing the visibility of water. Next, two practical design-oriented digital methods \nare briefly elaborated and illustrated by cases in Rotterdam (the Netherlands). Meanwhile, the study \nexplores how the analysis results support spatial design practice. Last, the study discusses the potential \nof integrating blue visibility analysis methods into the iterative design process and makes prospects for \nfuture research. \n\nIntroduction \nWith the prevalence of chronic lifestyle-related diseases and rapid urbanization, health issues \nhave received increasing attention. The health benefits of natural environments as a practical \nsolution to current health issues have been widely recognized, especially for green spaces. \nRecently, the health benefits of blue spaces have been identified, and many studies suggest that a direct view of aquatic elements (e. g. rivers, lakes, and oceans) benefits psychophysiological states and reduces stress (GRELLIER et al. 2017, HARTIG et al. 2014, ZHANG et al. 2022). Houses with blue views are associated with higher attractiveness and price (QIANG et al. 2019). Therefore, it is necessary to consider blue visibility in spatial planning or design process of urban environments, which could provide multiple benefits. On the other hand, current studies  mainly  focus  on  combining  blue  visibility  with  health  data  to  explore  the  relationship between them for developing health evidence. However, only limited studies focus on integrating this health evidence into practical spatial design or policymaking, especially in guiding the design processes, which could be regarded as a huge vacuum in the existing research \n(ZHANG et al. 2022). \n\nKnowledge\/evidence-based design approach and design research provide a solid foundation and  potential  for  filling  this  vacuum,  as  well  as  extend  scientific  understanding  of  design processes that were previously regarded as a black box (JONES 1992, OZTURK 2020). Specifically, spatial design is a core activity in landscape architecture and its related disciplines to provide solutions for urban or rural areas to achieve desired social, cultural, and ecological outcomes (NIJHUIS & DE VRIES 2019). According to the ASE paradigm, design could be regarded as an integrative practice consisting of three interrelated phases: analysis, synthesis, and evaluation. In these three phases, blue visibility analysis methods could be applied to the analysis and evaluation phases to identify site limitations and potentials of design proposals, as well as provide solid support for assisting designers in the synthesis phase. For designers, the integration and utilizing of these methods, especially innovative digital ones, have greatly aided the spatial design practice (LIU & NIJHUIS 2020a). In other words, these methods can \nhelp translate and apply research evidence in the design practice. However, only a limited \nnumber of studies have offered some available methods or tools to analyse the visibility of \nblue spaces and explore their design potential (LIU & NIJHUIS 2020b, NIJHUIS, 2011). To sum \nup, there is a need to identify practical digital visibility analysis methods that support design \nresearch and design for the development of effective blue spaces in the urban environment. \n\nThis paper aims first to provide an overview of potential methods for analysing the visibility \nof water from a design perspective. Also, two practical design-oriented digital methods are \nbriefly elaborated and illustrated by cases in Rotterdam (the Netherlands). The paper ends \nwith a discussion on the potential of integrating blue visibility analysis methods into the iterative design process and provides an outlook for future research. \n\nMethods \nDigital Methods for Analysing Blue Space Visibility \nReviewing the current research and practice on landscape visibility, there are six representative practical  methods suitable for analyzing blue  visibility, including the statistical  index \napproach, (Cumulative) viewshed analysis, (3D) Isovist analysis, segmentation analysis, eye-\ntracking analysis, and 3D landscape analysis (HELBICH et al. 2019, KIM et al. 2019, LIU & \nNIJHUIS 2020b, NIJHUIS 2015, PALMER 2022a and 2022b, PUSPITASARI & KWON 2020). Spe-\ncifically, the statistical index analysis uses alternative indicators, such as the number, total\/ \nmean area, or density, to measure blue visibility. It is mainly applied in spatial design projects \nat the regional scale and contains the advantage of simple and rapid calculation. (Cumulative) \nviewshed analysis adopts the continuous digital landscape model to calculate and visualize \nthe surfaces that are visible to specific observer features. Since it is integrated into GIS software, it could be applied in regional\/intermediate projects where computing power is sufficient. Due to the input data and used analysing tools, the way in which the above two methods \nare  integrated into the design process to assist design decisions is to allow comparison  of \nchanges pre\/post spatial design interventions. On the other hand, (3D) isovist analysis shares \na similar calculation logic with viewshed analysis, while the precision and ease of modelling \nallow it to be applied to projects at the individual scale by simulating blue visibility changes \nduring people’s movements. Segmentation analysis and eye-tracking analysis both borrow \nthe theory or techniques from computer vision to describe the visibility of blue space at the \nindividual scale through the analysis of characteristics in specific scenes quantitatively. The \neye-tracking analysis attempts to describe people’s perception of blue  spaces  more objectively by measuring observers’ eye movements and associating them with spatial characteristics. Last, 3D landscape analysis is widely used in designers’ daily practice to identify the characteristics  of  specific  spatial  arrangements  using  2\/3D  visualisations  (LIU  &  NIJHUIS 2020b). Unlike the two blue visibility analysis methods at the regional scale, the four methods at intermediate\/individual scales, when integrated into the design process, allow rapid simu-\nlation of the post-intervention scenario to help designers test and visualize different design intentions. Table 1 lists the existing blue visibility analysis methods with detailed information.  \n\nAfter reviewing the methods, it is important to assess their potential for integration into the \ndesign process and to select the representative and novel ones to demonstrate their application. There are four criteria to identify their potential in the design process. Specifically, the \nmethods should first allow implementation in designer-friendly software. Most of the methods listed could be integrated and run in existing and easy-learning software environments, \nincluding GIS, Rhino, SketchUp, Photoshop, and Excel. Only the segmentation analysis needs \nto  be  run  in  Python  directly  via  existing  deep-learning  packages  and  pre-training  models, \nwhich  may  be  unfamiliar  to  designers.  Therefore,  it  is  worth  showing  its  application  and \ndiscussing its design potential in this study. Second, the methods should be adaptive to the \ninput data with multiple precision and sources. Since eye-tracking analysis relies heavily on \nuser participation, the requirements for input data are relatively strict. In other words, it describes blue visibility subjectively from a non-designer’s point of view and therefore is not \nincluded in this study. Third, the method should understand the eye-level visibility of blue \nspaces since it is closely related to spatial design rather than planning and is currently receiving growing attention. Accordingly, the intermediate\/individual-level methods are selected, \nas the regional scale methods are closely related to landscape planning. Last, the methods \nneed to be integrated into design iterations, allowing quick changes to represent and test designers’ new ideas. Thus, the scenario-based methods indicated in the last column of Table 1 will  be  chosen.  Based  on  the  above  criteria  and  the  novelty  of  the  methods,  (3D)  Isovist analysis  and  segmentation  analysis  are  chosen  in  this  research  for  investigation,  and  their \ndesign possibilities are examined. \n\nStudy Area and Materials \nTo show the application of the two selected methods, a part of the Rotte River in Rotterdam \nis used as the study site. There are three reasons for choosing the Rotte River as the \ncase. First, the Rote River is located in Rotterdam, the second largest city in the Netherlands, \nwhich is rich in blue space resources. Rotterdam’s urban living is closely related to the water, \nand blue visibility plays an important role in the spatial design of the urban environments. \nSecond, the Rotte River used to be a major transport artery of the city in the past, and industrial products and vegetables were taken to the markets and auctions via it. Nowadays, the \nRotte River has been transformed into a public space which is closely related to the daily life \nof the public and provides multiple benefits. Last, as an essential urban river in Rotterdam, \ndata availability and physical accessibility (i. e. field survey) helped to evaluate and refine \nthe results of method applications. \n\nAs mentioned above, two methods for analyzing blue visibility are used to show their appli-\ncations and explore their design potential. Considering that each method has its unique char-\nacteristics, Table 2 lists the details of the tools and data required for the two methods. \n\nResults \nThree situations are presented to illustrate the application of the two methods and the design \npotential of their analysis results. Specifically, route-based visibility analysis adopts the 3D \nIsovist analysis method to calculate the visibility of water bodies under people’s movements. \nBuilding-based visibility analysis also adopts the 3D Isovist analysis method, taking the building as the analysis object to calculate the visible proportion of blue space in different areas of \nthe building surface. Moreover, the segmentation analysis method is incorporated into scene-\nbased visibility analysis to obtain the visual features of typical scenes in selected area. \n\nSituation 1: Route-based Visibility Analysis \n3D Isovist analysis is used in route-based visibility analysis via Rhino-Grasshopper environ-\nment to calculate the water visibility of people alongside the specific route (Fig. 2). The process consists of the following steps: (a) divide the selected route into several parts; (b) generate original view sphere based on horizontal and vertical FOV (field of view); (c) construct \nand compute the Isovist Rays by setting the obstacles and analyzing radius; (d) calculate the \nproportion of Isovist Rays contacting the water surfaces for each part of the route; € visualize \nthe  analyzing  results  into  chart  diagrams.  Three  transportation  modes,  including  walking, \njogging, and cycling, and two directions, including North-South and South-North, are conducted in the calculation, and detailed analysis parameters are shown in Table 3.  On the other hand, during the movements on the selected route, the overall patterns of blue visibility among the three transportation modes are similar, especially for jogging and cycling. This could be due to the lack of clear route classification and design between the different transportation modes in the study area. Accordingly, the analysis can be applied to the planning and design of different routes by simulating the people’s blue visibility of different traffic behaviours, such as the blue visibility of cycling routes at intersections could be lower to prevent distraction. \n\nSituation 2: Building-based Visibility Analysis \nBuilding-based  visibility  analysis  also  conducts  3D  Isovist  analysis  to  calculate  the  water \nvisibility of building surfaces located near the Rotte River (Fig. 4). The analysis process consists of the following steps: (a) divide the building surfaces into the small matrix; (b) set the \ncenter point of each small cell as the input for 3D Isovist analysis; (c) conduct the 3D Isovist \nanalysis as mentioned above; (d) calculate the proportion of visible water bodies in each cell \nof building surfaces; € visualize the results on buildings in an interactive way; (f) calculate \nmean blue visibility of each building and visualize it on map (optional). Detailed parameters \nfor analysis are shown in Table 4. \n\nThe left graph of Figure 4 presents the analysis results directly on building surfaces, where \nthe surfaces with blue-side colours indicate higher blue visibility. In comparison, the surface \nwith red-side colours shows lower blue visibility. Even for the same building, the outcome \ninteractively  represents  the  varying  degrees  of  blue  visibility  at  different  points.  The blue \nvisibility of two adjacent rooms can be varied, which may lead to completely different con-\nsequences, as ULRICH’s (1984) famous experiment demonstrated that a ward with a natural \nview could have a positive influence on the recovery of the patients living in it. The result \ncan help designers in architecture or vegetation design, in adjusting the layout of buildings \nor vegetation and repositioning the building windows or vegetation to increase blue visibility. \n\nOn the other hand, the analysis results could provide evidence for planning and policy-mak-\ning on the intermediate scale. Specifically, the study further calculated the average blue visibility of each building surface cell and visualized the results on the map. The results show \nthat the middle three buildings have higher blue visibility, which provides the potential for \nevaluating  the  differences  in  blue  visibility  among  several  buildings  (Fig.  4  [right]).  This \nresearch merely uses a few riverside buildings for testing. In the future, the analysis can be \nextended to the buildings within a specific area to support the planning of neighbourhood \nspatial layout and strategies for pricing housing units. \n\nSituation 3: Scene-based Visibility Analysis \nThe machine learning-based segmentation analysis method is used in scene-based visibility \nanalysis. Following the procedures in  HELBICH et al.’s (2019) research, the fully convolutional neural network for semantic segmentation (FCN-8s) model is trained by the ADE20K \nscene parsing and segmentation databases. A total of 208 photos taken based on the on-site \ninvestigation were used as input images for segmentation (Fig. 5). Next, the number of elements in scenes and the ratio of different element groups to total pixels are calculated. \n\nOn the other hand, the statistical analysis of the segmentation results can quantitatively describe the landscape element characteristics in scenes. The three graphs in the first row of \nFigure 7 demonstrate the distribution of the number of elements in each scene and the average \nproportion of area occupied by the main landscape element groups in all scenes. The number \nof elements in the current scenes is concentrated in 20-30, and the number of elements whose \nfield of view accounts for more than 5% is concentrated in 6-9. Vegetation, water, and sky \nare the main landscape element groups, while facilities only occupy a limited proportion. The \nthree graphs in the second row of Figure 7 compare the element characteristics of typical \nscenes among three sections of the river. From the results on the number of elements, the \nvalue in section 3 is higher than the other two sections, showing that it has relatively high \nvisual complexity. The value of section 1 is more concentrated and less distributed in large \nvalues, demonstrating that its visual complexity is stable and relatively easy to understand. \nHowever, the value of section 2 presents more scattered patterns than the others, indicating \nthat people’s visual perception changes in this section are more significant. In addition, according to the results on the proportion of main landscape element groups, it is obvious that \nthe proportion of vegetation in scenes of section 2 is less than in the other two sections, and \nthe proportion of buildings is higher. More buildings in scenes could also prove that the visual \nperception of this section is dynamic and varied. Accordingly, segmentation analysis could \nbe regarded as a powerful tool for designers to describe the landscape elements and the spatial-visual characteristics in design. Visual complexity, openness, naturalness and other indicators calculated by segmentation results can provide quantitative evidence for designers to \ncompare different design schemes or intentions and then make final decisions. \n\nDiscussion and Conclusion \n\nAs exemplified by the presented applications, three situations of using two methods not only \nhelp to get a grip on the different characteristics of blue visibility of Rotter River, but also \nexplore the possibilities in assisting multi-scale spatial design to improve it. In other words, \ntwo practical and design-oriented digital methods, including (3D) Isovist analysis and seg-\nmentation analysis, could facilitate a comprehensive understanding of the site’s restrictions, \nlimitations, and potentials on blue visibility, and provide clues for future design interventions. \nOn the other hand, these methods are complementary and can be combined together in some \ncircumstances.  For  instance,  segmentation  analysis  could  also  be  applied  in  situation  1  to \noffer an understanding of various landscape elements and their organizations during movements beyond the Isovist analysis only focusing on water bodies. \n\nThis  study  does  not  provide  the  complete  process  of  applying  the  two  methods  to  spatial \ndesign, but only shows the possibility of their design potential in a highly simplified form \nthrough three application situations. However, based on the ASE paradigm of design pro-\ncesses mentioned in section 1, it is evident that they could be parts of the design iterations, \nincluding analysis, synthesis (design), and evaluation (Figure 8). Here, designers could use \nthem to analyze and understand the existing situation, test and evaluate ideas or intentions, \nand compare different options to make final decisions. \n\nNowadays, with the advancement of technology, digital methods and tools are being widely \ninvestigated and introduced into spatial design practices, greatly expanding the toolbox of \ndesigners. The two methods presented in this study could serve as an inspiration to encourage \nexploration of the potential of multi-disciplinary methods to be incorporated into design processes. However, the traditional means (e. g. sketches or models) cannot be overlooked and \nshould be combined with the digital methods to achieve design objectives better and improve \nthe development of the knowledge\/evidence-based design approach. In addition, this study \nhas several limitations. First, this study cannot include all possible methods and only provides \nlimited applications to inspire future research. Second, the landscape is dynamic and greatly \naffected  by  time  or  season,  especially  for  water  bodies  and  vegetation.  People  may  have \ngreater blue visibility in winter since the leaves are gone. Last, the data acquisition or precisions, quantity of site photos, processing power or time, etc, may influence the results. Future \nresearch  can  optimize  these  factors  to  improve  the  effectiveness  and  practicability  of  the \nmethods. \n

A Mixed Reality Experience: Advancing Design \nDecision-Making with Performance Metrics \nThrough Augmented Reality and Physical Media \n\nAbstract: Augmented reality and virtual reality have effectively served as an immersive environment overlayed within the real world. These experiences are, however, often static and limited in function, primarily, as a full-scale walk-through. This study tests the capabilities of including real-time interactivity and engagement as a tool for dynamic design decision-making. The idea is further explored by integrating landscape performance metrics and project goals to determine how this supplemental data may influence the participants design decision-making. The synchronization of qualitative and quantitative information through a mixed reality experience has major implications to design development as the stakeholder groups have the opportunity of experiencing real-time responses to their engagement of a design project. \n\nIntroduction \n\nThrough the emergence of landscape performance and the integration of quantitative metrics \ninto  outdoor  spaces,  technology  and  innovate  methods  can  begin  to  communicate  naturebased benefits as tangible outcomes to comprehend the complex ecological, social, and economic relationships of our complex environments (BECK 2015). Due to the fact that many of \nthese ecosystem services are intangible and abstract, new methods must be explored to effectively  communicate  these  invisible  landscape  performance  outcomes  into  a  perceptual \nrealm for a comprehensive understanding of design decisions (ZHANG et al. 2021). The viability of this process can be explored at both full and reduced scales as a real-time feedback \nmodel using a hybridization of augmented reality and physical media; catalysed as a mixed \nreality (MR) experienced in the p[AR]k.  \n\nThrough this comprehensive qualitative and quantitative mixed reality process, divergent decision-making, predicated on the information presented in an augmented reality (AR) interface, can be made for multiple responsive and sensible outcomes (LAHAIE 2016). This ultimately generates an immersive, engaging, and interactive design process for a more universal \naudience to participate in for specific needs from a landscape architecture project, shown in \nFigure 1. \n\nThe modeling of dynamic landscape benefits within a mixed reality experience of both physical demonstration pieces and augmented reality interfaces creates an accessible means to \nparticipate in the design development of any project. Augmented reality is not only gaining \ntraction as an innovative representation tool but with the integration of parametric modeling \nand performance metrics it can also serve as a decision-making tool (DUENSER et al. 2008) \nto the design process for specific goals and outcomes. With the incorporation of performance \nmetrics into the augmented interface, data becomes responsive to real-time change, performance parameters, and user decision-making.  \n\nA Mixed Reality Experience and Workflow \n\nThe p[AR]k attempts to model these dynamic landscape benefits within a mixed reality experience of both physical demonstration pieces and augmented reality interfaces to reach a \nuniversal audience within a dedicated workstation comprised of a physical sandbox and com-\nputational hardware. Augmented reality sandboxes are becoming a common tool to understand topography; however, they are often limited to specific outcomes visualized as coloured \nheightfields projected on sand media. Although it is beneficial to understand these funda-\nmentals, the computational rigor of these models can be advanced further using parametric \nsoftware  to  measure  additional  terrain  characteristics  and  ecosystem  services  that  include stormwater management, carbon sequestration, and energy savings, shown in Figure 2.  \n\nProviding visualizations, interactive properties, and tangible media in a mixed reality experience gives the user ownership and agency behind their decisions for outdoor spaces. Professionals,  community  members,  and  stakeholder  groups  can  come  together  and  learn  the \nimpact of their decisions as their actions are stored in a database for further analysis of communal interests.  \n\nSandbox Station Capacity \n\nThe feedback collected from the point cloud of the sandscape is processed through the parametric modeling software to analyse and generate visuals with charted information based on \nvarious  parameters.  In  addition  to  sand  media  serving  as  the  terrain  model,  mobile  smart \ndevices, oculus quest controllers, or aruco markers can reference and embed various amenities  that  include  trees,  benches,  water  features,  paths  and  other  elements  onto  the  terrain \nmodel for a conceptual landscape performance rendition. There are several benefits from this \nprocess that include workflow and design development, design-thinking, scenario modeling, \ntrade-offs assessments, landscape performance, and co-creation and collaboration.  \n\nIn this study, users were put into a hybrid mixed reality experience of physical and augmented \nreality to address design opportunities within the scope of landscape performance. They were \nintroduced to environment, social, and economic scenario objectives that could be mitigated \nthrough the manipulation of a physical sandscape and augmented placement of trees within \na hypothetical neighbourhood pop-up park. With this experience, users manipulated the sand \ntopography and moved pieces around, perceiving the impacts different designs had in achieving stormwater management, carbon dioxide (CO2) sequestration, and energy savings. Simultaneously, data readouts from the topography, amenities, and surrounding neighbourhood \ncontext communicated quantitative data on the design iterations to assess the trade-offs and \nperformance of different scenario models related to ecosystem services. With each change or \naddition to this AR model, the data readouts instantly updated to inform next moves within \nthe design decision-making process. \n\nThe metrics and formulas for these parametric performance models were configured from \nmetrics and calculators commonly used by allied professions that include iTree’s tree benefit \ncalculator, NRCS stormwater calculator, and the US Department of Energy typical household \nenergy consumption. The iTree benefit values used in the different performance scenarios \nwere based on a thirty-year-old healthy honey mesquite tree.  \n\nPerformance Objectives \n\nWith the influx of real-time quantitative data that updates during this process, there is a profound opportunity to fundamentally shift design thinking and intent from these augmented \noutcomes. By embedding measurables and metrics to this workflow, this new design process \nand methodology of a MR experience can potentially emerge that enables the respective parties to generate robust design strategies for evaluation on specific goals and objectives. As \npart  of  this  performative  MR  experience,  the  interface  can  be  configured  to  display  data readouts communicating quantitative information throughout the design process to assess the \ntrade-offs of different scenarios as a divergent process (CIRULIS & BRIGMANIS 2013).  \n\nThere are many different AR programs available for users to immerse themselves within a \ndesigned space, however, the values most programs don’t provide is the ability to synchronize it to an industry standard modeling software such as 3D Rhinoceros to further refine a \ndesign concept. This is made possible with the plugin additions of Grasshopper (parametric \nmodeling) and Fologram (AR platform) to create a real-time feedback between the perceptual \nAR interface and the cognitive modeling software. Grasshopper manages and integrates the \ntangible and intangible analytics for performative landscapes while establishing a dialogue \nwith the Fologram application on a smart device. Fologram is then used to engage with the \ndesign  model  using  either  finger  gestures  on  a  touch  screen  or  by  scanning  printed  aruco \n\n\nmarkers, referencing different design elements such as trees, pavers, or benches. The programs in tandem create a responsive workflow of reciprocating outcomes based on the decision-making process of the user. The perceptual experience created can be viewed simultaneously on the computer and in the physical world, blending the two in a hybridized environment.  \n\nWithin the p[AR]k project experience, users were evaluated on two different scenarios to \ndetermine if performance objective and metrics impacted their decision making. In the first \nscenario, users were only required to manipulate the p[AR]k space through a perceptual lense \nof  only  seeing  the  site  as  qualitative  and  figural  with  landforms,  water  features,  and  tree \nplantings. In the second scenario the users were provided different landscape performance \nobjectives that integrated and displayed quantified metrics to determine if and how this may \nimpact their design decision-making any differently. Performance scenarios included managing stormwater runoff, sequestering CO2, and reducing energy consumption from buildings.  \n\nPerformance Methods \n\nFor the stormwater runoff scenario, the surrounding impervious conditions of streets, sidewalks and buildings coupled with the park’s landforms contributed to a calculated stormwater \nrunoff volume from a typical 0.5” rain event. This volume served as a baseline objective to \nmanage through a catchment system (landscape depression) and trees. The runoff from those \nlandform conditions were conveyed through drainage lines, suggesting the most optimal location to place trees to intercept the runoff. In the carbon sequestration scenario, the EPA’s \nmetric for an average typical passenger vehicle emitting about 4.6 metric tons of carbon dioxide per year, or 10,141 pounds of CO2, was used to establish a site measurement for the \nsurrounding neighbourhood context. And according to the U.S. Department of Transportation, the average number of cars owned per household is about 1.88. Based on these statistics, \nthe surrounding residential households contributed a total of 247,853 pounds of carbon emissions annually. Lastly, the energy savings scenario used the U.S. Energy Information Administration’s average household consumption metric of 10,715 kilowatt hours annually. \n\nUsers  were  first  expected  to  manipulate  the  topography  to  create  dynamic  landforms  and \nwater features within the neighbourhood pop-up park, see Figure 3. This would ultimately \nimpact  stormwater runoff potential  while  simultaneously creating drainage  and  catchment \nsystems in the landscape. The participant quickly realized that either one large or multiple \nintermediate  catchment  systems  within  the  topography  could  not  contain  the  site’s  runoff alone and would also require the strategic placement of trees to help with the mitigation process through interception.  \n\nTrees can intercept runoff through both their tree canopy and root structure. For the modeling \nand  calculation process,  the tree’s  ability  to  intercept  runoff from  their root  structure was \nused and would be assessed on its performance based on its proximity to the generated drain-\nage lines in the topography. As the user realized this in their tree placement, they began to \nstrategically place trees within close proximity to the visualized drainage lines in order to \nmaximize their interception potential leading to a higher percentage of managed runoff. \n\nThe design of the neighbourhood pop-up park for CO2 sequestration was more ambiguous \nleading to less consistent tree placement strategy since this is a non-point source pollution. \nIn these types of situations, it was found during the study that when there are unclear demar-\ncations for tree placement users would often place trees with less reason or logic into the \nlandscape, shown in Figure 4. This did, however, lead to users manipulating the sandscape \ntopography to have less area dedicated to catchment basins so that more trees could be placed. \n\nTree placement within the energy savings scenario had similar results to the stormwater management one in that as users realized the relationship of a tree’s location to a building would \nreduce its energy use, their strategic planting gravitated towards those specific parameters. \nWith the energy savings, tree distance and orientation to the building would result in different \nkilowatt hours saved. This can be seen in the tree and building values in Figure 5. \nFor example, a tree in near proximity to the north facing façade of a building would be less \nbeneficial to a marginally further distanced tree from the south facing façade since that sun \nfacing façade would be absorbing the most, requiring more tree shade protection to reduce \nthe building HVAC use.  \nThe combination of the responsive interface, the ability to co-create and engage with different \nstakeholder groups, and the real-time integration of data can fundamentally reroute the design \nthinking methods. Abstract and formal ideas can merge into one process, helping the user \nengage, innovate, increase options, and see the implications of those decisions simultane-\nously with their collaborators as a cyclical feedback loop. \n\nResults \n\nAfter users participated in this study through the p[AR]k, they were provided a survey to \nassess if and how the integration of landscape performance metrics (quantitative information) \nimpacted  their  design  decision-making  (qualitative  information).  Out  of  this  beta  testing \ngroup of roughly thirty undergraduate landscape architecture students, one hundred percent \nagreed that the inclusion of landscape performance values impacted their design decision-\nmaking, as asked in the first survey question. This broad overview of landscape performance \nmetrics were followed-up with more specific performance questions to determine which ones \ndid  or  did  not  have  a  significant  impact  on  their  design  decision-making,  provided  in  the \nbelow figures.  \n\nDesign Decision-Making Outcomes \n\nFollowing  the  first  survey  question,  the  first  landscape  performance  question  in  Figure  6 asked the user to rate how significant the inclusion of performance metrics was to their design \ndecision-making.  A  scale  of  1  to  5  (x-axis)  was  used  where  1  meant  no  significance  and 5 meant major significance. The number of results (y-axis) shows the majority found it within \nthe high significance range. \n\nThe next performance question in Figure 7 asked which landscape performance scenario was \nof value to the user. The scenarios were specifically diversified to reflect environmental, social, and economic values. The participant could select multiple options so many users found \nmultiple performance scenarios to be important to them. \n\nThe last performance question in Figure 8 asks for the significance in designing towards a \nspecific goal. This question also used a scale ranking of 1 to 5 was used where 1 meant no \nsignificance and 5 meant major significance. This clearly indicated that establishing performance goals for individuals drove their design decision-making.  \n\nConclusion and Outlook \n\nThis  mixed  reality  provides  an  advanced  learning  experience  for  the  user  to  engage  with innovative technology, create robust analytical modeling and assessments, and create a participatory decision-making experience to advocate for healthy sustainable cities (WANG et al. \n2013). The hybridization between malleable model making with augmented data reveals a \nsymbiotic connection of instrumental tools in design thinking. It correlates with many STEM \nrelated principles of evidenced-based strategies where design can act as a strategic response \nto problematic issues of flooding, public health, and equitable resources within the built environment.  \n\nThis mixed reality design experience has tremendous potential to increase the capacity for \nusers, designers, and the community to work together and advocate for healthy living environments, make design more efficient by linking tools that help speed up the process, and \nhelps  everyone  involved  see  the  benefits  of  proposed  designs  (LIU & WANG  2019).  Augmented Reality has shown to serve as an innovative and versatile tool to visually communicate information as part of an analytical and design narrative for more informed design decision-making. This MR experience and workflow can further separate itself from other methods in the immersion and perception of space as it overlays qualitative and quantitative information impacting the composition and performance of a design concept. Rarely is it possible to experience the data that binds ecologies together. AR still contains limitations to this \nprogressive design approach, however, it can begin to give a glimpse of these interactions \nand  relationships  between  systems  in  real-time  as  designers  augment  space  into  a  mixed-reality. \n

A Parametric Design Methodology for a Novel \nEcosystem \n\nAbstract: A literature recognizes the ecological value of biodiverse “novel ecosystems” that arise from an interplay of anthropogenic and independent ecosystem processes. Several factors influence the creation of these novel ecosystems and there is no shortage of data acquisition methods for, or complexity of descriptive data about them. However, there is a need to articulate and contextualize tools and meth-ods for formal design iteration that can make sense of this complexity and facilitate its translation into functional and meaningful landscape form. This paper describes a method for abstracting ecosystem processes into a simple parametric model, presented in the context of a riverbed mining operation in southern Georgia. The results of this initial methodology reveal the potential of parametric models to mediate between digital models of formal proposals and abstract models of ecosystem process. Separating and recombining parametric site models, abstract ecosystem models, and landscape photomontages reveals possibilities for a more facile methodology for iteration of design interventions. A parametric model also serves as a site for negotiation between project goals and constraints. Finally, the generation of a digital parametric site model allows for subsequent visualisation and editing of more specific digital models for design development and construction. \n\nIntroduction \n\nAggregate Mining Landscapes as “Novel Ecosystems” \n\nAggregate mining landscapes are widely understood as sites of chronic ecosystem degradation and destruction. However, there is a growing consensus that recognizes the ecological \nvalue of chronically degraded but “novel” ecosystems in supporting biodiversity and providing ecosystem services. A “novel ecosystem” is understood here broadly as a “new species \ncombination that arises spontaneously and irreversibly in response to anthropogenic land-use \nchanges” (MURCIA 2011). While significant debate surrounds the “irreversibility” of these \nchanges, the “restoration” of sites with a high degree of anthropogenic disturbance can improve biodiversity and ecosystem services. Rather than allow descriptions of “novel ecosystems” to simplify the project of ecological restoration, designers’ engagement with these sites \nshould focus on relationships between anthropogenic disturbance, ecosystem services, and \ncomplexity (MURCIA 2011). \n\nRestoration research in riverbed aggregate mining contexts suggests that disturbed mining \nsites provide new ecological niches that support overall site biodiversity, and that restoration \nefforts could benefit from a focus on “near-natural” restoration rather than more resource-\nintensive planting approaches (ŘEHOUNKOVÁ 2011). Similar approaches advocate for designing ecological processes and functions to allow for plants to “develop a measure of control \n[themselves]” (DEL TREDICI 2007) or “intervene and leave room” (GROSSE-BACHLE 2005). \n\nThis paper expands and applies this approach to ecosystem restoration to explore the role of \ngeodiversity in parametric modeling and redesign of aggregate mining operations. An active \nopen riverbed mining site in the south of Georgia provides the case study for the project, \npresenting opportunities to explore a design methodology that attempts to engage and alter \nan existing process of anthropogenic geomorphological change. Restoration is here under-\nstood as amplification and diversification of remaining landscape qualities. \n\nFrom Geodiversity to Geomorphological Diversity \n\nWhere geodiversity is a result of a broader collection of factors including mineral, paleontological, and structural\/ tectonic factors, geomorphological diversity describes that subset of \nfactors encompassed by surface processes. While variations in surface processes like differential weathering lead to increased geomorphic diversity, these same processes can also lead \nto reduced geomorphic diversity (THOMAS 2011). In the shifting landscape of an active aggregate mining operation, geodiversity can be understood not only as geo-determinism but \nalso as an effect of the existence of multiple states of succession within a given ecosystem. \nAltering the mining process can lead to coordination and amplification of a wider range of \necosystem successional states.  \n\nParametric Modeling and Scenario-based Design \n\nAshari et al. note that “Key academics and practitioners of landscape architecture are implementing parametric design as part of their design process in generating various design scenarios” (ASHARI et al. 2022). The goal of the methodology is incorporating the context of the \ndesign  work  into  a  formal  parametric  model  from  which  to  generate  proposed  scenarios. \nThus, the project is an attempt to situate parametric modeling within a broader definition of \ndesign scenarios (SHEARER 2022). The method should allow the model to facilitate a formal \ndialectic between given and proposed formal scenarios that is open to interpretation by designers. Additional parameters can facilitate landscape designers, planners, quarry operators, \nscientists documenting biodiversity, and the interests of laypersons living near and visiting \nthe site. The methodology elaborated in this article proposes modifications to a traditional \nAnalysis\/Concept\/Design\/Evaluation workflow. The aim was to use parametric modeling to \nencode simple formal models of observed ecological processes and begin to visualize formal \ninterventions in these processes. \n\nMethodology + Case Study \n\nSite-based Research + Analysis \n\nInterview \n\nThe design team kicked off the project with a semi-formal site visit and workshop to identify \nformal parameters and key system concepts of the mining operation. We invited architecture \nstudents from a local university to work with the design team to interview on-site excavators, \noperations managers, and ecologists.  \n\nThe interviews revealed that excavators control the shifting landscape by creating dams, which allow them to direct the river and its powerful floods. \n\nAccording to the on-site operations manager, dams are built for a variety of reasons, including protecting machinery from periodic flooding, reducing sediment flow, and allowing \nfor truck access from extraction points to processing sites. After a certain area is excavated, \ndams are eventually removed to allow larger floods to “replenish excavated material”, a \nprocess which can take as few as five years.  \n\nAfter collecting the qualitative description of the mining process and ecological diversity, the \nteam compiled satellite imagery, reviewed drone footage, and composed diagrams describing \nthe mining process and its extent. While the drone footage from the February visit shows a \nsparse winter landscape, satellite imagery shows a river in constant flux, coming to life each \nspring as a new layer of vegetation spreads over the bed of silt and rocks freshly deposited \nby winter flooding. The imagery serves as a partial record of the last decade and reveals the \nimpact of mining activities on the riverbed over time. Aggregate mining disturbs the riverbed \non a timeline of weeks to months, but this impact is superseded by spring floods that occur \nyearly. \n\nIn response to these conditions, we hypothesized that the mining and dam-building processes could be harnessed to increase the geomorphological diversity of the mining site. Processes of excavation, dam building, and periodic flooding have the potential to create a \nwide range of microhabitats that support increased species biodiversity. \n\nDefinition of Ecosystem \n\nGrasshopper Definition of Formal Ecosystem Drivers \n\nA secondary step of analysis involved the translation of the narrative context of the site into \nformal parameters that respond to existing ecological conditions and planned works on the \nsite. To create a tool for quick formal iteration with respect to site-scale decisions (“Planning \nDecisions” in Fig. 1), we needed to identify and abstract the appropriate metrics and formal \nparameters of the mining operation and larger landscape ecological dynamics and forms. \n\nIdentifying Macro- and Micro-ecosystems \n\nThe abstraction of landscape ecological features was accomplished by comparing areas of \nsimilar  vegetation  cover  to  the  topographical  surface  to  define  boundary  conditions  on  a \nbroad site-scale. As observed on site and through sectional analysis in Google Earth, the edge \nof the “Intact Bosque” follows the scoured edge of the riverbed, providing a sharp boundary \nat the site scale. A lighter shade of vegetation composes an intermediary edge zone that has \nallowed for the development of an early successional bosque, which exists at 1-2m above the \napparent limit of flooding. The floodplain is defined by a zone of high-frequency scouring \nevidenced by the limited presence of shrubs. Scattered across the floodplain are former borrow pits, which host littoral micro-ecosystems similar to the early successional bosque. \n\nBy  applying  Richard  Forman’s  principles  of  landscape  ecology,  the  early  successional \nbosque can be understood as the cellular or nuclear membrane of the intact bosque, facilitating the migration and succession of species (DRAMSTAD et al. 1996). A key assumption for \nthe model is the role of the intact bosque as a nucleus for expansion into the shifting floodplain and active mine zones (CORBIN et al. 2016). This allowed us to argue for the conservation of the bosque by shifting tipping grounds from the floor of the intact bosque to the more \nfrequently  disturbed  early  successional  bosque.  The  tipping  piles  currently  interspersed \nthroughout the intact bosque should be redistributed as a way of amplifying the seed bank of \nthe more frequently disturbed landscape.  \n\nConcept Development \n\nThe goal of the concept development phase was to create a simple iterative model of masterplan forms. At the site scale, the ecological system is represented as a “boundary model” \n(HILL 2005). The boundaries represented in the model (the edges of the intact forest and the \nedge of the main channel of the river) define the limits of the proposed berm system. These \nedges are subdivided to generate start and end points for the berm and distances between all \npossible start and end points are calculated. Each of these possible berms is then recalculated \nas a set of bi-arcs, or curves composed of two simple arcs. The definition incorporates In-\nCurve interior culling to exclude iterations that exceed the limits of the project.  \n\nFollowing initial iteration, a selected curve or set of curves is then used as a basis for the \ngeneration  of  a  surface  that  can  be  intersected  and  compared  with  models  of  the  existing \nsurface. In this project, the lack of a high-definition surface model forced us to rely on abstracted orthoimagery to infer elevation information. In future iterations of the methodology, \na context model with greater definition can add greater analytical definition to this stage. \n\nThe vertical difference in the model is developed relative to a “system zero” that can shift to \nany average or given waterline elevation. This allowed us to reduce the complexity of varying \nwater levels while also retaining the ability to incorporate more complex water elevation data. \n\nDesign Development \n\nThe iterative outcomes of the concept development model form the base of a further-refined \n“design development” model. The development model is broken into smaller models of individual zones to generate a greater diversity of micro-ecosystems. \n\nManual and Parametric Cutting Operations \n\nBerms can be cut with individual curve parameters or sets at specific intervals to introduce \nfurther porosity in the system. Varying the elevation of these cuts can generate check-dams \nor culverts with a range of crestline elevations. \n\nDistribution of Varying Nutrient Levels and Soil Types \n\nParameters  for  specific  soil  types  can  be displayed by  developing  a key-color  legend and \ncustom material previews. \n\nIncorporation of Environmental Simulation on Smaller Sites \n\nThe generation of a physical model allows for a range of existing Grasshopper plugins to \nanalyze  environmental  factors  such  as  hydrological  saturation  (Groundhog)  and  temperature\/energy modeling (e. g. Ladybug, Honeybee). \n\nPhotomontage and Further Descriptive Visualisation \n\nPhotomontage was used not as a way of determining the fixed or final condition but as a \nmethod of representing combinations of potential project conditions to create an image open \nto interpretation (M’CLOSKEY 2014). The definition generates measured landscape forms that \ncan be montaged over existing landscape conditions and textures to produce projective photomontages (Fig. 5). Such hybrid images can be used to establish metric visual parameters \nthat facilitate systemic and systemic design decisions. \n\nDiscussion \n\nDeveloping Facile Definitions \n\nThere is a need to balance specificity and complexity with respect to digital data inputs and \noutcomes when generating formal iterations. Nested, simplified models allow design teams \nto move efficiently between decision-making scales without carrying unnecessary complexity to the model.  \n\nInitial investigations in the design development phase revealed that the use of environmental \nsimulation plugins such as Ladybug, Honeybee, and Groundhog (saturation) work best on \nsmaller sub-sites, where more subtle forces of surface geology become legible. Further case \nstudies are needed to elaborate possible applications to large-scale sites. \n\nDesigners working with parametric software must always take caution when integrating specific datasets. Beginning with an abstracted master plan model with simple geometry allows \nfor fast and loose overlays with existing context data (orthoimagery, topography, observed \nvegetation, etc.). \n\nRules-based Experimentation \n\nSome rules were fast and loose, aimed at experimentation and later refinement (i. e., each \nberm should be double-curved). Others were highly specific, (i. e., the length of the berm, \nthe radius of the berm enclosing an area). The definitional simplicity of the model facilitates \ngeometric iteration and pattern generation. \n\nRepresentation through Hybrid Drawings \n\nThe hybrid drawings produced through this workflow operate like traditional landscape rep-\nresentational method of “landscape overlays” and yet add another layer of specificity and \ncomplexity.  User-displayed  text  and  annotation  can  further  integrate  metric  and  technical \nparameters of the represented form. \n\nConclusion and Outlook \n\nThis project and paper focus on the outcomes of an initial draft of a parametric methodology \nfor engagement with novel ecosystems through geodiversity. The goal of the case study project was to bring the mining operation parameters into a model that can facilitate rapid visualisation of site-scale forms, followed by an initial investigation of smaller parameters. Creating a protocol for nested models with feedback was crucial to moving between scales and \ndiscerning between “hard” and “loose” formal design decisions. \n\nThe methodology allows the abstracted parametric model to become a site of physical and \ndiscursive negotiation and coordination between the various actors involved in the project. \nThe next step in refining this methodology is to test the utility of this parametric model facilitating interdisciplinary data and feedback in the design process. The case study used to develop this tool aimed to establish a more intentional role for formal decision-making by facilitating decisions that incorporate aesthetic and metric-based approaches. \n\nFurther research could unfold along two strategies for further defining the surface: a more \nspecific integration of soil types and the use of 3D scanning to incorporate temporal change \nof landscape form.  \n\nEventual applications of the methodology could inform design protocols for novel and ex-\npanded riparian ecosystems. The workflow can also be applied to smaller sites and the gen-\neration of formal iterations.  \n

Comparing Transportation Metrics to Measure\nAccessibility to Community Amenities \n\nAbstract: Landscape architects and urban planners play an important role in helping create inclusive, \naccessible communities. To do this, it is helpful to understand how the built environment and access to \nvarious amenities and places affect activities of daily community living. These activities can influence social engagement with others and satisfaction with one’s social life. Thus, understanding how the built environment  influences  their  choice  of  living  can  shed  light  on  the  ramifications  to  an  individual’s overall social satisfaction. As previous studies show, there are various methods for measuring accessibility. But to what extent are these metrics different or provide similar results? In the current study, we generate various geospatial models to measure distance, density, and accessibility. The metrics produced are then compared to identify how similar they are in measuring access to several different places. Results show that all metrics are statistically significant and similar, however, similarities range from poor  correlation  to  very  high  correlation.  The  most  consistent  can  then  be  used  in  future  studies  to identify how well they correlate to stated access, actual access, and the influence on social satisfaction. \n\nIntroduction \n\nA tenant of landscape architects and urban planners is to improve the quality of life in communities. An essential variable in this equation is improving the satisfaction of social life as \na result of community integration (SEEMAN 1996, YEN & SYME 1999) and development patterns.  To  accomplish  this,  landscape  architects,  policymakers,  and urban planners need  to \nknow how social and environmental factors impact community integration and, ultimately, \nsatisfaction with social life. Prior work in the discipline has shown that if we create improved \nintegration of people within their community, people experience a higher level of social satisfaction (CHRISTENSEN et al. 2010). \n\nSeveral factors affect the level of satisfaction with social life among people, including factors \ninfluenced by the surrounding neighborhood. For example, social factors such as place attachment (CAO et al. 2020, HUR & MORROW-JONES 2008) and neighborhood cohesion (Liu, \n2017), make higher rates of satisfaction (MITCHELL et al. 2013, OKTAY et al. 2021). Additionally, environmental factors including landscape and green space (BOTTICELLO et al. 2014, \nYOUSSOUFI et al. 2020), mixed land use (BEARD et al. 2009, CAO et al. 2020) destinations \nand urban amenities (ALLEN 2015, SATARIANO et al. 2010), and street connectivity (GÓMEZ \net al. 2010) also play a role in facilitating social satisfaction. However, there is no standardized rule used to calculate how built environment factors and the proximity to urban amenities are associated with the level of social satisfaction. Further, there are limited studies that \nsystematically compare accessibility measures (KAPATSILA et al. 2023). Not only can it be \nimportant to compare the results from a range of accessibility metrics, but equally important \nis  the  level  of  technical  difficulty  required  to  accomplish  each.  In  this  paper,  we  explore \naccessibility to common community places in which individuals take part in a range of different  activities  (JONES  1981).  These  places  include  areas  of  outdoor  recreation,  grocery \nstores, retail stores, restaurants, and others. Throughout this paper, we refer to these places \nas “place types”. Since accurate metrics are necessary for effective policy development and \nimplementation, we are keen to ask: to what extent do different accessibility metrics agree \nwith each other”? Specifically, how different are geospatial techniques for measuring and \nquantifying access to place types by neighborhood?  \n\nThere is a diverse knowledge and broad understanding of the linkages between the level of \nsatisfaction among individuals and environmental factors including neighborhood and place \ntypes (SAMMER et al. 2012, WHITE & SUMMERS 2017). There is, however, uncertainty about \nhow  accessibility  to  each  place  type  affects  social  engagement.  Given  the  potential  importance of these places to facilitate social satisfaction, it will be helpful to identify a robust \nspatial metric that could explain the impact of place types on the level of satisfaction with \nsocial life. We could further use the spatial models to assess and promote policies that integrate people into their surrounding environments and communities. Understanding the relationship between place types and the level of satisfaction can inform how landscape architects \nand planners design inclusive communities. However, before we can understand this relationship, it is also important to understand how we assess accessibility. \n\nOne of the more basic measures of accessibility is to determine the degree of access from one \nlocation to another. Certainly, there are differences in the kinds of reliance on different modes \nof transportation across demographics (PARK et al. 2022). There are several ways for measuring accessibility. However, this paper is not focused on attempting to identify the range of \nmulti-modal transportation accessibility techniques. Instead, we focus on understanding the \nconsistency of different measures of accessibility, mainly because some models may be biased (GIANNOTTI et al. 2022). In this paper, we identify the degree to which six common \nspatial accessibility models are related. We generate a systematic comparison of these models \nby measuring the spatial pattern and accessibility to several place types. By identifying similarities, we can determine trade-offs between model complexity and consistency of the metrics. The easiest and most consistent models can then be used in future studies where empirical data about demographics, disability status, and travel behaviors can be used to identify \nthe relationship between access to place types and social satisfaction. \n\nMethods  \n\nDetermining accessibility is a rather complex process. Transportation-related studies provide \nseveral  means  to  produce  an  accessibility  measure,  with  the  most  precise  being  produced \nusing empirical data collected about individual travel patterns. However, these data can be \nparticularly expensive to obtain and may be logistically prohibitive to obtain in some international contexts. In this study, we pursued comparing six different geospatial models that use aggregate data at the US Census block group level (heretofore: “block group”). To conduct our analyses, we used the Safegraph Point of Interest data points (POI) and aggregated \nthese data into eight categories. Each category is then referred to as a place type. Six metrics \nwere defined to represent the spatial pattern of place types. including, accessibility to different destinations (CAO et al. 2020), proximity to various destinations (TSEMBERIS et al. 2003), \nthe density of place types (YANG 2008), and spatial models (GIANNOTTI et al. 2022, LUO & \nQI  2009).  More  specifically  our  metrics  are:  1)  Average  proximity  to  place  types,  2)  frequency of place types (count of place types within the block group), 3) Density of place types \n(using kernel density), 4) The number of block groups (in USA, referred to as block groups) \nwithin the service area of place types, 5) the gravity model, and 6) two-step floating catchment  area  (2SFCA).  Each  of  these  metrics  measures  accessibility  to  place  types,  but  it  is \nimportant to note that the level of technical difficulty varies widely. Furthermore, variables \nused to calculate each metric can differ. For instance, 2SFCA and gravity model considers \npopulation,  while  frequency  metrics  and  the  kernel  density  focus  on  the  number  of  place \ntypes in a unit (e. g. block group). As a study area, we analyzed data from across the Greater \nSalt Lake City, UT region in the USA. Some items, including accessibility and distribution \nof place types, were selected from neighborhood satisfaction scales developed by (GUTTING \net al. 2021, OKTAY et al. 2021). This technique provides a simple proxy for determining the \nextent  of  access  to  place  types  KWEON  et  al.  (2010)  produced  similar  measures  based  on \ndifferent place types by limiting the distance of an accessible amenity to a respondent’s home. \nConducting a correlation between the metrics results can provide insight into the similar results that we can get. \n\nTwo density measures were produced, frequency of place types (count of urban place types \nwithin the block groups) and density of place types (using kernel density), Metric #1 and #2, \nrespectively. Metric #1 counts the total number of the selected place types intersecting with \na block group, using spatial selection. Metric #2 uses kernel density to calculate the density \nof features and place types in a block group (YANG 2008). Kernel density was performed by \nthe planar option, which is appropriate for the analysis on the local scale.  \n\nFor average proximity to place types (Metric #3), we generated a set of origin locations that \nwould provide a meaningful context for trips from within each block group. Every intersection of the road network within each block group became an origin node. Intersections within \nthe block groups balance the trade-off between identifying every building from which people \ntravel to and from, but also provide more precision than the centroid of the block group. We \ncalculated the median distance of travel using Safegraph datapoints and set as a travel distance to get to different destinations from the intersection nodes. Driving distance was used \nbecause there is limited information about alternative use of public transit. Then, the average \nproximity from all origin nodes to all place types within the travel distance was calculated. \nFigure 1 shows the average proximity, by block groups, from origins to each place type.  \n\nThe number of block groups within the service area of place types (Metric #4) flips the density calculation by starting from the place instead of the block group. To produce this metric, \na service area was generated for each place type using a network analysis. The route distance \nwas calculated based on the median distance that individuals reported as the travel distance \nto  get  to  different  destinations  (similar  to  Metric  #1).  Then  the  number  of  place  types  by \nservice area within each block group was calculated by spatial joining the service area with \nany intersecting block groups.  \n\nThen, the more established 2SFCA metric (Metric #5) was used for measuring accessibility \nto each place type. 2SFCA defines a catchment area around each location and computes the \nsupply-to-demand ratio for the catchment area. The boundary of the catchment area can be \ndelineated with the radius, travel distance, and travel time (LUO & QI 2009).  \n\nThe other commonly used transportation metric we employed was the gravity model (Metric \n6). The gravity model has been used to model human mobility and accessibility. The model \nconsiders the distance between two nodes and the population within the place type’s service \n\nResults  \n\nResults of this systematic comparison are provided first as a correlation matrix (Table 1), \nthen as a series of visual representations below. To demonstrate the statistical differences \nbetween  each  metric,  we  produced  correlation  tables  for  each  of  the  eight  different  place \ntypes, by each of the different Metrics (or geospatial models). Here we show a summary table \nof the average correlation values across all eight place types. The purpose of this table is to \nhighlight  (in)consistencies  between  metrics  and  to  identify  potential  sensitivities  of  these \nmodels  across  place  types.  Note,  Metric  #3  is  inversely  correlated  with  all  other  metrics. \nThus, these were this inverted to positive values so the average correlation would maintain \nits accuracy of strength, regardless of signing. Consistently high correlation values with a \nrelatively low standard deviation suggest that these Metrics are likely to produce similar results. This table highlights that Metrics #4, #5, and #6 maintain very high correlation and low \nvariance across all place types. Metric #2 also seems to be highly correlated with Metrics #4, \n#5, and #6.  \n\nTo depict these data visually, several maps were generated (Figures 1-6, for Metric #1 – #6, \nrespectively). Given the diversity of values for each of the different Metrics, we created Table \n2, which identifies the grouping of values for each of the different legends. Using these visuals one can see differences in the relative distribution of high to low access to various place \ntypes. For instance, Metric #1 shows a clear visual difference from the other Metrics (which \nis also clear in Table 1). Also, the overall consistency of Metric #2 with Metrics #3 – #6 is \nalso fairly apparent in these figures. Note, the groupings used in these figures were not the \nvalues used to conduct the correlations (correlations were not run by groups). Instead, correlations were conducted on the raw values produced from each metric for each of the block \ngroups. The figures are providing only a visual reference with the groupings of data produced \nusing Natural Jenks, these groupings were not used in the correlation analysis. The figures \nonly symbolize the results of the metrics for access to outdoor recreation. \n\nA summary description of these figures is provided here. Figures 1 and 2 illustrate the results \nof the count of place types within each block group (Metric #1) and the density of place types \nusing kernel density (Metric #2). The darker color indicates that a block group has a greater \nnumber and density of urban place types. Alternatively, as the color gets lighter, there are \nfewer place types and a lower density of place types. Figure 3 illustrates the results of the \naverage proximity to place types. The darker color shows a shorter distance to the outdoor \nrecreation  and  as  the  color  becomes  lighter,  it  shows  a  longer  distance  to  the  destination. \n\nDiscussion and Conclusion \n\nLandscape architects are regularly involved in community design and transportation planning. Finding models that provide reliable metrics and are easy to perform can help facilitate \nrapid  iterations  of  design  and  planning  recommendations.  In  this  study,  we  compared  six \nmetrics that measure accessibility to different place types and showed differences between \nthem. Results indicate a high correlation between metrics #5 of the 2-SFCA method, #6 of \nthe gravity model, #4 of the number of block groups within each place type service area, and \n#2 of the kernel density. Furthermore, we provide a stark warning about the dangers of using \na  single  geospatial  metric  –  especially  if  the  metric  needs  further  empirical  evaluation  to compare  its  reliability  and  effectiveness.  The  2FSCA  (Metric  #5)  and  gravity  (Metric  #6) \nmodels have been well published in the literature (KAPATSILA et al. 2023, LIU et al. 2022, \nLUO & QI 2009) but can be more complex to run than other metrics (Metric #2), though these \nare highly correlated. This comparison highlights the potential trade-off between model complexity and the outcomes. It will be important for future studies to ascertain the value of the \nmore complex models. For instance, correlations between models might be high, but do they \nmaintain the same level of consistency when other variables are included (e. g. demographics \nor disability status)? If reliability is maintained, then simpler methods should be used first, \nwith  the  more  complex  methods  becoming  necessary  only  if  there  is  a  good  empirically-sound reason. \n\nOur analysis has shown that some models of accessibility differ quite substantially. At the \nsame time, some of these models share a high statistical similarity. One of the challenges \nthese models provide is that they can serve to validate actual travel times and provide data to \ninform planning policy. However, there are limited studies that attempt to connect these models  to  social  satisfaction.  Our  results  are  aligned  with  other  studies  that  compared  simple cumulative opportunity measures and the measures produced by the gravity model to under-\nstand if there is a significant correlation or not between them. The results showed that cumulative  opportunity  measures  can  substitute  complex  measures  like  the  gravity  model \n(KAPATSILA et al. 2023). It can be argued that social satisfaction is an important indicator of \nthe quality of life, perhaps more so than just assessing how long it takes someone to get from \npoint A to B. Thus, to validate these models, a future study should study the statistical relationship between each model and how they relate to social satisfaction. Further, we also anticipate gathering empirical data on the time to travel and modes of travel for people living \nwith disabilities. This information can then be used to compare differences between the general public and those with disabilities – not only for functional access to place types but more \nimportantly for how the spatial relationship to these place types influences social satisfaction. \nThe study can contribute to a wide range of fields, including landscape architecture, urban \ndesign,  urban  planning,  and  transportation  planning.  Yet,  landscape  architects  do  play  an \nimportant role in helping design access to a range of different place types, particularly greenspace and open space. With this work, we have established the importance of testing different \nmodels  to  determine  community  access  to  place  types,  including  outdoor  recreation.  This \nwork provides a means to connect accessibility and the design of urban spaces, to create more \nsuitable and equitable access to different place types for all citizens. \n

Eroding Terrains: Developing Computational Design \nTools for Interactive Site Erosion \n\nAbstract: Landscape erosion processes can be problematic and are universal in their effect on all forms \nof landscape contexts and conditions. Hydrological erosion processes are important features of ecologies, yet are often extremely problematic, and can be exacerbated by climate extremes, weather events, \nanimal and human activities, and especially transformations through agricultural processes. This research documents and proposes computational design tools and methods for erosion simulation in real-world scenarios. While there are many examples of soil erosion modelling in the life sciences and engineering fields, they are rarely applied at the detailed scale of the landscape-, architecture- and design \ndisciplines. The work  attempts  to  leverage erosion  processes  for  design  by creating  new  workflows \ninside familiar design and modelling programs. Applications may vary between agricultural land and \nareas of accelerated climate change, however, the test case for this application is in a fire-affected landscape particularly prone to erosion. This research seeks to unite site investigation and survey techniques with interactive erosion modelling within AEC design software. By introducing intuitive ways to model erosion processes mitigation becomes possible within the landscape analysis and design process, creating opportunities to avoid erosion before it occurs. \n\nIntroduction \n\nErosion is a fundamental landscape process that underlies all landform generation. In combination with transport and sedimentation, it is integral to all landscape processes and their \ninhabited ecologies (KONDOLF 1994). Despite many advancements in the various ways in \nwhich humans have formed and manipulated the earth, erosion remains process we still struggle to work with. How we counter the degenerative effects of erosion have barely changed \nover  the  last  century  (BATES  &  ZEASMAN  1930).  This  research  is  particularly  focused  on \nhydrological erosion as one of the key forms of erosion affecting landscapes worldwide at an \naccelerating rate due to climate change and land-use practices. The perceived demand for \nsuch techniques comes from both an observed lack of such analyses executed in the AEC \nindustries,  and  the direct demand for  such  methods  from  within  parallel  research projects \n(MELSOM 2022).  The  parallel  research  projects  inform  this  case  study  and  initial  practice \nmodel for this technique, namely the specific and heightened erosion issues faced by post-fire landscapes, although the techniques are equally applicable to a wide range of other landscape and built environment circumstances, such as disused agricultural and cleared landscape plots, de-vegetated drought-affected areas, and building construction sites. The work \ndocuments the current progress in developing specific tools for common erosion models at a \nlocal site scale, leveraging high-resolution user-generated site models. \n\nRecent shifts in weather patterns, storm event frequency and magnitude, connected with on-going climate change exacerbates the loss of soils as a key societal issue that already dates back  centuries  (MONTGOMERY  2012).  It  commonly  results  in  the  loss  of  arable  land,  increased landscape disturbance, the destruction of ecological systems, as well as negative effects on the built environment. Erosion simulation is an answer in the field of civil engineering, providing insight to where and how it might occur. Large to medium scale modelling is widespread, and often leverage GIS or proprietary and specialised modelling software solutions (MAY et al. 2005, ARGENTIERO et al. 2021). Furthermore, there is also some scepticism in the relevance and accuracy of such simulations at territorial scales (MONDA et al. 2017). Nevertheless, these models tend to focus on the territorial or catchment scale, distinctly abstract from the detailed site scale and restricted to the realm of specialised engineering applications and computation intensive instrumentation (KANITO & FEYISSA 2021). \n\nAt the design scales there are clear and compelling examples of methods that propose to work \nwith avalanches and sedimentation events instead of against it. Here materials are redistributed as they erode or arrive on site (HURKXKENS 2021). The potential to combine detailed site data with predictive or preventative erosion modelling provides many compelling avenues for landscape management, generative possibilities, effective hybridisation of erosion, \nsedimentation, and design. \n\nIterative Erosion Modelling \n\nHydrological erosion types follow several generally established patterns and types, each often the precursor for the next: splash, sheet, rill, gully, bank and stream, ordered by increasing \nscale. Rill and gully erosion have been isolated as the most useful for this research, to generate a simplified simulation tool. Existing specialised applications in earth engineering have \nformed  both  the  basis  for  this  selection  and  a  model  for  confirmation  of  applicability \n(HANCOCK et al. 2008). As can be seen in such precedents, high-resolution site data is required \nin order to generate relevant results. Detailed, recent models are a necessary starting point, \nwith medium to high-resolution laser scanning or photogrammetry a base requirement. Due \nto the nature of rilling scale erosion sites, photogrammetry is particularly interesting as it excels \nin open ground, un-vegetated areas, allowing a consistent accuracy of 10cm down to 2cm. \nOpen agricultural fields, mining landscapes, and post-industrial sites are suitable examples \nof high-resolution photogrammetry subjects, or in the case of this research, post-fire affected \nsites, cleared of foliage and vegetation canopy. The site of Rosedale, NSW, Australia was \nchosen as an ideal candidate for such a fire-affected erosion modelling scenario (Figure 1). \n\nA simplified model closely mimics the established model (KANITO et al. 2021, HANCOCK et \nal. 2008) yet allows for a close to real-time feedback loop, and the integration of iterative \nworkflows. To this end, Rhinoceros was chosen as a base software, with the integration of \nscripting and plugin development to provide a seamless connection with three-dimensional \ndesign  software  that  is  both  intuitive  and  an  industry  standard.  Rather  than  analysing  the \nmodel  outside  the  design  software,  it  is  compatible  with  other  AEC  design  software  and \nmethods, without interrupting the design process. It is also compatible with GIS software and \nvarious spatial data types. This simplified process can integrate other landscaper factors such \nas soil characteristics, barriers, and vegetation to improve the accuracy of the simulation further. \n\nThe concept of iteration is also considered an important simulation criterion within the design \nspace, in this case, differentiated into two iterative models, integral and event iteration: \n\nIntegral  Iteration  describes  the  case  in  which  the  eroded  model  accounts  for  erosion  and \ndeposition  within  the  same  continuous  modelling  cycle,  with  eroded  areas  having  a  compound effect on their continued erosive processes, rather than acting on existing site characteristics alone, and allowing for changes to the site to be made during simulation.  \n\nEvent Iteration modelling allows for separate events, with a shift in intervening characteristics (vegetation, topography, physical intervention). This model allows for multiple hydrological events to take place separately, with shifts in the intervening period. This is an im-\nportant factor in many erosion-prone landscapes, as long-term erosion effects are often generated through multiple or repeated erosion events that are incremental, rather than occurring \nin one discrete event. \n\nTerrain Characteristics also play a key role in understanding the processes of erosion. Many \nfactors affect its course over the surface in landscape terrain models and have therefore been \nincluded in the erosion model, with varying levels of integration (Figure 2). \n\nSoil Texture is a key characteristic in erosion models. Different soil types erode and deposit \nat varied rates, and the standard simulation technique of a reference raster image has been \napplied. \n\nTerrain Slope and rate of slope change are fundamental erosion characteristics, regardless of \nsoil type, as they affect the speed and acceleration\/deceleration of water movement and there-\nfore energy of the water, and its propensity to either erode or deposit material. To this point, \nonly slope angle has been implemented.  \n\nTerrain Roughness at this site scale. Here individual terrain details such as vehicle tyre tracks, \nanimal marks and soil or rock texture can have a huge influence on erosion patterns. Not to \nbe  confused  with  soil  texture,  additional  roughness or  triggers  to  erosion  can be  included \neither as proxy mesh, with noise, or as a raster image. \n\nErosion Resistance is the demarcation of areas that physically cannot erode or are otherwise \nresistant to erosion due to solid barriers, vegetation, root systems, or other physical hindrance. \nThese areas can be either physically modelled or marked with images, allowing a graduated \neffect. \n\nEach of these terrain characteristics has been integrated into the workflow to form a working \nmodel for a limited range of case studies (Table 1). Surface water flow calculation is based \non detailed DTM data and simplified erosion simulation using reference parameters implemented with the computational terrain modelling plugin. Preliminary simulations assume a homogenous substrate, although the overall resistance characteristics to erosion can be manipulated. Additional testing and verification would be required for broader applications with accurate and repeatable results. \n\nSurveying and Erosion Modelling Tool \n\nThe implementation and testing of the erosion simulations have centred around specific post-fire landscapes. These make appropriate sites, as they are often immediately susceptible to \nreal erosion following an intense fire event. Erosion in these landscapes presents a massive \nissue for many authorities and communities. Analysis conducted in such landscapes has determined that up to 50 times more erosion can take place in an extremely fire-damaged landscape than in one marginally affected by fire, as well as many other mitigating factors (TULAU et al. 2015). To survey the affected terrain, there are precedents for UAV imagery and its use in general erosion mapping and simulation (MISTHOS et al. 2019). This survey method functions well in circumstances where erosion risk is high, due to lack of ground cover and exposed terrain. It also enables successive landscape surveys and allows for the mapping of landscape change and subsequent model adaptation. In addition, reference layers for erosion \nresistance can be generated from this data. In this case study, industry-standard photogrammetric  software  –  Agisoft  Metashape  –  was  used  for  this  stage  of  research,  however,  the \ndelineation of the scanned site and predetermined route may aid in generating more accurate \nresults with repeated scans of the same site, documenting its evolution and supporting iterative model generation. The required resolution and detail of the test site required a relatively \nlow altitude (40m) scan height with a high overlap of 80% in both directions, with an angled \ncamera (75°) flying in a gridded pattern around tree-bases (a common area of photogrammetric error). \n\nThe  simulations  are  built  on  top  of  Docofossor,  a  terrain  modelling  plugin  for  the  visual \nscripting environment Grasshopper of Rhino 3D (HURKXKENS et al. 2019). It uses regular \nraster grids as underlying data-model for its terrain representation. This enables simple modelling operations in cut and fill using distance functions. Like the plugin, the erosion simulations make use of build-in class methods from RhinoCommon or via the Rhinoscript python \nimplementation to compute the grid values.  \n\nThe implication allows for animation and simulation of any part or any duration timeline. For \ndetailed areas of the case study site (Figures 3) of around 50 x 50 m, animation frames can \nbe calculated in less than 5 seconds on a standard workstation set-up, facilitating an optimal \nsimulation-to-design workflow. When compared with large-scale surface water flow, the results  demonstrate  that  a  laminar  surface  concept  of  layered,  continuous  water  supply  and movement works well to imitate site-observed erosion phenomena in scale, extent, and pattern (Figure 4). Within the chosen case-study typology of fire-affected areas, there are ample examples and areas for verification and refinement of the erosion models in various soil and \nsurface conditions. The varied performance in differing substrates is an area for further research and study. \n\nDiscussion \n\nThe resulting model combines a cleaned, photogrammetric terrain model collected on site, \nwith a scalable yet detailed simulation of rill-model erosion. This can form the basis for site \nselection, risk analysis, or developing of erosion mitigation strategies in high-risk areas.  \n\nThe various data elements produced during the described process consists of base data and \nsite analysis, as well as simulation data, such as the resulting flow-paths, erosion \/ deposition \npatterns and debris transport lines. The results reinforced the individual and combined roles \nthat terrain roughness, converging slope details, and obstacles such as trees, fallen tree trunks, \nand rocks play in the resulting site-specific example. Site observation reflected the general \ntrends of the erosion model; however, additional calibration can be applied to further refine \nthe exact volume of material transported. The nature of the site material, being a mixture of \nfine ash, partially fire-consumed debris and dry topsoil that are non-uniformly distributed on \nthe terrain lead to a model in which exact depths and volumes of material erosion and depo-\nsition are variable. Therefore, the erosion paths and patterns can be shown to have a higher \nfidelity than the depth of erosion. As referred to in the conclusion section, additional material-specific experimentation or specialist data would help to refine these models.  \n\nThe potential for iteration in this process, both as a computational tool in simulation, and a \nworkflow for gradually improving and refining the model worked well, especially given the \nresponsiveness  of  the  algorithm.  The  proposed  additional  applications  for  iterative  design \nproposals  using  the  same  process  are  feasible  in  both  implementation  and  viable  design \nmethod. \n\nConclusion and Outlook \n\nThe  relevance  and  importance  of  erosion  simulation,  and  its  challenges  within  the  design \ndisciplines are established, and the case is made for its viability and implementation. The \nlack of a designer-level toolset to deal with these issues has been addressed in this research, \nas well as the potential of these techniques for the AEC professions. The range of further \napplications and possible sites is only increasing with the growing impacts of climate change. \nSuch simulation techniques can be deployed to predict erosion issues that may occur in the \nfuture  and  allow  for  pre-emptive  interventions  that  may  avoid  or  transform  such  erosion \nevents into more positive outcomes. Within the space of fire events alone, there is a huge \nscope for adjusting landscape management practices to better recover from fire events, especially their implications for soils, sediment, and the fostering of their landscape biodiversity \n(TULAU et al. 2015, ATKINSON et al. 2020). \n\nThe imitation of real-world site conditions and recorded erosion sites are of key importance \nto further refine the plugin settings based on local conditions and the predictive accuracy and \nusefulness of the technique. Similar optimisation tools such as RAMMS have also been carried out both during and after the release of landslide and rockfall computational simulation \n(CHRISTEN et al. 2012).  \n\nFurther development is required to optimize and better simulate existing high-resolution simulation  models,  as  well  as  the  integration  of  these  techniques  into  teaching,  research,  and \npractice (IGWE et al. 2017). There is a strong potential for generating data layers for other \napplications and GIS systems and facilitating new forms of engagement and multidisciplinary \ncollaboration in landscape engineering, remediation, and management projects. Where erosion can be predicted and mitigated, the potential for design with erosion processes emerges. \nThe possibilities of hybrid design processes that work hand in hand with the environment, \n(GIROT & HURKXKENS 2018) open areas of potential design endeavour, in which the landscape can be shaped over time with minimal intervention and resources. \n

Exploring Less Geometric Landfill Slopes through \nParametric Digital Modelling \n\n\n\nAbstract: Massive and visually disruptive landfills in urban areas can potentially be seen by hundreds \nof thousands of people daily. Even after landfill closure, constructed slopes and ridgelines can contrast \nwith the surrounding terrain because of their signature geometric form. This paper uses three landfills \nin Southern California to demonstrate the need for better visual mitigation, test the sculpting of landfill \nslopes through parametric digital modelling, and then discuss how the process can be enhanced for real-world application that improves visual quality while meeting engineering requirements. This is an area \nwhere landscape architects can make greater contributions in mitigating the visual impacts of landfills. \n\nIntroduction \n\nLandfills are the primary way that non-recyclable municipal waste is managed. Incineration \nis eschewed due to the introduction of carbon particulates and a harmful airborne brew of \npotentially carcinogenic chemicals associated with plastics and other modern manufactured \nmaterials. The ever-growing volume of waste is also a major concern and landfills can be \nmassive. Besides the large physical dimensions of landfills, the process of land filling requires a substantial investment in time, expense, and effort to locate suitable sites, meet stringent permit requirements, prepare the site for liquid containment and methane gas extraction, manage daily fill operations, and mitigate a full range of impacts. For these reasons, the trend is towards fewer, but larger landfills (EPA 2014, 2-11). \n\nMany landfills are geometric in shape and the planar sides and mesa-like top can be recognized from miles away. In urban areas, the number of viewers can be numbered in the hundreds-of-thousands, and unsightly views or the presence of landfills can negatively impact property  values  ranging  from  3-7%  (REICHERT  et  al.  1991,  BOUVIER  et  al.  2000,  READY \n2005). Moreover, the scale of urban landfills can be dominating. For example, Puente Hills \nlandfill in Southern California, which closed in 2013, has a footprint of 283 ha (700 ac) and \nis 150 m (490 ft) in height. Counting buffer land, the facility consumes 526 ha (1,300 ac).  \n\nObjective \n\nLandfill design and operations generally fall within the realm of engineering and scientific \nconsultants.  Landscape  architects  become  involved  when  considering  landfill  aesthetics. \nTypically, these activities are related to landcover planting and the preparation of visual analyses and simulations when preparing environmental impact documents prior to landfill permitting. As “shapers of land”, the objective of this paper is to explore how landscape architects might become more involved in the earlier stages of landfill design through enhanced \ndigital modelling so the landfill shape upon closure can better blend with the terrain context. \n\nExtending the Role of Landscape Architects? \n\nThe origin of this paper derives from the primary author’s environmental consulting work \npreparing visual assessments for two landfills in southern California: Elsmere Canyon Landfill (early 1990s) and Simi Valley Landfill Expansion (mid 2000s). In both cases, the landfills were  of  the  canyon\/valley  type.  Extensive  3D  computer  modelling,  GIS-based  viewshed mapping, and before\/after photo simulations (Fig. 1) were conducted to determine visual exposure and estimate visual impacts as viewed from key observation points (KOPs). These points were public gathering areas like parks, major travel ways, and nearby residential and commercial areas at distance ranges from 0.3 to 8.5 km (0.2 to 5.3 mi). \n\nIn the case of Elsmere Canyon Landfill, the permit was denied after much public opposition. \nSimi Valley Landfill was already an operational landfill in mid-life, and the expansion was \napproved after a multi-year environmental review process which addressed public concerns. \nEven though the expanded landfill conformed to conventional engineering design, the pri-\nmary author wondered if landfill slopes could be made to appear less geometric and better \nblend with contextual terrain. Instead of involving landscape architects to assess or mitigate \nvisual impacts after landfill design is nearly complete, the role of landscape architects could \nbe  expanded  to  perform  landform  sculptural  studies  earlier  in  the  design  process.  Closely \ncoordinating  with  engineers,  slope  sculpting  would  still  need  to  meet  fill  volume  requirements, access road routing, methane gas piping, and comply with efficient daily operations. \nThis paper only explores landform, and does not address vegetation, atmospheric conditions, \nor other factors affecting visual quality. \n\nConcept Overview \n\nEnhanced Slope Sculpting to Reduce Visual Impacts \n\nThe goal of the “sculpting” process is to introduce more slope undulation into uniform slopes \nto replicate convex finger ridges and concave drainages found in contextual terrain, but to a \nlesser  degree  to  still  support  engineering  requirements.  This  will  increase  tonal  variation \n(shade\/shadow)  patterns  which  will  better  blend  with  contextual,  undisturbed  terrain.  As \nviewing distance increases and atmospheric factors become more pronounced, tonal contrasts \nare more important to visual mitigation compared to texture or hue variations. \n\nSlope Sculpting Procedures \n\nLandfill form emerges as systematic lifts (layers) approximately 8-20 feet thick. Each lift is \ncomposed of cells where daily to weekly accumulation of refuse is compacted and covered \nwith 6” of soil. Once cell placement reaches the perimeter of the lift, the outer slope is shaped \nat a not to exceed 1.5:1 ratio. A series of 15’ wide benches are also added per EPA regulations \n(EPA 1988, 62). Under the sculpting concept, none of these standard filling and grading operations would be appreciably altered until the lift edge nears. At this point, GPS-enabled earth moving equipment would grade an undulating edge, that over years, would emerge as finger ridges or drainages on the slope much like 3D printing. The precision of GPS is essential to accurately locate and place cover material along the undulating lift perimeter where \nthe eventual slope form is not immediately apparent. \n\nTowards this goal, several additional steps are needed beyond traditional engineering design: \n\nNumerically determine the slope gradient and vertical\/horizontal convexity of the surrounding  topography  (usually  applicable  to  canyon\/valley  landfill  types)  for  use  as  a \ncontextual referent. \n\nIteratively sculpt a 3D landfill computer model where exposed sides more closely replicate contextual slopes and topographic features, and then shape a rounded cap or ridgeline profile that undulates as opposed to a flat mesa. The model footprint may have to be slightly expanded to offset anticipated volume losses compared to conventional geometric forms, or the overall height increased (LAW et al. 2008). \n\nTransfer the preliminary sculpted model into Civil 3D or other engineering software for detailed design and implementation documentation. \n\nPrepare a grading plan that can be uploaded into GPS-enabled refuse\/earthmoving equipment to guide landfill slope shaping over decades. \n\nMethods \n\nThere are multiple  methods to analyze  undulations in topographic surfaces to set numeric \nbase conditions for slope modelling: slope aspect and gradient, planform curvature, profile \ncurvature,  topographic  openness,  and  landscape  roughness.  Some  numeric  techniques  include fractal dimension indexing (FRAC) (CUSHMAN et al. 2005, 103-104; MCGARIGAL & MARKS 1995), standard deviations of contour line segments, and topographic position indexing (TPI) (JASIEWICZ & STEPINSKI 2013, MOKARRAM & HOJATI 2016).  \n\nTo identify a landfill as a test case for parametric digital sculpting, Zhong (2020) inventoried \n43 landfills including 14 active and 29 closed landfills larger than 100 acres in Los Angeles \nCounty. As part of the review, FRAC indices were calculated for the landfills to assess how \ngeometric the slopes appear and identify candidate landfills for further analysis. \n\nAfter candidate landfills  were reviewed, attention  turned towards  which digital  modelling \nsoftware might be most useful. WESTORT (2015, 225-226) discusses the need for improved \nlandform design tools which are 3D, provide geometric control, are easy to handle, provide \nquick response time, and are quantitatively accurate. Furthermore, the ability to iterate before \nand during the construction [or design] phase is desirable. From our experience, Autodesk \nCivil 3D meets most of the criteria for Digital Elevation Modeling (DEM) but is deficient in \ninteractive surface sculpting. A spline modeler like Rhino is better suited for this purpose and \noffers parametric automation through Grasshopper terrain plug-ins like Docofossor, Bison, \nand TOPO kit. Upon initial review, it appears that these plug-ins do not offer the sculpting \nfeatures\/control as envisioned without additional customization. \n\nTo test how inclined finger ridges can be introduced to geometric landfill slopes while still \nmaintaining landfill capacity, ZHONG (2020) used the closed Puente Hills Landfill to proto-type  a  hybrid  manual-parametric  landform  sculpting  process  using  a  customized  Rhino\/ \nGrasshopper script using 3D control framework (Fig. 2). Preparatory work consisted of man-\nually digitizing major ridgelines, finger ridges, and intervening drainage flow lines from the \nundisturbed  1950  topography  as  a  fully  detailed  referent  of  pre-landfill  conditions.  Points \nfrom this skeletal landform structure were then filtered through a Grasshopper script to interactively reduce ridge and valley point detail as a percentage. Two highpoint locations from \nthe 2018 landfill top deck (or intended height of a planned landfill) served as landfill closure \n(2013) height parameters. Once parameters were set, a simplified surface was interpolated \nthrough the points. Using various combinations of 22%, 66%, and 88% remaining ridgeline \nand  valley  points,  seven  surfaces  (P1-P7)  were  generated  for  comparison.  Processing  per \niteration took about 4-6 hours. \n\nResults \n\nAfter the manual-parametric methods were established to generate landform alternatives, further modelling exploration was undertaken. For comparison against standard landfill design, \ntwo planar geometric surfaces (G1-G2) and three advanced contoured surfaces (A1-3) were \nmanually defined through contours and generated through Rhino. The G1 and G2 surfaces \ntypified landfills of low visual quality and the A1-3 surfaces represented enhanced landfills \nhaving some amount of slope undulation (Fig. 3). \n\nFig. 3:  Results  were  compared  for  manual  geometric,  manual  advanced  contouring,  and \nparametric  modelling  of  landfill  configurations  against  1950  existing  topography \nand the 2018 shape configuration of the Puente Hills landfill (ZHONG 2020) \n\nOnce the 12 alternative landform  surfaces  were  modelled in Rhino, the surfaces  were exported into Civil3D for volume calculations. Two sets of volumetrics were compared: 1) the \n1950 pre-landfill referent surface compared to the 12 Rhino alternatives (2020) for total volume capacity; and 2) the 2018 DEM dataset (2013 closed landfill conditions) compared to \nthe same 12 Rhino alternatives. The latter comparison is intended to directly reveal net volume  gain\/loss by introducing  more  undulations to constructed landfill  surfaces.  Of the 12 \nalternatives, three showed capacity gains:  A3 (+5%), G2 (+24%), and G1 (40%). Surface \nundulations for the closed landfill and among the 12 alternatives were also compared through \nslope mapping and aspect mapping which quickly made differences visually evident. \n\nDiscussion and Conclusions \n\nModelling results reveal that although simplified, the P1-P7 parametric surfaces too closely \nresemble the complexity of the 1950 topographic referent. P1-P7 volume capacity was not \nsufficient, slope angles were not constrained to the 1.5:1 standard (not part of script), and \nexcessive slope undulations\/aspect variation would likely make implementation difficult. As \nexpected, introducing more surface undulations decreased landfill volume capacity for most \nalternatives compared to the more geometric landfill forms. \n\nThrough this exploratory test, however, advancements were made in parametric surface modelling that enabled rapid iteration, testing, and comparison of landfill alternatives. The A3 \nalternative demonstrates that more slope undulations can be introduced to improve landfill \naesthetics while still maintaining capacity volume. Rapid iteration, as demonstrated through \n12 alternatives, is essential in finding the right balance of improved aesthetics, capacity volume, and other engineering factors to be tested in future work. \n\nResults demonstrate the potential of applying digital sculpting tools to enhance landfill slopes \nto make them appear less geometric and planar. Artistic manipulation must be coupled with \nengineering requirements to maintain slope stability, constructability, and volume capacity. \nGPS enabled refuse\/earth moving equipment can provide the precision and locational accu-\nracy across large lift expanses to achieve more naturally appearing “outer shell” forms. \n\nMaking progress to sculpt landfill surfaces iteratively and more freely for aesthetic purposes \npartially fulfilled the initial objective of this paper. Full realization of the objective requires \nlandscape architects to better understand the complexity, timing, and workflow commensu-\nrate with landfill design and operations if they are to be involved. Based on past professional \nexperience  with  landfills,  many  engineers,  technical  consultants,  regulatory  agencies,  and \nenvironmental assessment  specialists are involved, and the  design and permitting requirements are substantial. Reducing visual impacts is a worthwhile goal but knowing when and \nhow optimized landform modelling with a greater emphasis on aesthetics can be introduced \ninto the design process is challenging. To be cost- and time-efficient, it needs to be used early \nin the process, offer rapid iteration, meet engineering requirements, and then be passed off to \nothers for technical refinement. At the landfill operational stage, extra edge\/slope requirements must also be safe and compatible with the myriad of choreographed activities taking \nplace on the working deck. \n\nSeveral limitations are evident: more documented research is needed regarding the long-term \naesthetic  impacts  of  landfills  upon  closure  after  vegetation  has  matured;  more  parametric \ncontrols are needed for slope shaping, the Rhino to Civil 3D transference needs to be more \nstreamlined; and most importantly, a test case involving engineers needs to be identified. \n\nFuture Work \n\nFuture improvements are needed to incorporate more parametric control of slope undulation \nand shaping. Additional ridgeline control is also needed for shaping the landfill cap to avoid \na mesa-like appearance. A hybrid between the P and A models is envisioned. \n\nIn addition to ridgeline controls, select parametric contours (splines) could be added as control  features  to  parameterize  surface  undulation.  Parameters  would  be  based  on  sinuosity \nwhich is simply calculated by dividing the sinuous contour length by the straight distance \nbetween the contour line endpoints. Calculating sinuosity is typically associated with stream \nsystems but can also be applied to characterizing landfill slopes where FRAC and TPI indices \nare too general to control shaping. Referencing the sinuosity index of contextual landform, a \nfew parametric contours placed at strategic locations at the edge of landfill lifts could seed \nthe formation of finger ridges. The finger ridges would become more apparent as the landfill \nheight grows with each successive lift much like 3D printing. \n\nDifferences in slope sinuosity can be illustrated using existing portions of the Lopez Canyon \nlandfill in Sylmar, California (Fig. 4). In this 3D view of the 2016 DEM surface, a contour \nline (L1) traces undulating slopes of the contextual foreground slopes, whereas the more linear contour line (L2) traces the constructed geometric slope of the landfill face rising above \nthe foreground ridge. The calculated sinuosity indices (SI) are 1.44 and 1.19, respectively. In \na revised parametric model, the SI of L2 could be adjusted to resemble the undulations of L1 \nmore closely while still allowing for proper slope benching, access road construction, and \nmethane gas piping. This will be tested as the Rhino\/Grasshopper script is improved. \n\nThese future improvements should enhance modelling capabilities, increase ease-of-use, and \nprovide better integration with software used to prepare construction documents. Discussions \nare also needed with landfill designers with regards to landfill operations, sequencing, and \noverall feasibility of this envisioned approach to landfill aesthetics and visual mitigation. \n

A Mixed Reality Experience: Advancing Design \nDecision-Making with Performance Metrics \nThrough Augmented Reality and Physical Media \n\nAbstract: Augmented reality and virtual reality have effectively served as an immersive environment overlayed within the real world. These experiences are, however, often static and limited in function, primarily, as a full-scale walk-through. This study tests the capabilities of including real-time interactivity and engagement as a tool for dynamic design decision-making. The idea is further explored by integrating landscape performance metrics and project goals to determine how this supplemental data may influence the participants design decision-making. The synchronization of qualitative and quantitative information through a mixed reality experience has major implications to design development as the stakeholder groups have the opportunity of experiencing real-time responses to their engagement of a design project. \n\nIntroduction \n\nThrough the emergence of landscape performance and the integration of quantitative metrics \ninto  outdoor  spaces,  technology  and  innovate  methods  can  begin  to  communicate  naturebased benefits as tangible outcomes to comprehend the complex ecological, social, and economic relationships of our complex environments (BECK 2015). Due to the fact that many of \nthese ecosystem services are intangible and abstract, new methods must be explored to effectively  communicate  these  invisible  landscape  performance  outcomes  into  a  perceptual \nrealm for a comprehensive understanding of design decisions (ZHANG et al. 2021). The viability of this process can be explored at both full and reduced scales as a real-time feedback \nmodel using a hybridization of augmented reality and physical media; catalysed as a mixed \nreality (MR) experienced in the p[AR]k.  \n\nThrough this comprehensive qualitative and quantitative mixed reality process, divergent decision-making, predicated on the information presented in an augmented reality (AR) interface, can be made for multiple responsive and sensible outcomes (LAHAIE 2016). This ultimately generates an immersive, engaging, and interactive design process for a more universal \naudience to participate in for specific needs from a landscape architecture project, shown in \nFigure 1. \n\nThe modeling of dynamic landscape benefits within a mixed reality experience of both physical demonstration pieces and augmented reality interfaces creates an accessible means to \nparticipate in the design development of any project. Augmented reality is not only gaining \ntraction as an innovative representation tool but with the integration of parametric modeling \nand performance metrics it can also serve as a decision-making tool (DUENSER et al. 2008) \nto the design process for specific goals and outcomes. With the incorporation of performance \nmetrics into the augmented interface, data becomes responsive to real-time change, performance parameters, and user decision-making.  \n\nA Mixed Reality Experience and Workflow \n\nThe p[AR]k attempts to model these dynamic landscape benefits within a mixed reality experience of both physical demonstration pieces and augmented reality interfaces to reach a \nuniversal audience within a dedicated workstation comprised of a physical sandbox and com-\nputational hardware. Augmented reality sandboxes are becoming a common tool to understand topography; however, they are often limited to specific outcomes visualized as coloured \nheightfields projected on sand media. Although it is beneficial to understand these funda-\nmentals, the computational rigor of these models can be advanced further using parametric \nsoftware  to  measure  additional  terrain  characteristics  and  ecosystem  services  that  include stormwater management, carbon sequestration, and energy savings, shown in Figure 2.  \n\nProviding visualizations, interactive properties, and tangible media in a mixed reality experience gives the user ownership and agency behind their decisions for outdoor spaces. Professionals,  community  members,  and  stakeholder  groups  can  come  together  and  learn  the \nimpact of their decisions as their actions are stored in a database for further analysis of communal interests.  \n\nSandbox Station Capacity \n\nThe feedback collected from the point cloud of the sandscape is processed through the parametric modeling software to analyse and generate visuals with charted information based on \nvarious  parameters.  In  addition  to  sand  media  serving  as  the  terrain  model,  mobile  smart \ndevices, oculus quest controllers, or aruco markers can reference and embed various amenities  that  include  trees,  benches,  water  features,  paths  and  other  elements  onto  the  terrain \nmodel for a conceptual landscape performance rendition. There are several benefits from this \nprocess that include workflow and design development, design-thinking, scenario modeling, \ntrade-offs assessments, landscape performance, and co-creation and collaboration.  \n\nIn this study, users were put into a hybrid mixed reality experience of physical and augmented \nreality to address design opportunities within the scope of landscape performance. They were \nintroduced to environment, social, and economic scenario objectives that could be mitigated \nthrough the manipulation of a physical sandscape and augmented placement of trees within \na hypothetical neighbourhood pop-up park. With this experience, users manipulated the sand \ntopography and moved pieces around, perceiving the impacts different designs had in achieving stormwater management, carbon dioxide (CO2) sequestration, and energy savings. Simultaneously, data readouts from the topography, amenities, and surrounding neighbourhood \ncontext communicated quantitative data on the design iterations to assess the trade-offs and \nperformance of different scenario models related to ecosystem services. With each change or \naddition to this AR model, the data readouts instantly updated to inform next moves within \nthe design decision-making process. \n\nThe metrics and formulas for these parametric performance models were configured from \nmetrics and calculators commonly used by allied professions that include iTree’s tree benefit \ncalculator, NRCS stormwater calculator, and the US Department of Energy typical household \nenergy consumption. The iTree benefit values used in the different performance scenarios \nwere based on a thirty-year-old healthy honey mesquite tree.  \n\nPerformance Objectives \n\nWith the influx of real-time quantitative data that updates during this process, there is a profound opportunity to fundamentally shift design thinking and intent from these augmented \noutcomes. By embedding measurables and metrics to this workflow, this new design process \nand methodology of a MR experience can potentially emerge that enables the respective parties to generate robust design strategies for evaluation on specific goals and objectives. As \npart  of  this  performative  MR  experience,  the  interface  can  be  configured  to  display  data readouts communicating quantitative information throughout the design process to assess the \ntrade-offs of different scenarios as a divergent process (CIRULIS & BRIGMANIS 2013).  \n\nThere are many different AR programs available for users to immerse themselves within a \ndesigned space, however, the values most programs don’t provide is the ability to synchronize it to an industry standard modeling software such as 3D Rhinoceros to further refine a \ndesign concept. This is made possible with the plugin additions of Grasshopper (parametric \nmodeling) and Fologram (AR platform) to create a real-time feedback between the perceptual \nAR interface and the cognitive modeling software. Grasshopper manages and integrates the \ntangible and intangible analytics for performative landscapes while establishing a dialogue \nwith the Fologram application on a smart device. Fologram is then used to engage with the \ndesign  model  using  either  finger  gestures  on  a  touch  screen  or  by  scanning  printed  aruco \n\n\nmarkers, referencing different design elements such as trees, pavers, or benches. The programs in tandem create a responsive workflow of reciprocating outcomes based on the decision-making process of the user. The perceptual experience created can be viewed simultaneously on the computer and in the physical world, blending the two in a hybridized environment.  \n\nWithin the p[AR]k project experience, users were evaluated on two different scenarios to \ndetermine if performance objective and metrics impacted their decision making. In the first \nscenario, users were only required to manipulate the p[AR]k space through a perceptual lense \nof  only  seeing  the  site  as  qualitative  and  figural  with  landforms,  water  features,  and  tree \nplantings. In the second scenario the users were provided different landscape performance \nobjectives that integrated and displayed quantified metrics to determine if and how this may \nimpact their design decision-making any differently. Performance scenarios included managing stormwater runoff, sequestering CO2, and reducing energy consumption from buildings.  \n\nPerformance Methods \n\nFor the stormwater runoff scenario, the surrounding impervious conditions of streets, sidewalks and buildings coupled with the park’s landforms contributed to a calculated stormwater \nrunoff volume from a typical 0.5” rain event. This volume served as a baseline objective to \nmanage through a catchment system (landscape depression) and trees. The runoff from those \nlandform conditions were conveyed through drainage lines, suggesting the most optimal location to place trees to intercept the runoff. In the carbon sequestration scenario, the EPA’s \nmetric for an average typical passenger vehicle emitting about 4.6 metric tons of carbon dioxide per year, or 10,141 pounds of CO2, was used to establish a site measurement for the \nsurrounding neighbourhood context. And according to the U.S. Department of Transportation, the average number of cars owned per household is about 1.88. Based on these statistics, \nthe surrounding residential households contributed a total of 247,853 pounds of carbon emissions annually. Lastly, the energy savings scenario used the U.S. Energy Information Administration’s average household consumption metric of 10,715 kilowatt hours annually. \n\nUsers  were  first  expected  to  manipulate  the  topography  to  create  dynamic  landforms  and \nwater features within the neighbourhood pop-up park, see Figure 3. This would ultimately \nimpact  stormwater runoff potential  while  simultaneously creating drainage  and  catchment \nsystems in the landscape. The participant quickly realized that either one large or multiple \nintermediate  catchment  systems  within  the  topography  could  not  contain  the  site’s  runoff alone and would also require the strategic placement of trees to help with the mitigation process through interception.  \n\nTrees can intercept runoff through both their tree canopy and root structure. For the modeling \nand  calculation process,  the tree’s  ability  to  intercept  runoff from  their root  structure was \nused and would be assessed on its performance based on its proximity to the generated drain-\nage lines in the topography. As the user realized this in their tree placement, they began to \nstrategically place trees within close proximity to the visualized drainage lines in order to \nmaximize their interception potential leading to a higher percentage of managed runoff. \n\nThe design of the neighbourhood pop-up park for CO2 sequestration was more ambiguous \nleading to less consistent tree placement strategy since this is a non-point source pollution. \nIn these types of situations, it was found during the study that when there are unclear demar-\ncations for tree placement users would often place trees with less reason or logic into the \nlandscape, shown in Figure 4. This did, however, lead to users manipulating the sandscape \ntopography to have less area dedicated to catchment basins so that more trees could be placed. \n\nTree placement within the energy savings scenario had similar results to the stormwater management one in that as users realized the relationship of a tree’s location to a building would \nreduce its energy use, their strategic planting gravitated towards those specific parameters. \nWith the energy savings, tree distance and orientation to the building would result in different \nkilowatt hours saved. This can be seen in the tree and building values in Figure 5. \nFor example, a tree in near proximity to the north facing façade of a building would be less \nbeneficial to a marginally further distanced tree from the south facing façade since that sun \nfacing façade would be absorbing the most, requiring more tree shade protection to reduce \nthe building HVAC use.  \nThe combination of the responsive interface, the ability to co-create and engage with different \nstakeholder groups, and the real-time integration of data can fundamentally reroute the design \nthinking methods. Abstract and formal ideas can merge into one process, helping the user \nengage, innovate, increase options, and see the implications of those decisions simultane-\nously with their collaborators as a cyclical feedback loop. \n\nResults \n\nAfter users participated in this study through the p[AR]k, they were provided a survey to \nassess if and how the integration of landscape performance metrics (quantitative information) \nimpacted  their  design  decision-making  (qualitative  information).  Out  of  this  beta  testing \ngroup of roughly thirty undergraduate landscape architecture students, one hundred percent \nagreed that the inclusion of landscape performance values impacted their design decision-\nmaking, as asked in the first survey question. This broad overview of landscape performance \nmetrics were followed-up with more specific performance questions to determine which ones \ndid  or  did  not  have  a  significant  impact  on  their  design  decision-making,  provided  in  the \nbelow figures.  \n\nDesign Decision-Making Outcomes \n\nFollowing  the  first  survey  question,  the  first  landscape  performance  question  in  Figure  6 asked the user to rate how significant the inclusion of performance metrics was to their design \ndecision-making.  A  scale  of  1  to  5  (x-axis)  was  used  where  1  meant  no  significance  and 5 meant major significance. The number of results (y-axis) shows the majority found it within \nthe high significance range. \n\nThe next performance question in Figure 7 asked which landscape performance scenario was \nof value to the user. The scenarios were specifically diversified to reflect environmental, social, and economic values. The participant could select multiple options so many users found \nmultiple performance scenarios to be important to them. \n\nThe last performance question in Figure 8 asks for the significance in designing towards a \nspecific goal. This question also used a scale ranking of 1 to 5 was used where 1 meant no \nsignificance and 5 meant major significance. This clearly indicated that establishing performance goals for individuals drove their design decision-making.  \n\nConclusion and Outlook \n\nThis  mixed  reality  provides  an  advanced  learning  experience  for  the  user  to  engage  with innovative technology, create robust analytical modeling and assessments, and create a participatory decision-making experience to advocate for healthy sustainable cities (WANG et al. \n2013). The hybridization between malleable model making with augmented data reveals a \nsymbiotic connection of instrumental tools in design thinking. It correlates with many STEM \nrelated principles of evidenced-based strategies where design can act as a strategic response \nto problematic issues of flooding, public health, and equitable resources within the built environment.  \n\nThis mixed reality design experience has tremendous potential to increase the capacity for \nusers, designers, and the community to work together and advocate for healthy living environments, make design more efficient by linking tools that help speed up the process, and \nhelps  everyone  involved  see  the  benefits  of  proposed  designs  (LIU & WANG  2019).  Augmented Reality has shown to serve as an innovative and versatile tool to visually communicate information as part of an analytical and design narrative for more informed design decision-making. This MR experience and workflow can further separate itself from other methods in the immersion and perception of space as it overlays qualitative and quantitative information impacting the composition and performance of a design concept. Rarely is it possible to experience the data that binds ecologies together. AR still contains limitations to this \nprogressive design approach, however, it can begin to give a glimpse of these interactions \nand  relationships  between  systems  in  real-time  as  designers  augment  space  into  a  mixed-reality. \n\nA Parametric Design Methodology for a Novel \nEcosystem \n\nAbstract: A literature recognizes the ecological value of biodiverse “novel ecosystems” that arise from an interplay of anthropogenic and independent ecosystem processes. Several factors influence the creation of these novel ecosystems and there is no shortage of data acquisition methods for, or complexity of descriptive data about them. However, there is a need to articulate and contextualize tools and meth-ods for formal design iteration that can make sense of this complexity and facilitate its translation into functional and meaningful landscape form. This paper describes a method for abstracting ecosystem processes into a simple parametric model, presented in the context of a riverbed mining operation in southern Georgia. The results of this initial methodology reveal the potential of parametric models to mediate between digital models of formal proposals and abstract models of ecosystem process. Separating and recombining parametric site models, abstract ecosystem models, and landscape photomontages reveals possibilities for a more facile methodology for iteration of design interventions. A parametric model also serves as a site for negotiation between project goals and constraints. Finally, the generation of a digital parametric site model allows for subsequent visualisation and editing of more specific digital models for design development and construction. \n\nIntroduction \n\nAggregate Mining Landscapes as “Novel Ecosystems” \n\nAggregate mining landscapes are widely understood as sites of chronic ecosystem degradation and destruction. However, there is a growing consensus that recognizes the ecological \nvalue of chronically degraded but “novel” ecosystems in supporting biodiversity and providing ecosystem services. A “novel ecosystem” is understood here broadly as a “new species \ncombination that arises spontaneously and irreversibly in response to anthropogenic land-use \nchanges” (MURCIA 2011). While significant debate surrounds the “irreversibility” of these \nchanges, the “restoration” of sites with a high degree of anthropogenic disturbance can improve biodiversity and ecosystem services. Rather than allow descriptions of “novel ecosystems” to simplify the project of ecological restoration, designers’ engagement with these sites \nshould focus on relationships between anthropogenic disturbance, ecosystem services, and \ncomplexity (MURCIA 2011). \n\nRestoration research in riverbed aggregate mining contexts suggests that disturbed mining \nsites provide new ecological niches that support overall site biodiversity, and that restoration \nefforts could benefit from a focus on “near-natural” restoration rather than more resource-\nintensive planting approaches (ŘEHOUNKOVÁ 2011). Similar approaches advocate for designing ecological processes and functions to allow for plants to “develop a measure of control \n[themselves]” (DEL TREDICI 2007) or “intervene and leave room” (GROSSE-BACHLE 2005). \n\nThis paper expands and applies this approach to ecosystem restoration to explore the role of \ngeodiversity in parametric modeling and redesign of aggregate mining operations. An active \nopen riverbed mining site in the south of Georgia provides the case study for the project, \npresenting opportunities to explore a design methodology that attempts to engage and alter \nan existing process of anthropogenic geomorphological change. Restoration is here under-\nstood as amplification and diversification of remaining landscape qualities. \n\nFrom Geodiversity to Geomorphological Diversity \n\nWhere geodiversity is a result of a broader collection of factors including mineral, paleontological, and structural\/ tectonic factors, geomorphological diversity describes that subset of \nfactors encompassed by surface processes. While variations in surface processes like differential weathering lead to increased geomorphic diversity, these same processes can also lead \nto reduced geomorphic diversity (THOMAS 2011). In the shifting landscape of an active aggregate mining operation, geodiversity can be understood not only as geo-determinism but \nalso as an effect of the existence of multiple states of succession within a given ecosystem. \nAltering the mining process can lead to coordination and amplification of a wider range of \necosystem successional states.  \n\nParametric Modeling and Scenario-based Design \n\nAshari et al. note that “Key academics and practitioners of landscape architecture are implementing parametric design as part of their design process in generating various design scenarios” (ASHARI et al. 2022). The goal of the methodology is incorporating the context of the \ndesign  work  into  a  formal  parametric  model  from  which  to  generate  proposed  scenarios. \nThus, the project is an attempt to situate parametric modeling within a broader definition of \ndesign scenarios (SHEARER 2022). The method should allow the model to facilitate a formal \ndialectic between given and proposed formal scenarios that is open to interpretation by designers. Additional parameters can facilitate landscape designers, planners, quarry operators, \nscientists documenting biodiversity, and the interests of laypersons living near and visiting \nthe site. The methodology elaborated in this article proposes modifications to a traditional \nAnalysis\/Concept\/Design\/Evaluation workflow. The aim was to use parametric modeling to \nencode simple formal models of observed ecological processes and begin to visualize formal \ninterventions in these processes. \n\nMethodology + Case Study \n\nSite-based Research + Analysis \n\nInterview \n\nThe design team kicked off the project with a semi-formal site visit and workshop to identify \nformal parameters and key system concepts of the mining operation. We invited architecture \nstudents from a local university to work with the design team to interview on-site excavators, \noperations managers, and ecologists.  \n\nThe interviews revealed that excavators control the shifting landscape by creating dams, which allow them to direct the river and its powerful floods. \n\nAccording to the on-site operations manager, dams are built for a variety of reasons, including protecting machinery from periodic flooding, reducing sediment flow, and allowing \nfor truck access from extraction points to processing sites. After a certain area is excavated, \ndams are eventually removed to allow larger floods to “replenish excavated material”, a \nprocess which can take as few as five years.  \n\nAfter collecting the qualitative description of the mining process and ecological diversity, the \nteam compiled satellite imagery, reviewed drone footage, and composed diagrams describing \nthe mining process and its extent. While the drone footage from the February visit shows a \nsparse winter landscape, satellite imagery shows a river in constant flux, coming to life each \nspring as a new layer of vegetation spreads over the bed of silt and rocks freshly deposited \nby winter flooding. The imagery serves as a partial record of the last decade and reveals the \nimpact of mining activities on the riverbed over time. Aggregate mining disturbs the riverbed \non a timeline of weeks to months, but this impact is superseded by spring floods that occur \nyearly. \n\nIn response to these conditions, we hypothesized that the mining and dam-building processes could be harnessed to increase the geomorphological diversity of the mining site. Processes of excavation, dam building, and periodic flooding have the potential to create a \nwide range of microhabitats that support increased species biodiversity. \n\nDefinition of Ecosystem \n\nGrasshopper Definition of Formal Ecosystem Drivers \n\nA secondary step of analysis involved the translation of the narrative context of the site into \nformal parameters that respond to existing ecological conditions and planned works on the \nsite. To create a tool for quick formal iteration with respect to site-scale decisions (“Planning \nDecisions” in Fig. 1), we needed to identify and abstract the appropriate metrics and formal \nparameters of the mining operation and larger landscape ecological dynamics and forms. \n\nIdentifying Macro- and Micro-ecosystems \n\nThe abstraction of landscape ecological features was accomplished by comparing areas of \nsimilar  vegetation  cover  to  the  topographical  surface  to  define  boundary  conditions  on  a \nbroad site-scale. As observed on site and through sectional analysis in Google Earth, the edge \nof the “Intact Bosque” follows the scoured edge of the riverbed, providing a sharp boundary \nat the site scale. A lighter shade of vegetation composes an intermediary edge zone that has \nallowed for the development of an early successional bosque, which exists at 1-2m above the \napparent limit of flooding. The floodplain is defined by a zone of high-frequency scouring \nevidenced by the limited presence of shrubs. Scattered across the floodplain are former borrow pits, which host littoral micro-ecosystems similar to the early successional bosque. \n\nBy  applying  Richard  Forman’s  principles  of  landscape  ecology,  the  early  successional \nbosque can be understood as the cellular or nuclear membrane of the intact bosque, facilitating the migration and succession of species (DRAMSTAD et al. 1996). A key assumption for \nthe model is the role of the intact bosque as a nucleus for expansion into the shifting floodplain and active mine zones (CORBIN et al. 2016). This allowed us to argue for the conservation of the bosque by shifting tipping grounds from the floor of the intact bosque to the more \nfrequently  disturbed  early  successional  bosque.  The  tipping  piles  currently  interspersed \nthroughout the intact bosque should be redistributed as a way of amplifying the seed bank of \nthe more frequently disturbed landscape.  \n\nConcept Development \n\nThe goal of the concept development phase was to create a simple iterative model of masterplan forms. At the site scale, the ecological system is represented as a “boundary model” \n(HILL 2005). The boundaries represented in the model (the edges of the intact forest and the \nedge of the main channel of the river) define the limits of the proposed berm system. These \nedges are subdivided to generate start and end points for the berm and distances between all \npossible start and end points are calculated. Each of these possible berms is then recalculated \nas a set of bi-arcs, or curves composed of two simple arcs. The definition incorporates In-\nCurve interior culling to exclude iterations that exceed the limits of the project.  \n\nFollowing initial iteration, a selected curve or set of curves is then used as a basis for the \ngeneration  of  a  surface  that  can  be  intersected  and  compared  with  models  of  the  existing \nsurface. In this project, the lack of a high-definition surface model forced us to rely on abstracted orthoimagery to infer elevation information. In future iterations of the methodology, \na context model with greater definition can add greater analytical definition to this stage. \n\nThe vertical difference in the model is developed relative to a “system zero” that can shift to \nany average or given waterline elevation. This allowed us to reduce the complexity of varying \nwater levels while also retaining the ability to incorporate more complex water elevation data. \n\nDesign Development \n\nThe iterative outcomes of the concept development model form the base of a further-refined \n“design development” model. The development model is broken into smaller models of individual zones to generate a greater diversity of micro-ecosystems. \n\nManual and Parametric Cutting Operations \n\nBerms can be cut with individual curve parameters or sets at specific intervals to introduce \nfurther porosity in the system. Varying the elevation of these cuts can generate check-dams \nor culverts with a range of crestline elevations. \n\nDistribution of Varying Nutrient Levels and Soil Types \n\nParameters  for  specific  soil  types  can  be displayed by  developing  a key-color  legend and \ncustom material previews. \n\nIncorporation of Environmental Simulation on Smaller Sites \n\nThe generation of a physical model allows for a range of existing Grasshopper plugins to \nanalyze  environmental  factors  such  as  hydrological  saturation  (Groundhog)  and  temperature\/energy modeling (e. g. Ladybug, Honeybee). \n\nPhotomontage and Further Descriptive Visualisation \n\nPhotomontage was used not as a way of determining the fixed or final condition but as a \nmethod of representing combinations of potential project conditions to create an image open \nto interpretation (M’CLOSKEY 2014). The definition generates measured landscape forms that \ncan be montaged over existing landscape conditions and textures to produce projective photomontages (Fig. 5). Such hybrid images can be used to establish metric visual parameters \nthat facilitate systemic and systemic design decisions. \n\nDiscussion \n\nDeveloping Facile Definitions \n\nThere is a need to balance specificity and complexity with respect to digital data inputs and \noutcomes when generating formal iterations. Nested, simplified models allow design teams \nto move efficiently between decision-making scales without carrying unnecessary complexity to the model.  \n\nInitial investigations in the design development phase revealed that the use of environmental \nsimulation plugins such as Ladybug, Honeybee, and Groundhog (saturation) work best on \nsmaller sub-sites, where more subtle forces of surface geology become legible. Further case \nstudies are needed to elaborate possible applications to large-scale sites. \n\nDesigners working with parametric software must always take caution when integrating specific datasets. Beginning with an abstracted master plan model with simple geometry allows \nfor fast and loose overlays with existing context data (orthoimagery, topography, observed \nvegetation, etc.). \n\nRules-based Experimentation \n\nSome rules were fast and loose, aimed at experimentation and later refinement (i. e., each \nberm should be double-curved). Others were highly specific, (i. e., the length of the berm, \nthe radius of the berm enclosing an area). The definitional simplicity of the model facilitates \ngeometric iteration and pattern generation. \n\nRepresentation through Hybrid Drawings \n\nThe hybrid drawings produced through this workflow operate like traditional landscape rep-\nresentational method of “landscape overlays” and yet add another layer of specificity and \ncomplexity.  User-displayed  text  and  annotation  can  further  integrate  metric  and  technical \nparameters of the represented form. \n\nConclusion and Outlook \n\nThis project and paper focus on the outcomes of an initial draft of a parametric methodology \nfor engagement with novel ecosystems through geodiversity. The goal of the case study project was to bring the mining operation parameters into a model that can facilitate rapid visualisation of site-scale forms, followed by an initial investigation of smaller parameters. Creating a protocol for nested models with feedback was crucial to moving between scales and \ndiscerning between “hard” and “loose” formal design decisions. \n\nThe methodology allows the abstracted parametric model to become a site of physical and \ndiscursive negotiation and coordination between the various actors involved in the project. \nThe next step in refining this methodology is to test the utility of this parametric model facilitating interdisciplinary data and feedback in the design process. The case study used to develop this tool aimed to establish a more intentional role for formal decision-making by facilitating decisions that incorporate aesthetic and metric-based approaches. \n\nFurther research could unfold along two strategies for further defining the surface: a more \nspecific integration of soil types and the use of 3D scanning to incorporate temporal change \nof landscape form.  \n\nEventual applications of the methodology could inform design protocols for novel and ex-\npanded riparian ecosystems. The workflow can also be applied to smaller sites and the gen-\neration of formal iterations.  \n\nComparing Transportation Metrics to Measure\nAccessibility to Community Amenities \n\nAbstract: Landscape architects and urban planners play an important role in helping create inclusive, \naccessible communities. To do this, it is helpful to understand how the built environment and access to \nvarious amenities and places affect activities of daily community living. These activities can influence social engagement with others and satisfaction with one’s social life. Thus, understanding how the built environment  influences  their  choice  of  living  can  shed  light  on  the  ramifications  to  an  individual’s overall social satisfaction. As previous studies show, there are various methods for measuring accessibility. But to what extent are these metrics different or provide similar results? In the current study, we generate various geospatial models to measure distance, density, and accessibility. The metrics produced are then compared to identify how similar they are in measuring access to several different places. Results show that all metrics are statistically significant and similar, however, similarities range from poor  correlation  to  very  high  correlation.  The  most  consistent  can  then  be  used  in  future  studies  to identify how well they correlate to stated access, actual access, and the influence on social satisfaction. \n\nIntroduction \n\nA tenant of landscape architects and urban planners is to improve the quality of life in communities. An essential variable in this equation is improving the satisfaction of social life as \na result of community integration (SEEMAN 1996, YEN & SYME 1999) and development patterns.  To  accomplish  this,  landscape  architects,  policymakers,  and urban planners need  to \nknow how social and environmental factors impact community integration and, ultimately, \nsatisfaction with social life. Prior work in the discipline has shown that if we create improved \nintegration of people within their community, people experience a higher level of social satisfaction (CHRISTENSEN et al. 2010). \n\nSeveral factors affect the level of satisfaction with social life among people, including factors \ninfluenced by the surrounding neighborhood. For example, social factors such as place attachment (CAO et al. 2020, HUR & MORROW-JONES 2008) and neighborhood cohesion (Liu, \n2017), make higher rates of satisfaction (MITCHELL et al. 2013, OKTAY et al. 2021). Additionally, environmental factors including landscape and green space (BOTTICELLO et al. 2014, \nYOUSSOUFI et al. 2020), mixed land use (BEARD et al. 2009, CAO et al. 2020) destinations \nand urban amenities (ALLEN 2015, SATARIANO et al. 2010), and street connectivity (GÓMEZ \net al. 2010) also play a role in facilitating social satisfaction. However, there is no standardized rule used to calculate how built environment factors and the proximity to urban amenities are associated with the level of social satisfaction. Further, there are limited studies that \nsystematically compare accessibility measures (KAPATSILA et al. 2023). Not only can it be \nimportant to compare the results from a range of accessibility metrics, but equally important \nis  the  level  of  technical  difficulty  required  to  accomplish  each.  In  this  paper,  we  explore \naccessibility to common community places in which individuals take part in a range of different  activities  (JONES  1981).  These  places  include  areas  of  outdoor  recreation,  grocery \nstores, retail stores, restaurants, and others. Throughout this paper, we refer to these places \nas “place types”. Since accurate metrics are necessary for effective policy development and \nimplementation, we are keen to ask: to what extent do different accessibility metrics agree \nwith each other”? Specifically, how different are geospatial techniques for measuring and \nquantifying access to place types by neighborhood?  \n\nThere is a diverse knowledge and broad understanding of the linkages between the level of \nsatisfaction among individuals and environmental factors including neighborhood and place \ntypes (SAMMER et al. 2012, WHITE & SUMMERS 2017). There is, however, uncertainty about \nhow  accessibility  to  each  place  type  affects  social  engagement.  Given  the  potential  importance of these places to facilitate social satisfaction, it will be helpful to identify a robust \nspatial metric that could explain the impact of place types on the level of satisfaction with \nsocial life. We could further use the spatial models to assess and promote policies that integrate people into their surrounding environments and communities. Understanding the relationship between place types and the level of satisfaction can inform how landscape architects \nand planners design inclusive communities. However, before we can understand this relationship, it is also important to understand how we assess accessibility. \n\nOne of the more basic measures of accessibility is to determine the degree of access from one \nlocation to another. Certainly, there are differences in the kinds of reliance on different modes \nof transportation across demographics (PARK et al. 2022). There are several ways for measuring accessibility. However, this paper is not focused on attempting to identify the range of \nmulti-modal transportation accessibility techniques. Instead, we focus on understanding the \nconsistency of different measures of accessibility, mainly because some models may be biased (GIANNOTTI et al. 2022). In this paper, we identify the degree to which six common \nspatial accessibility models are related. We generate a systematic comparison of these models \nby measuring the spatial pattern and accessibility to several place types. By identifying similarities, we can determine trade-offs between model complexity and consistency of the metrics. The easiest and most consistent models can then be used in future studies where empirical data about demographics, disability status, and travel behaviors can be used to identify \nthe relationship between access to place types and social satisfaction. \n\nMethods  \n\nDetermining accessibility is a rather complex process. Transportation-related studies provide \nseveral  means  to  produce  an  accessibility  measure,  with  the  most  precise  being  produced \nusing empirical data collected about individual travel patterns. However, these data can be \nparticularly expensive to obtain and may be logistically prohibitive to obtain in some international contexts. In this study, we pursued comparing six different geospatial models that use aggregate data at the US Census block group level (heretofore: “block group”). To conduct our analyses, we used the Safegraph Point of Interest data points (POI) and aggregated \nthese data into eight categories. Each category is then referred to as a place type. Six metrics \nwere defined to represent the spatial pattern of place types. including, accessibility to different destinations (CAO et al. 2020), proximity to various destinations (TSEMBERIS et al. 2003), \nthe density of place types (YANG 2008), and spatial models (GIANNOTTI et al. 2022, LUO & \nQI  2009).  More  specifically  our  metrics  are:  1)  Average  proximity  to  place  types,  2)  frequency of place types (count of place types within the block group), 3) Density of place types \n(using kernel density), 4) The number of block groups (in USA, referred to as block groups) \nwithin the service area of place types, 5) the gravity model, and 6) two-step floating catchment  area  (2SFCA).  Each  of  these  metrics  measures  accessibility  to  place  types,  but  it  is \nimportant to note that the level of technical difficulty varies widely. Furthermore, variables \nused to calculate each metric can differ. For instance, 2SFCA and gravity model considers \npopulation,  while  frequency  metrics  and  the  kernel  density  focus  on  the  number  of  place \ntypes in a unit (e. g. block group). As a study area, we analyzed data from across the Greater \nSalt Lake City, UT region in the USA. Some items, including accessibility and distribution \nof place types, were selected from neighborhood satisfaction scales developed by (GUTTING \net al. 2021, OKTAY et al. 2021). This technique provides a simple proxy for determining the \nextent  of  access  to  place  types  KWEON  et  al.  (2010)  produced  similar  measures  based  on \ndifferent place types by limiting the distance of an accessible amenity to a respondent’s home. \nConducting a correlation between the metrics results can provide insight into the similar results that we can get. \n\nTwo density measures were produced, frequency of place types (count of urban place types \nwithin the block groups) and density of place types (using kernel density), Metric #1 and #2, \nrespectively. Metric #1 counts the total number of the selected place types intersecting with \na block group, using spatial selection. Metric #2 uses kernel density to calculate the density \nof features and place types in a block group (YANG 2008). Kernel density was performed by \nthe planar option, which is appropriate for the analysis on the local scale.  \n\nFor average proximity to place types (Metric #3), we generated a set of origin locations that \nwould provide a meaningful context for trips from within each block group. Every intersection of the road network within each block group became an origin node. Intersections within \nthe block groups balance the trade-off between identifying every building from which people \ntravel to and from, but also provide more precision than the centroid of the block group. We \ncalculated the median distance of travel using Safegraph datapoints and set as a travel distance to get to different destinations from the intersection nodes. Driving distance was used \nbecause there is limited information about alternative use of public transit. Then, the average \nproximity from all origin nodes to all place types within the travel distance was calculated. \nFigure 1 shows the average proximity, by block groups, from origins to each place type.  \n\nThe number of block groups within the service area of place types (Metric #4) flips the density calculation by starting from the place instead of the block group. To produce this metric, \na service area was generated for each place type using a network analysis. The route distance \nwas calculated based on the median distance that individuals reported as the travel distance \nto  get  to  different  destinations  (similar  to  Metric  #1).  Then  the  number  of  place  types  by \nservice area within each block group was calculated by spatial joining the service area with \nany intersecting block groups.  \n\nThen, the more established 2SFCA metric (Metric #5) was used for measuring accessibility \nto each place type. 2SFCA defines a catchment area around each location and computes the \nsupply-to-demand ratio for the catchment area. The boundary of the catchment area can be \ndelineated with the radius, travel distance, and travel time (LUO & QI 2009).  \n\nThe other commonly used transportation metric we employed was the gravity model (Metric \n6). The gravity model has been used to model human mobility and accessibility. The model \nconsiders the distance between two nodes and the population within the place type’s service \n\nResults  \n\nResults of this systematic comparison are provided first as a correlation matrix (Table 1), \nthen as a series of visual representations below. To demonstrate the statistical differences \nbetween  each  metric,  we  produced  correlation  tables  for  each  of  the  eight  different  place \ntypes, by each of the different Metrics (or geospatial models). Here we show a summary table \nof the average correlation values across all eight place types. The purpose of this table is to \nhighlight  (in)consistencies  between  metrics  and  to  identify  potential  sensitivities  of  these \nmodels  across  place  types.  Note,  Metric  #3  is  inversely  correlated  with  all  other  metrics. \nThus, these were this inverted to positive values so the average correlation would maintain \nits accuracy of strength, regardless of signing. Consistently high correlation values with a \nrelatively low standard deviation suggest that these Metrics are likely to produce similar results. This table highlights that Metrics #4, #5, and #6 maintain very high correlation and low \nvariance across all place types. Metric #2 also seems to be highly correlated with Metrics #4, \n#5, and #6.  \n\nTo depict these data visually, several maps were generated (Figures 1-6, for Metric #1 – #6, \nrespectively). Given the diversity of values for each of the different Metrics, we created Table \n2, which identifies the grouping of values for each of the different legends. Using these visuals one can see differences in the relative distribution of high to low access to various place \ntypes. For instance, Metric #1 shows a clear visual difference from the other Metrics (which \nis also clear in Table 1). Also, the overall consistency of Metric #2 with Metrics #3 – #6 is \nalso fairly apparent in these figures. Note, the groupings used in these figures were not the \nvalues used to conduct the correlations (correlations were not run by groups). Instead, correlations were conducted on the raw values produced from each metric for each of the block \ngroups. The figures are providing only a visual reference with the groupings of data produced \nusing Natural Jenks, these groupings were not used in the correlation analysis. The figures \nonly symbolize the results of the metrics for access to outdoor recreation. \n\nA summary description of these figures is provided here. Figures 1 and 2 illustrate the results \nof the count of place types within each block group (Metric #1) and the density of place types \nusing kernel density (Metric #2). The darker color indicates that a block group has a greater \nnumber and density of urban place types. Alternatively, as the color gets lighter, there are \nfewer place types and a lower density of place types. Figure 3 illustrates the results of the \naverage proximity to place types. The darker color shows a shorter distance to the outdoor \nrecreation  and  as  the  color  becomes  lighter,  it  shows  a  longer  distance  to  the  destination. \n\nDiscussion and Conclusion \n\nLandscape architects are regularly involved in community design and transportation planning. Finding models that provide reliable metrics and are easy to perform can help facilitate \nrapid  iterations  of  design  and  planning  recommendations.  In  this  study,  we  compared  six \nmetrics that measure accessibility to different place types and showed differences between \nthem. Results indicate a high correlation between metrics #5 of the 2-SFCA method, #6 of \nthe gravity model, #4 of the number of block groups within each place type service area, and \n#2 of the kernel density. Furthermore, we provide a stark warning about the dangers of using \na  single  geospatial  metric  –  especially  if  the  metric  needs  further  empirical  evaluation  to compare  its  reliability  and  effectiveness.  The  2FSCA  (Metric  #5)  and  gravity  (Metric  #6) \nmodels have been well published in the literature (KAPATSILA et al. 2023, LIU et al. 2022, \nLUO & QI 2009) but can be more complex to run than other metrics (Metric #2), though these \nare highly correlated. This comparison highlights the potential trade-off between model complexity and the outcomes. It will be important for future studies to ascertain the value of the \nmore complex models. For instance, correlations between models might be high, but do they \nmaintain the same level of consistency when other variables are included (e. g. demographics \nor disability status)? If reliability is maintained, then simpler methods should be used first, \nwith  the  more  complex  methods  becoming  necessary  only  if  there  is  a  good  empirically-sound reason. \n\nOur analysis has shown that some models of accessibility differ quite substantially. At the \nsame time, some of these models share a high statistical similarity. One of the challenges \nthese models provide is that they can serve to validate actual travel times and provide data to \ninform planning policy. However, there are limited studies that attempt to connect these models  to  social  satisfaction.  Our  results  are  aligned  with  other  studies  that  compared  simple cumulative opportunity measures and the measures produced by the gravity model to under-\nstand if there is a significant correlation or not between them. The results showed that cumulative  opportunity  measures  can  substitute  complex  measures  like  the  gravity  model \n(KAPATSILA et al. 2023). It can be argued that social satisfaction is an important indicator of \nthe quality of life, perhaps more so than just assessing how long it takes someone to get from \npoint A to B. Thus, to validate these models, a future study should study the statistical relationship between each model and how they relate to social satisfaction. Further, we also anticipate gathering empirical data on the time to travel and modes of travel for people living \nwith disabilities. This information can then be used to compare differences between the general public and those with disabilities – not only for functional access to place types but more \nimportantly for how the spatial relationship to these place types influences social satisfaction. \nThe study can contribute to a wide range of fields, including landscape architecture, urban \ndesign,  urban  planning,  and  transportation  planning.  Yet,  landscape  architects  do  play  an \nimportant role in helping design access to a range of different place types, particularly greenspace and open space. With this work, we have established the importance of testing different \nmodels  to  determine  community  access  to  place  types,  including  outdoor  recreation.  This \nwork provides a means to connect accessibility and the design of urban spaces, to create more \nsuitable and equitable access to different place types for all citizens. \n\nEroding Terrains: Developing Computational Design \nTools for Interactive Site Erosion \n\nAbstract: Landscape erosion processes can be problematic and are universal in their effect on all forms \nof landscape contexts and conditions. Hydrological erosion processes are important features of ecologies, yet are often extremely problematic, and can be exacerbated by climate extremes, weather events, \nanimal and human activities, and especially transformations through agricultural processes. This research documents and proposes computational design tools and methods for erosion simulation in real-world scenarios. While there are many examples of soil erosion modelling in the life sciences and engineering fields, they are rarely applied at the detailed scale of the landscape-, architecture- and design \ndisciplines. The work  attempts  to  leverage erosion  processes  for  design  by creating  new  workflows \ninside familiar design and modelling programs. Applications may vary between agricultural land and \nareas of accelerated climate change, however, the test case for this application is in a fire-affected landscape particularly prone to erosion. This research seeks to unite site investigation and survey techniques with interactive erosion modelling within AEC design software. By introducing intuitive ways to model erosion processes mitigation becomes possible within the landscape analysis and design process, creating opportunities to avoid erosion before it occurs. \n\nIntroduction \n\nErosion is a fundamental landscape process that underlies all landform generation. In combination with transport and sedimentation, it is integral to all landscape processes and their \ninhabited ecologies (KONDOLF 1994). Despite many advancements in the various ways in \nwhich humans have formed and manipulated the earth, erosion remains process we still struggle to work with. How we counter the degenerative effects of erosion have barely changed \nover  the  last  century  (BATES  &  ZEASMAN  1930).  This  research  is  particularly  focused  on \nhydrological erosion as one of the key forms of erosion affecting landscapes worldwide at an \naccelerating rate due to climate change and land-use practices. The perceived demand for \nsuch techniques comes from both an observed lack of such analyses executed in the AEC \nindustries,  and  the direct demand for  such  methods  from  within  parallel  research projects \n(MELSOM 2022).  The  parallel  research  projects  inform  this  case  study  and  initial  practice \nmodel for this technique, namely the specific and heightened erosion issues faced by post-fire landscapes, although the techniques are equally applicable to a wide range of other landscape and built environment circumstances, such as disused agricultural and cleared landscape plots, de-vegetated drought-affected areas, and building construction sites. The work \ndocuments the current progress in developing specific tools for common erosion models at a \nlocal site scale, leveraging high-resolution user-generated site models. \n\nRecent shifts in weather patterns, storm event frequency and magnitude, connected with on-going climate change exacerbates the loss of soils as a key societal issue that already dates back  centuries  (MONTGOMERY  2012).  It  commonly  results  in  the  loss  of  arable  land,  increased landscape disturbance, the destruction of ecological systems, as well as negative effects on the built environment. Erosion simulation is an answer in the field of civil engineering, providing insight to where and how it might occur. Large to medium scale modelling is widespread, and often leverage GIS or proprietary and specialised modelling software solutions (MAY et al. 2005, ARGENTIERO et al. 2021). Furthermore, there is also some scepticism in the relevance and accuracy of such simulations at territorial scales (MONDA et al. 2017). Nevertheless, these models tend to focus on the territorial or catchment scale, distinctly abstract from the detailed site scale and restricted to the realm of specialised engineering applications and computation intensive instrumentation (KANITO & FEYISSA 2021). \n\nAt the design scales there are clear and compelling examples of methods that propose to work \nwith avalanches and sedimentation events instead of against it. Here materials are redistributed as they erode or arrive on site (HURKXKENS 2021). The potential to combine detailed site data with predictive or preventative erosion modelling provides many compelling avenues for landscape management, generative possibilities, effective hybridisation of erosion, \nsedimentation, and design. \n\nIterative Erosion Modelling \n\nHydrological erosion types follow several generally established patterns and types, each often the precursor for the next: splash, sheet, rill, gully, bank and stream, ordered by increasing \nscale. Rill and gully erosion have been isolated as the most useful for this research, to generate a simplified simulation tool. Existing specialised applications in earth engineering have \nformed  both  the  basis  for  this  selection  and  a  model  for  confirmation  of  applicability \n(HANCOCK et al. 2008). As can be seen in such precedents, high-resolution site data is required \nin order to generate relevant results. Detailed, recent models are a necessary starting point, \nwith medium to high-resolution laser scanning or photogrammetry a base requirement. Due \nto the nature of rilling scale erosion sites, photogrammetry is particularly interesting as it excels \nin open ground, un-vegetated areas, allowing a consistent accuracy of 10cm down to 2cm. \nOpen agricultural fields, mining landscapes, and post-industrial sites are suitable examples \nof high-resolution photogrammetry subjects, or in the case of this research, post-fire affected \nsites, cleared of foliage and vegetation canopy. The site of Rosedale, NSW, Australia was \nchosen as an ideal candidate for such a fire-affected erosion modelling scenario (Figure 1). \n\nA simplified model closely mimics the established model (KANITO et al. 2021, HANCOCK et \nal. 2008) yet allows for a close to real-time feedback loop, and the integration of iterative \nworkflows. To this end, Rhinoceros was chosen as a base software, with the integration of \nscripting and plugin development to provide a seamless connection with three-dimensional \ndesign  software  that  is  both  intuitive  and  an  industry  standard.  Rather  than  analysing  the \nmodel  outside  the  design  software,  it  is  compatible  with  other  AEC  design  software  and \nmethods, without interrupting the design process. It is also compatible with GIS software and \nvarious spatial data types. This simplified process can integrate other landscaper factors such \nas soil characteristics, barriers, and vegetation to improve the accuracy of the simulation further. \n\nThe concept of iteration is also considered an important simulation criterion within the design \nspace, in this case, differentiated into two iterative models, integral and event iteration: \n\nIntegral  Iteration  describes  the  case  in  which  the  eroded  model  accounts  for  erosion  and \ndeposition  within  the  same  continuous  modelling  cycle,  with  eroded  areas  having  a  compound effect on their continued erosive processes, rather than acting on existing site characteristics alone, and allowing for changes to the site to be made during simulation.  \n\nEvent Iteration modelling allows for separate events, with a shift in intervening characteristics (vegetation, topography, physical intervention). This model allows for multiple hydrological events to take place separately, with shifts in the intervening period. This is an im-\nportant factor in many erosion-prone landscapes, as long-term erosion effects are often generated through multiple or repeated erosion events that are incremental, rather than occurring \nin one discrete event. \n\nTerrain Characteristics also play a key role in understanding the processes of erosion. Many \nfactors affect its course over the surface in landscape terrain models and have therefore been \nincluded in the erosion model, with varying levels of integration (Figure 2). \n\nSoil Texture is a key characteristic in erosion models. Different soil types erode and deposit \nat varied rates, and the standard simulation technique of a reference raster image has been \napplied. \n\nTerrain Slope and rate of slope change are fundamental erosion characteristics, regardless of \nsoil type, as they affect the speed and acceleration\/deceleration of water movement and there-\nfore energy of the water, and its propensity to either erode or deposit material. To this point, \nonly slope angle has been implemented.  \n\nTerrain Roughness at this site scale. Here individual terrain details such as vehicle tyre tracks, \nanimal marks and soil or rock texture can have a huge influence on erosion patterns. Not to \nbe  confused  with  soil  texture,  additional  roughness or  triggers  to  erosion  can be  included \neither as proxy mesh, with noise, or as a raster image. \n\nErosion Resistance is the demarcation of areas that physically cannot erode or are otherwise \nresistant to erosion due to solid barriers, vegetation, root systems, or other physical hindrance. \nThese areas can be either physically modelled or marked with images, allowing a graduated \neffect. \n\nEach of these terrain characteristics has been integrated into the workflow to form a working \nmodel for a limited range of case studies (Table 1). Surface water flow calculation is based \non detailed DTM data and simplified erosion simulation using reference parameters implemented with the computational terrain modelling plugin. Preliminary simulations assume a homogenous substrate, although the overall resistance characteristics to erosion can be manipulated. Additional testing and verification would be required for broader applications with accurate and repeatable results. \n\nSurveying and Erosion Modelling Tool \n\nThe implementation and testing of the erosion simulations have centred around specific post-fire landscapes. These make appropriate sites, as they are often immediately susceptible to \nreal erosion following an intense fire event. Erosion in these landscapes presents a massive \nissue for many authorities and communities. Analysis conducted in such landscapes has determined that up to 50 times more erosion can take place in an extremely fire-damaged landscape than in one marginally affected by fire, as well as many other mitigating factors (TULAU et al. 2015). To survey the affected terrain, there are precedents for UAV imagery and its use in general erosion mapping and simulation (MISTHOS et al. 2019). This survey method functions well in circumstances where erosion risk is high, due to lack of ground cover and exposed terrain. It also enables successive landscape surveys and allows for the mapping of landscape change and subsequent model adaptation. In addition, reference layers for erosion \nresistance can be generated from this data. In this case study, industry-standard photogrammetric  software  –  Agisoft  Metashape  –  was  used  for  this  stage  of  research,  however,  the \ndelineation of the scanned site and predetermined route may aid in generating more accurate \nresults with repeated scans of the same site, documenting its evolution and supporting iterative model generation. The required resolution and detail of the test site required a relatively \nlow altitude (40m) scan height with a high overlap of 80% in both directions, with an angled \ncamera (75°) flying in a gridded pattern around tree-bases (a common area of photogrammetric error). \n\nThe  simulations  are  built  on  top  of  Docofossor,  a  terrain  modelling  plugin  for  the  visual \nscripting environment Grasshopper of Rhino 3D (HURKXKENS et al. 2019). It uses regular \nraster grids as underlying data-model for its terrain representation. This enables simple modelling operations in cut and fill using distance functions. Like the plugin, the erosion simulations make use of build-in class methods from RhinoCommon or via the Rhinoscript python \nimplementation to compute the grid values.  \n\nThe implication allows for animation and simulation of any part or any duration timeline. For \ndetailed areas of the case study site (Figures 3) of around 50 x 50 m, animation frames can \nbe calculated in less than 5 seconds on a standard workstation set-up, facilitating an optimal \nsimulation-to-design workflow. When compared with large-scale surface water flow, the results  demonstrate  that  a  laminar  surface  concept  of  layered,  continuous  water  supply  and movement works well to imitate site-observed erosion phenomena in scale, extent, and pattern (Figure 4). Within the chosen case-study typology of fire-affected areas, there are ample examples and areas for verification and refinement of the erosion models in various soil and \nsurface conditions. The varied performance in differing substrates is an area for further research and study. \n\nDiscussion \n\nThe resulting model combines a cleaned, photogrammetric terrain model collected on site, \nwith a scalable yet detailed simulation of rill-model erosion. This can form the basis for site \nselection, risk analysis, or developing of erosion mitigation strategies in high-risk areas.  \n\nThe various data elements produced during the described process consists of base data and \nsite analysis, as well as simulation data, such as the resulting flow-paths, erosion \/ deposition \npatterns and debris transport lines. The results reinforced the individual and combined roles \nthat terrain roughness, converging slope details, and obstacles such as trees, fallen tree trunks, \nand rocks play in the resulting site-specific example. Site observation reflected the general \ntrends of the erosion model; however, additional calibration can be applied to further refine \nthe exact volume of material transported. The nature of the site material, being a mixture of \nfine ash, partially fire-consumed debris and dry topsoil that are non-uniformly distributed on \nthe terrain lead to a model in which exact depths and volumes of material erosion and depo-\nsition are variable. Therefore, the erosion paths and patterns can be shown to have a higher \nfidelity than the depth of erosion. As referred to in the conclusion section, additional material-specific experimentation or specialist data would help to refine these models.  \n\nThe potential for iteration in this process, both as a computational tool in simulation, and a \nworkflow for gradually improving and refining the model worked well, especially given the \nresponsiveness  of  the  algorithm.  The  proposed  additional  applications  for  iterative  design \nproposals  using  the  same  process  are  feasible  in  both  implementation  and  viable  design \nmethod. \n\nConclusion and Outlook \n\nThe  relevance  and  importance  of  erosion  simulation,  and  its  challenges  within  the  design \ndisciplines are established, and the case is made for its viability and implementation. The \nlack of a designer-level toolset to deal with these issues has been addressed in this research, \nas well as the potential of these techniques for the AEC professions. The range of further \napplications and possible sites is only increasing with the growing impacts of climate change. \nSuch simulation techniques can be deployed to predict erosion issues that may occur in the \nfuture  and  allow  for  pre-emptive  interventions  that  may  avoid  or  transform  such  erosion \nevents into more positive outcomes. Within the space of fire events alone, there is a huge \nscope for adjusting landscape management practices to better recover from fire events, especially their implications for soils, sediment, and the fostering of their landscape biodiversity \n(TULAU et al. 2015, ATKINSON et al. 2020). \n\nThe imitation of real-world site conditions and recorded erosion sites are of key importance \nto further refine the plugin settings based on local conditions and the predictive accuracy and \nusefulness of the technique. Similar optimisation tools such as RAMMS have also been carried out both during and after the release of landslide and rockfall computational simulation \n(CHRISTEN et al. 2012).  \n\nFurther development is required to optimize and better simulate existing high-resolution simulation  models,  as  well  as  the  integration  of  these  techniques  into  teaching,  research,  and \npractice (IGWE et al. 2017). There is a strong potential for generating data layers for other \napplications and GIS systems and facilitating new forms of engagement and multidisciplinary \ncollaboration in landscape engineering, remediation, and management projects. Where erosion can be predicted and mitigated, the potential for design with erosion processes emerges. \nThe possibilities of hybrid design processes that work hand in hand with the environment, \n(GIROT & HURKXKENS 2018) open areas of potential design endeavour, in which the landscape can be shaped over time with minimal intervention and resources. \n\nExploring Less Geometric Landfill Slopes through \nParametric Digital Modelling \n\n\n\nAbstract: Massive and visually disruptive landfills in urban areas can potentially be seen by hundreds \nof thousands of people daily. Even after landfill closure, constructed slopes and ridgelines can contrast \nwith the surrounding terrain because of their signature geometric form. This paper uses three landfills \nin Southern California to demonstrate the need for better visual mitigation, test the sculpting of landfill \nslopes through parametric digital modelling, and then discuss how the process can be enhanced for real-world application that improves visual quality while meeting engineering requirements. This is an area \nwhere landscape architects can make greater contributions in mitigating the visual impacts of landfills. \n\nIntroduction \n\nLandfills are the primary way that non-recyclable municipal waste is managed. Incineration \nis eschewed due to the introduction of carbon particulates and a harmful airborne brew of \npotentially carcinogenic chemicals associated with plastics and other modern manufactured \nmaterials. The ever-growing volume of waste is also a major concern and landfills can be \nmassive. Besides the large physical dimensions of landfills, the process of land filling requires a substantial investment in time, expense, and effort to locate suitable sites, meet stringent permit requirements, prepare the site for liquid containment and methane gas extraction, manage daily fill operations, and mitigate a full range of impacts. For these reasons, the trend is towards fewer, but larger landfills (EPA 2014, 2-11). \n\nMany landfills are geometric in shape and the planar sides and mesa-like top can be recognized from miles away. In urban areas, the number of viewers can be numbered in the hundreds-of-thousands, and unsightly views or the presence of landfills can negatively impact property  values  ranging  from  3-7%  (REICHERT  et  al.  1991,  BOUVIER  et  al.  2000,  READY \n2005). Moreover, the scale of urban landfills can be dominating. For example, Puente Hills \nlandfill in Southern California, which closed in 2013, has a footprint of 283 ha (700 ac) and \nis 150 m (490 ft) in height. Counting buffer land, the facility consumes 526 ha (1,300 ac).  \n\nObjective \n\nLandfill design and operations generally fall within the realm of engineering and scientific \nconsultants.  Landscape  architects  become  involved  when  considering  landfill  aesthetics. \nTypically, these activities are related to landcover planting and the preparation of visual analyses and simulations when preparing environmental impact documents prior to landfill permitting. As “shapers of land”, the objective of this paper is to explore how landscape architects might become more involved in the earlier stages of landfill design through enhanced \ndigital modelling so the landfill shape upon closure can better blend with the terrain context. \n\nExtending the Role of Landscape Architects? \n\nThe origin of this paper derives from the primary author’s environmental consulting work \npreparing visual assessments for two landfills in southern California: Elsmere Canyon Landfill (early 1990s) and Simi Valley Landfill Expansion (mid 2000s). In both cases, the landfills were  of  the  canyon\/valley  type.  Extensive  3D  computer  modelling,  GIS-based  viewshed mapping, and before\/after photo simulations (Fig. 1) were conducted to determine visual exposure and estimate visual impacts as viewed from key observation points (KOPs). These points were public gathering areas like parks, major travel ways, and nearby residential and commercial areas at distance ranges from 0.3 to 8.5 km (0.2 to 5.3 mi). \n\nIn the case of Elsmere Canyon Landfill, the permit was denied after much public opposition. \nSimi Valley Landfill was already an operational landfill in mid-life, and the expansion was \napproved after a multi-year environmental review process which addressed public concerns. \nEven though the expanded landfill conformed to conventional engineering design, the pri-\nmary author wondered if landfill slopes could be made to appear less geometric and better \nblend with contextual terrain. Instead of involving landscape architects to assess or mitigate \nvisual impacts after landfill design is nearly complete, the role of landscape architects could \nbe  expanded  to  perform  landform  sculptural  studies  earlier  in  the  design  process.  Closely \ncoordinating  with  engineers,  slope  sculpting  would  still  need  to  meet  fill  volume  requirements, access road routing, methane gas piping, and comply with efficient daily operations. \nThis paper only explores landform, and does not address vegetation, atmospheric conditions, \nor other factors affecting visual quality. \n\nConcept Overview \n\nEnhanced Slope Sculpting to Reduce Visual Impacts \n\nThe goal of the “sculpting” process is to introduce more slope undulation into uniform slopes \nto replicate convex finger ridges and concave drainages found in contextual terrain, but to a \nlesser  degree  to  still  support  engineering  requirements.  This  will  increase  tonal  variation \n(shade\/shadow)  patterns  which  will  better  blend  with  contextual,  undisturbed  terrain.  As \nviewing distance increases and atmospheric factors become more pronounced, tonal contrasts \nare more important to visual mitigation compared to texture or hue variations. \n\nSlope Sculpting Procedures \n\nLandfill form emerges as systematic lifts (layers) approximately 8-20 feet thick. Each lift is \ncomposed of cells where daily to weekly accumulation of refuse is compacted and covered \nwith 6” of soil. Once cell placement reaches the perimeter of the lift, the outer slope is shaped \nat a not to exceed 1.5:1 ratio. A series of 15’ wide benches are also added per EPA regulations \n(EPA 1988, 62). Under the sculpting concept, none of these standard filling and grading operations would be appreciably altered until the lift edge nears. At this point, GPS-enabled earth moving equipment would grade an undulating edge, that over years, would emerge as finger ridges or drainages on the slope much like 3D printing. The precision of GPS is essential to accurately locate and place cover material along the undulating lift perimeter where \nthe eventual slope form is not immediately apparent. \n\nTowards this goal, several additional steps are needed beyond traditional engineering design: \n\nNumerically determine the slope gradient and vertical\/horizontal convexity of the surrounding  topography  (usually  applicable  to  canyon\/valley  landfill  types)  for  use  as  a \ncontextual referent. \n\nIteratively sculpt a 3D landfill computer model where exposed sides more closely replicate contextual slopes and topographic features, and then shape a rounded cap or ridgeline profile that undulates as opposed to a flat mesa. The model footprint may have to be slightly expanded to offset anticipated volume losses compared to conventional geometric forms, or the overall height increased (LAW et al. 2008). \n\nTransfer the preliminary sculpted model into Civil 3D or other engineering software for detailed design and implementation documentation. \n\nPrepare a grading plan that can be uploaded into GPS-enabled refuse\/earthmoving equipment to guide landfill slope shaping over decades. \n\nMethods \n\nThere are multiple  methods to analyze  undulations in topographic surfaces to set numeric \nbase conditions for slope modelling: slope aspect and gradient, planform curvature, profile \ncurvature,  topographic  openness,  and  landscape  roughness.  Some  numeric  techniques  include fractal dimension indexing (FRAC) (CUSHMAN et al. 2005, 103-104; MCGARIGAL & MARKS 1995), standard deviations of contour line segments, and topographic position indexing (TPI) (JASIEWICZ & STEPINSKI 2013, MOKARRAM & HOJATI 2016).  \n\nTo identify a landfill as a test case for parametric digital sculpting, Zhong (2020) inventoried \n43 landfills including 14 active and 29 closed landfills larger than 100 acres in Los Angeles \nCounty. As part of the review, FRAC indices were calculated for the landfills to assess how \ngeometric the slopes appear and identify candidate landfills for further analysis. \n\nAfter candidate landfills  were reviewed, attention  turned towards  which digital  modelling \nsoftware might be most useful. WESTORT (2015, 225-226) discusses the need for improved \nlandform design tools which are 3D, provide geometric control, are easy to handle, provide \nquick response time, and are quantitatively accurate. Furthermore, the ability to iterate before \nand during the construction [or design] phase is desirable. From our experience, Autodesk \nCivil 3D meets most of the criteria for Digital Elevation Modeling (DEM) but is deficient in \ninteractive surface sculpting. A spline modeler like Rhino is better suited for this purpose and \noffers parametric automation through Grasshopper terrain plug-ins like Docofossor, Bison, \nand TOPO kit. Upon initial review, it appears that these plug-ins do not offer the sculpting \nfeatures\/control as envisioned without additional customization. \n\nTo test how inclined finger ridges can be introduced to geometric landfill slopes while still \nmaintaining landfill capacity, ZHONG (2020) used the closed Puente Hills Landfill to proto-type  a  hybrid  manual-parametric  landform  sculpting  process  using  a  customized  Rhino\/ \nGrasshopper script using 3D control framework (Fig. 2). Preparatory work consisted of man-\nually digitizing major ridgelines, finger ridges, and intervening drainage flow lines from the \nundisturbed  1950  topography  as  a  fully  detailed  referent  of  pre-landfill  conditions.  Points \nfrom this skeletal landform structure were then filtered through a Grasshopper script to interactively reduce ridge and valley point detail as a percentage. Two highpoint locations from \nthe 2018 landfill top deck (or intended height of a planned landfill) served as landfill closure \n(2013) height parameters. Once parameters were set, a simplified surface was interpolated \nthrough the points. Using various combinations of 22%, 66%, and 88% remaining ridgeline \nand  valley  points,  seven  surfaces  (P1-P7)  were  generated  for  comparison.  Processing  per \niteration took about 4-6 hours. \n\nResults \n\nAfter the manual-parametric methods were established to generate landform alternatives, further modelling exploration was undertaken. For comparison against standard landfill design, \ntwo planar geometric surfaces (G1-G2) and three advanced contoured surfaces (A1-3) were \nmanually defined through contours and generated through Rhino. The G1 and G2 surfaces \ntypified landfills of low visual quality and the A1-3 surfaces represented enhanced landfills \nhaving some amount of slope undulation (Fig. 3). \n\nFig. 3:  Results  were  compared  for  manual  geometric,  manual  advanced  contouring,  and \nparametric  modelling  of  landfill  configurations  against  1950  existing  topography \nand the 2018 shape configuration of the Puente Hills landfill (ZHONG 2020) \n\nOnce the 12 alternative landform  surfaces  were  modelled in Rhino, the surfaces  were exported into Civil3D for volume calculations. Two sets of volumetrics were compared: 1) the \n1950 pre-landfill referent surface compared to the 12 Rhino alternatives (2020) for total volume capacity; and 2) the 2018 DEM dataset (2013 closed landfill conditions) compared to \nthe same 12 Rhino alternatives. The latter comparison is intended to directly reveal net volume  gain\/loss by introducing  more  undulations to constructed landfill  surfaces.  Of the 12 \nalternatives, three showed capacity gains:  A3 (+5%), G2 (+24%), and G1 (40%). Surface \nundulations for the closed landfill and among the 12 alternatives were also compared through \nslope mapping and aspect mapping which quickly made differences visually evident. \n\nDiscussion and Conclusions \n\nModelling results reveal that although simplified, the P1-P7 parametric surfaces too closely \nresemble the complexity of the 1950 topographic referent. P1-P7 volume capacity was not \nsufficient, slope angles were not constrained to the 1.5:1 standard (not part of script), and \nexcessive slope undulations\/aspect variation would likely make implementation difficult. As \nexpected, introducing more surface undulations decreased landfill volume capacity for most \nalternatives compared to the more geometric landfill forms. \n\nThrough this exploratory test, however, advancements were made in parametric surface modelling that enabled rapid iteration, testing, and comparison of landfill alternatives. The A3 \nalternative demonstrates that more slope undulations can be introduced to improve landfill \naesthetics while still maintaining capacity volume. Rapid iteration, as demonstrated through \n12 alternatives, is essential in finding the right balance of improved aesthetics, capacity volume, and other engineering factors to be tested in future work. \n\nResults demonstrate the potential of applying digital sculpting tools to enhance landfill slopes \nto make them appear less geometric and planar. Artistic manipulation must be coupled with \nengineering requirements to maintain slope stability, constructability, and volume capacity. \nGPS enabled refuse\/earth moving equipment can provide the precision and locational accu-\nracy across large lift expanses to achieve more naturally appearing “outer shell” forms. \n\nMaking progress to sculpt landfill surfaces iteratively and more freely for aesthetic purposes \npartially fulfilled the initial objective of this paper. Full realization of the objective requires \nlandscape architects to better understand the complexity, timing, and workflow commensu-\nrate with landfill design and operations if they are to be involved. Based on past professional \nexperience  with  landfills,  many  engineers,  technical  consultants,  regulatory  agencies,  and \nenvironmental assessment  specialists are involved, and the  design and permitting requirements are substantial. Reducing visual impacts is a worthwhile goal but knowing when and \nhow optimized landform modelling with a greater emphasis on aesthetics can be introduced \ninto the design process is challenging. To be cost- and time-efficient, it needs to be used early \nin the process, offer rapid iteration, meet engineering requirements, and then be passed off to \nothers for technical refinement. At the landfill operational stage, extra edge\/slope requirements must also be safe and compatible with the myriad of choreographed activities taking \nplace on the working deck. \n\nSeveral limitations are evident: more documented research is needed regarding the long-term \naesthetic  impacts  of  landfills  upon  closure  after  vegetation  has  matured;  more  parametric \ncontrols are needed for slope shaping, the Rhino to Civil 3D transference needs to be more \nstreamlined; and most importantly, a test case involving engineers needs to be identified. \n\nFuture Work \n\nFuture improvements are needed to incorporate more parametric control of slope undulation \nand shaping. Additional ridgeline control is also needed for shaping the landfill cap to avoid \na mesa-like appearance. A hybrid between the P and A models is envisioned. \n\nIn addition to ridgeline controls, select parametric contours (splines) could be added as control  features  to  parameterize  surface  undulation.  Parameters  would  be  based  on  sinuosity \nwhich is simply calculated by dividing the sinuous contour length by the straight distance \nbetween the contour line endpoints. Calculating sinuosity is typically associated with stream \nsystems but can also be applied to characterizing landfill slopes where FRAC and TPI indices \nare too general to control shaping. Referencing the sinuosity index of contextual landform, a \nfew parametric contours placed at strategic locations at the edge of landfill lifts could seed \nthe formation of finger ridges. The finger ridges would become more apparent as the landfill \nheight grows with each successive lift much like 3D printing. \n\nDifferences in slope sinuosity can be illustrated using existing portions of the Lopez Canyon \nlandfill in Sylmar, California (Fig. 4). In this 3D view of the 2016 DEM surface, a contour \nline (L1) traces undulating slopes of the contextual foreground slopes, whereas the more linear contour line (L2) traces the constructed geometric slope of the landfill face rising above \nthe foreground ridge. The calculated sinuosity indices (SI) are 1.44 and 1.19, respectively. In \na revised parametric model, the SI of L2 could be adjusted to resemble the undulations of L1 \nmore closely while still allowing for proper slope benching, access road construction, and \nmethane gas piping. This will be tested as the Rhino\/Grasshopper script is improved. \n\nThese future improvements should enhance modelling capabilities, increase ease-of-use, and \nprovide better integration with software used to prepare construction documents. Discussions \nare also needed with landfill designers with regards to landfill operations, sequencing, and \noverall feasibility of this envisioned approach to landfill aesthetics and visual mitigation. \n\nParametric Planting Design: Algorithmic Methods \nfor Resilient Communities \n\nAbstract: Parametric applications in landscape architecture are gaining traction as designers realize the full potential of script-based analysis in various stages of design. Planting design is one realm of parametric landscape architecture that is traditionally done manually with books, websites, or other research on hand, thereby keeping its application within the grasp of landscape designers. This discussion proposes a method of using algorithmic design to analyze and specify plant species based on four different measures. Further, it is possible to expand this method in the form of a browser-based program for non-designers to take part in resilient landscape planting. \n\nIntroduction \n\nThe origin of computation-driven landscape analysis and design is often attributed to Carl \nSteinitz’s 1966 land evaluation and the SYMAP print of the Delmarva Peninsula (STEINITZ \n2014). Subsequent decades brought advancements in processing power and user interface, \nallowing a variety of software to gain traction in the design field including Photoshop, AutoCAD, and specifically for landscape architects, LANDCADD (ERVIN 2020, MACDOUGALL\n1984). ERVIN (2020) also describes the rise of optimization software and use of algorithmically-generated landscapes in response to the formation of the internet (ERVIN & HASBROUCK\n2001). As such, the success of spatial design computer applications has led to at least a partial \nreliance on digital workflows in the design process, if not a large portion of the work. \n\nIn an effort to explore emerging landscape architectural frontiers, designers echoed Steinitz’ \nexperimentation  and  began  programming  new  tools  for  greater  flexibility  in  their  work \n(CANTRELL &  MEKIES 2018). Development of programs continued with some tools being \ncodified  as  permanent  sub-tools,  such  as  Grasshopper  within  the  3D  modelling  software \nRhino. \n\nGeneral investigations of parametric landscape design problems can exist in the form of blog \nposts  (GENERATIVE LANDSCAPES),  online  videos,  and  academic  papers  (SERDAR & KAYA\n2019). Commercial tools have also been created and added to aid in the digital landscape \ndesign process (LANDKIT). Notable built projects include Eda U. Gerstacker Grove by Stoss \nLandscape Urbanism at University of Michigan, where student desire lines, drainage, and \nparametric bench profiles were incorporated into an algorithm to generate a site model that \nresponds to and supports the pedestrian experience (REED 2018). \n\nExisting Research \n\nWhile parametricism in landscape architecture is an ever-expanding area of study, limited \nresearch has been conducted on the use of algorithmic workflows regarding ecological factors including species selection and planting location. \n\nA thesis by Roasliina Luminiitty (2021) from Aalto University examines parametric planting \ndesign’s integration in the landscape design progress. LUMINIITTY (2021) analyzes prior software used for landscape design, as well as more modern investigations into algorithmic landscape architecture. The paper offers a detailed explanation into the components of parametric \nplanting design and offers a framework for digital planting design workflows, which can be \nexpanded further with the inclusion of measurements and real-world data to inform the final \nresult. Parametric patterns can be tailored for design continuity and be ecologically developed \nby an algorithmic plant selection process to create a holistic planting concept. \n\nOLIN Lab’s Tech- and Eco Labs have also developed research into digital workflows for \nplanting design. The process utilizes AutoCAD, Rhino, Grasshopper, Python, LandFX, and \nAdobe Suite products to derive functional planting plans for use in a landscape architecture \noffice setting (AREVALO 2020). The process is broken down into four parts: (1) Investigating \nplants as living material, (2) Speculating and experimenting with parametric components, (3) \n3D Spatial and aesthetic analysis, and (4) Seasons and time. AREVALO (2020) states that this \nworkflow was successful for the office-side design process, but documentation was still prepared manually, which requires work by a landscape architect. \n\nLandKit is a Grasshopper plug-in developed by LANDAU Design+Technology that creates \ncustom  components  in Grasshopper  for  users  to  more  effectively  design  fundamentals  including with specific components called TopoKit, PavingKit, and PlantKit (LANDKIT). What \nsets PlantKit apart from other parametric planting tools is that it does not automatically assign \nspecies to the plants it generates, but rather establishes certain plant typologies to be determined later by the user. The plant typologies refer to similar sizes, environmental considerations, and biodiversity, which gives the end user more agency when specifying species and \naccounts for regional climate variations. \n\nThe creation of these products is testament to years of dedicated research into accurate and \nefficient planting algorithms, for use in a landscape architecture office. The development of \ndifferent algorithms and tools has taken off regarding landscape design and will continue to \nbring new and improved iterations into the field. However, this computation-driven analysis \nis mostly locked behind software with intense learning curves and high price points. With the \ngoal of simplifying communication between designer and computer, parametric application \ndevelopers should also strive to lower the barrier of entry for the use of these tools. \n\nDigital Equivalents to Planting Design Concepts \n\nBefore attempting to develop any parametric tools, it is critical to understand the concepts \nbehind existing ecologically sound landscapes. Traditional landscape design practice includes \nresearching native or naturalized plants in a specific region, while placing them in a pattern \ncorresponding  to  a  design  intent.  This  varies  from  project  to  project,  but  is  generally  the \nformat of the planting design strategy. Many different categories of planting information exist \nfor each plant, and can be addressed through different ways to fit the project’s goals. \n\nQualitative information exists as a subjective rationale in landscape design. This may include \naesthetic considerations, natural plant communities (dependent on location and ecosystems), \nand features included on a site and how the site functions as a whole. In the digital realm \nthese  cannot  be  quantified,  though  studies  have  investigated  various  methods  to  evaluate \nlandscape perception (KARMANOV 2009). Use of qualitative data or input is still important, \nhowever, as it establishes “the meaning individuals or groups ascribe to a social or human \nproblem (CRESWELL 2014). Use of this type of information can be presented in the setup of \na project, or change with user preferences. \n\nQuantitative information is a numerical type of data representation where all possible results \nare accounted for, and often presented numerically. In landscape architecture, common uses \nof quantitative data are found in climate data, topography, and geotechnical properties. Data \ncan also be extracted from the site itself through analysis tools and simulations, unearthing \nunderlying layers of data otherwise hidden. \n\nPlanting for a Post-Wild World (RAINER AND WEST 2015) describes the structure of a designed landscape through a series of layers: a structural layer, groundcover layer, seasonal \nfiller layer, and dynamic filler. The clear distinction between individual plants work together \nto  form  the  identity  of  a  garden  which  can  establish  character  even before  more  complex \ndesign motifs take place. Additionally, thinking of plants in a binary manner lends itself to \ndigital applications where a machine must be programmed to receive input and output information in a highly controlled manner. \n\nRAINER AND WEST (2015)  also  signify  the  importance  of  employing  ecological  strategies \nwithin plantings to promote resilience in plant communities. “Resiliency” is a commonly used \nterm referring to the ecological health of a landscape and its ability to recover after periods \nof distress (RAINER & WEST 2015), but it also can be interpreted as a human community’s \nability to recover from a disturbance (FLINT 2010). Given the difficulty of evaluating a multifaceted  concept  such  as  resilience,  we  can  instead  look  at  establishing  environmentally \nsound  starting  points  (namely  regionally  accurate  plant  spreadsheets)  in  order  to  generate \nresilient planting communities. \n\nSoftware for this algorithm process utilizes the Grasshopper tool in Rhinoceros 3D. Because \nthis software allows for algorithmic design approaches, a single input can trigger a variety of \nsubsequent processes and analyses, culminating in an algorithm-derived final product. \n\nPreparation for this tool included development of a plant list extracted from eastern Nebraska \nnursery stock listings to ensure success in the Nebraska landscape. In total, 198 unique species \nand 80 cultivars or varieties were identified and constructed in a spreadsheet with important \ninformation such as mature height and width, shade tolerance, salt tolerance, drought tolerance, bloom timings and color, nativity to Nebraska, and hardiness zone range. All plants \nwere parsed based on their landscape function: overstory conifer, overstory deciduous, understory conifer, understory deciduous, perennial, tall grass, groundcover, and annual. \n\nAlgorithm \n\nGrid \n\nA  site’s  surface  can  be  divided  into  a  grid  of  any  size,  though  standard  1-,  2,  and  5-foot \nsquares work best. The grid allows for easy analysis of site features such as elevation, edge \nproximities, and sun exposure. The ideal scale for this depends on the overall scale of the \nsite, with smaller sites requiring a higher level of detail. The ideal resolution for a 7,000 sq. \nft.  (650  m2)  site  can  be  2  feet,  while  larger  sites  may  need  5-foot  resolution  to  minimize \ncomputing time. \n\nPlant and Environment Scoring \n\nA surface in Rhino is referenced in Grasshopper where four analyses take place: Elevation, \nShade, Salt intensity, and Structure proximity (Fig. 1). The interplay between envi-\nronmental factors plays a large role in identifying a “best fit” species for a particular location \non a site (CZAJA et al. 2020). Elevation analysis takes note of local high and low points on \nthe  site,  and  corresponds  with  low  points  requiring  less  drought  tolerant  plants  and  high \npoints requiring more drought tolerant plants. Shade analysis looks at sun exposure on the \nsite from existing buildings and trees to accurately place plants with regards to sunlight hours. \nSalt tolerance measures look at a point’s distance from paving surfaces or curves to account \nfor  road  salt  accumulation  in  winter  months  near  the  planting  surface  peripheries.  Lastly, \nstructure proximity  refers  to the distance between  a plant  and  a  structure, preferring  slow \ngrowth nearer to the structure to reduce risk of root damage to the foundation. \n\nThe  “environmental  scores”  (elevation,  sun  exposure,  and  salt  intensity) of each  potential \nplanting spot on the site are compared to each “plant score” of a particular plant typology \n(Fig. 2). The difference between the “environmental score” and “plant score” determines the \nresiliency of the proposed plant, with a lesser difference resulting in higher probability of \nresilience. It is possible for the algorithm to compare all 278 plants for every potential location, though it would leave too many options available for the user and result in an unclear \ndirection. Parsing plants into specific landscape structures provides opportunity for a better \nstructured landscape (RAINER & WEST 2015). \n\nFlexibility \n\nThe  uniform  analysis  and  subsequent  visualization  of  a  landscape  allows  for  a  variety  of \nplanting  regimes  to  occur.  Planting  locations  can  be  derived  from  the  algorithm  itself,  or \ndecided by a user making informed decisions from the data. \n\nAlgorithm-derived  planting  plans  can  be  applied  in  a  few  ways,  provided  a  distinction  is \nmade for the specific plant typology being used in each spot (overstory, understory, tall grass, \netc.).  Grids,  attractor  curves,  and  random  points  are  options  when  considering  automatic \nplanting proposals (Fig. 3). Further exploration in parametric design tools such as Grasshop-\nper may offer informed layouts with emphasis on user comfort and more complex designs. \n\nThe user  may  defer  to  stylistic  choices based on  a  desired  theme  (naturalistic  landscapes, \nEnglish gardens, etc.). For manual placement of plants, collections of points can be projected \nonto the site surface and analysis be drawn for those, where inputted plant patterns and sizes \nare matched to the “best fit” plant for that location. The variability of planting styles allows \nfor highly unique landscapes designed by the end user. To aid in this process, planting pattern \ndiagrams were developed to demonstrate the core principles of various landscape styles. A \nfew selected styles being presented to the user show successful patterns easily replicable from \nan amateur designer’s perspective and increase the appearance of legible design intent. \n\nAlgorithm to Browser-based Tool \n\nThis algorithm can be interpreted as a backend process for a planting design tool intended \nfor people inexperienced with landscape design. Given that the tool is able to suggest planting \nstrategies from topographic information, it is possible to derive this information from other \nsources using real-world data and leave the user with freedom to focus on designing their \nspace. Further, incorporating heterogeneous (containing structure and hierarchy, biodiverse) \nlandscape  design  in  homeowner-designed  landscapes  improves  landscape  perception \n(KHACHATRYAN et al. 2020). These positive attributes prompted the idea of a browser-based \ntool that can aid in the creation of a homeowner’s landscape design. \n\nTranslating a Grasshopper script to a programming language is a fairly straightforward task, \ngiven  that  Grasshopper  is  in  essence  a  visual  coding  language.  Python  and  Javascript  are \npopular programming languages capable of creating interactive maps, ones which users could \nuse to select site boundaries in their respective regions. An application programming interface (API) allows for communication between two or more computer applications, such as \nan individual computer requesting data from a large online database. Integration of Open-StreetMap (OSM) and United States Geological Survey (USGS) API allows for up-to-date \ninterpretation of landscapes with OSM providing location data, and USGS providing elevation data. \n\nOpenStreetMap is a free, open-source online mapping service that uses volunteer-provided \ninformation to gather location data, along with deriving maps from Bing aerial imagery and \nother mapping techniques (OPENSTREETMAP). Overpass API is a resource for an application \nto request read-only data in a variety of formats for any particular use due to the open-source \nnature of the service. To obtain specific site data, a bounding box is drawn over a map and \ncoordinate boundaries are established. The software requests any road and building geometry \nintersecting or within the boundaries from Overpass, which can be interpreted and shown in \nthe map view. \n\nThe National Map (TNM) is a project by the USGS’s National Geospatial Program to con-\nsolidate  downloadable  products  into  one  location  for  all  public  and  private  use  (UNITED \nSTATES GEOLOGICAL SURVEY). The TNMAccess API allows developers access to multiple \ndatasets, and will use the highest resolution dataset for the desired location request. To obtain \naccurate elevation data, the Elevation Point Query Service returns the elevation in requested \nunits at a specified latitude and longitude. Coordinates from the initial OSM bounding box \ncan be used to create a rectangular array of coordinate points and sent as a request to TNMAccess, where surface analysis can begin. Once a site is selected, the user can demarcate structures, roads, and potential barriers to plants that are present but not recorded to cull any areas \nincapable of supporting plant life. \n\nThe development of a user interface or user experience (UI\/UX) can lower the barrier of entry \nto individual landscape design. User interface is considered the format in which users see and \noperate the software, which should contain simple and concise language to explain the concepts at play in landscape design such as elements of analysis, plant environment descriptions, and list of results provided by the algorithm. This is considered front end development: \nthe side that the user is allowed to see. All the user’s inputs are relayed to the back end of a \nsoftware to be analyzed before a response is sent back to the front with a clear visual result \n(Fig.4). \n\nUser experience is the act of using the software and experiencing it through various steps to \nproduce a valid result. The flow of this process includes clear language to describe what each \ncomponent is and how it changes the result. This includes the language and response of any \nanalysis performed by the application. The goal of this experience is to provide the user with \na simplified approach to landscape design, performing site-specific landscape analysis in the \nback end to produce a tailored result for further consideration. \n\nDiscussion \n\nThe creation of a digital planting tool geared towards the general public provides an accessible platform that can elevate the ecological diversity and architectural quality of typically \nunderutilized landscapes. The use of this proposed process does not necessarily end with the \nindividual user in a single-family home setting, but can be applied in a broader application \nfor use in community organizations and people interested in improving the landscape of their \ncommunity spaces. \n\nWhile the project does accurately complete the task of planting design, it performs mainly as \nbackend development with complex inputs. Further exploration into user interface and user \nexperience front end could improve the clarity of language and process of the tool, and ultimately may be able to compile a custom document regarding maintenance and further resources for the end user for future planning. Further back-end analysis of landscape can increase the accuracy of the results regarding unique species preferences, or the variable shade from vertical layers of vegetation. \n\nCertain limitations apply to the accuracy and scope of an accessible planting tool, with datasets  needing  to  be  researched  and  formatted  to  a  uniform  spreadsheet.  One  approach  to \nexpanding this process into a United States-wide resource would be the use of the Federal \nHighway Administration’s Ecoregional Revegetation Application (ERA). This resource is a \ncompiled list of plant species and related information found in ecoregions across the entire \nUnited States, including Alaska and Hawaii (STEINFELD et al. 2007). \n\nThrough  this  framework,  it  is  possible  to  begin  the  development  of  a  tool  that  brings  informed, site-specific planting information to the general public. \n\nRobots in the Garden: Artificial Intelligence and \nAdaptive Landscapes  \n\nAbstract: This paper introduces ELUA, the Ecological Laboratory for Urban Agriculture, a \ncollaboration among landscape architects, architects and computer scientists who specialize \nin  artificial  intelligence,  robotics  and  computer  vision.  ELUA  has  two  gantry  robots,  one \nindoors and the other outside on the rooftop of a 6-story campus building. Each robot can \nseed, water, weed, and prune in its garden. To support responsive landscape research, ELUA \nalso includes sensor arrays, an AI-powered camera, and an extensive network infrastructure. \nThis  project  demonstrates  a  way  to  integrate  artificial  intelligence  into  an  evolving  urban \necosystem, and encourages landscape architects to develop an adaptive design framework \nwhere design becomes a long-term engagement with the environment.  \n\nIntroduction \n\nIn the discipline of landscape architecture, a major epistemological framework has assumed \nthat the environment is a closed and static system that can be measured, predicted, and conceivably controlled by technology (LYSTRA 2014). The reality of severe climate change challenges this view. Although advancements in industrial technology have given humans some control over their environment, carbon continues to be released into the atmosphere at unprecedented rates. While science rigorously measures and predicts the increasingly grim im-\npact of human decisions, quantities of computer-processed data and complex control policies \nhave yet to provide straightforward solutions to climate change. This paper argues for a research paradigm where artificial intelligence (AI) helps adapt landscapes to a changing environment rather than control them. It considers the role AI can play within this new focus on adaptivity, and how they can contribute to an adaptive design framework that requires a long-term engagement with the environment. \n\nELUA, the Ecological Laboratory for Urban Agriculture, offers a case study for an evolving \necosystem, embedded with AI, that responds to the uncertainties of a changing climate. In a \ncollaborative endeavor among computer scientists, landscape architects and architects, two \ncommercial gantry robots and an extensive infrastructure support cultivation in two polyculture  gardens (Figure  1).  Our  work  includes  construction  and  customization  of  the  robots, \nincorporation of sensor arrays, an AI camera, and network infrastructure, as well as the design \nand construction of the garden beds.  \n\nIn the past two decades, many landscape programs have built laboratories with machinery \nand a “lab culture” as both research and education infrastructure. Examples include Alexander Robinson’s work at the Landscape Morphologies Lab of the University of Southern California(ROBINSON  &  DAVIS  2018);  Bradley Cantrell  and Xun  Liu’s work  with hydromorphology tables at the University of Virginia and Harvard University (LIU 2020); Matthew Seibert’s work at Milton Land Lab;1 and Ilmar Hurkxken and Christophe Girot’s Robotic \nLandscape work at ETH Zurich (HURKXKENS 2020). Each of these develops landscape laboratories that integrate physical spaces with customized tools and machinery. \n\nThis phenomenon mirrors the 21st-century development in landscape theory that prioritizes \ndynamic landscape processes and ecological evolution over static forms. Landscapes are imagined to evolve with recursive and process-based strategies over time, instead of as a one-time construction. Projects such as the Fresh Kills and Downsview Park competitions in the early 2000s weres examples of this design paradigm (CZERNIAK 2001, REED & LISTER 2014). Since then, many scholars have incorporated a broad range of ideas and concepts from both sciences and humanities to diversify and develop that paradigm. They include multispecies \nco-production,  novel  ecology,  feral  ecology,  and  cyborg  landscapes  (HOUSTON,  HILLIER, \nMACCALLUM, STEELE & BYRNE 2018, KLOSTERWILL 2019, PROMINSKI 2014). In addition, new tools have been imagined for integration into landscape systems that would execute process-based strategies and co-evolve with other landscape actors (CANTRELL & HOLTZMAN \n2015). \n\nOur research contributes to this body of work in theory and practice. We view an intelligent \nsystem, like its human counterparts, as an imperfect agent, rather than an omniscient, omnipotent black box. The perspective  of  collaborative  intelligence (EPSTEIN  2015) provides  an emergent, constructive view of artificially intelligent agents that participate in and support a collaborative  design  process.  We  envision  an  alternative  future  where  technology  plays  a more integral role in adaptation to rapidly changing environments. \n\nThis paper documents the design, construction, and preliminary testing of ELUA, and provides practical recommendations for such landscape laboratories. It also reflects on the ramifications of ELUA for landscape design and argues for a new research paradigm where AI \nis  an  integral  part  of  evolving  ecosystems.  From  our  perspective,  landscape  design  is  no \nlonger a finished product, but a long-term engagement and collaboration with an assemblage \nof actors, including AI systems, that co-creates an evolving ecosystem.  \n\nTechnologies and Design-build  \n\nELUA has two sites within the Spitzer School of Architecture at City College of New York, \nan outdoor garden on a rooftop and an indoor garden in a communal area near the landscape \nstudios. The outdoor garden (shown in Figures 1 and 2) focuses on growing food; the indoor \ngarden (shown in Figures 1 and 3) is used for education, prototype research, and experimental \ndevelopment.  \n\nInitial Hardware and Software \n\nBoth ELUA robots are from FarmBot,2 a California-based firm that designs and markets open-\nsource commercial gardening robots, and develops web applications for users to interface with \nthose robots. These are gantry robots that operate in three dimensions and employ interchange-\nable tool heads to rake soil, plant seeds, water plants, and weed. FarmBots are highly customi-\nzable; users can design and replace most parts to suit their individual needs. For ELUA, we have \ndesigned and 3D-printed our own watering nozzles, seeders, seed troughs, and camera mounts. \n\nFarmBot’s supporting code for farm design and robot control is also open source; users can \ncustomize  it  through  an  online  web  app.  This  allows  us  to  revise  or  replace  the  provided \nexecutable programs and to introduce new functionality into ELUA. The basic FarmBot code \nvisualizes garden designs before planting, photographs the garden, and provides primitive \nsensing and behaviors. \n\nCustomization for Robot-assisted Gardening  \n\nWe customized each of ELUA’s robots in several ways for our indoor and outdoor gardens, \nand both systems function as intended. ELUA’s rooftop robot has 2-meter tracks from a third-party vendor tailored to the spatial parameters of its site; they replace FarmBot’s original (x-axis) 1.5-meter robot tracks. To install the tracks on the I-beams on the rooftop, we designed \nand built our own joints. We developed planters made with standard milk crates lined with a \nlayer of geo-fabric. This modular approach provides flexibility to the entire rooftop design \nand  installation.  The  5'x5'  structural  frames  are  custom-built  with  10-foot,  16-gauge  steel \ndrywall studs and tracks, cut to size and assembled on-site with L-shaped corner clips. The \nstructural frames fit between two I-beams and support milk crate planters or wooden planting \nboxes (Figures 1, 2 and 4). As shown in Figures 1 and 3, the indoor system consists of a \nblack-pipe armature for the robot and mobile garden beds, instead of gantry tracks fixed directly onto the garden beds as suggested by FarmBot Inc.. This armature design allows us to \nremove and replace mobile garden beds if needed without deconstructing the entire gantry.  \n\nThe rooftop garden will eventually be used by a student group to produce food. In contrast, \nthe indoor garden is intended for more advanced experiments, where we will prototype and \ndevelop new algorithms, tool heads, and operations to be used for both robots.  \n\nEach FarmBot includes a camera that photographs the garden, with software to roughly stitch \nthe images together. We developed algorithms to improve image mosaicing (DICKSON et al. \n2002, MOLINA & ZHU 2014). Meanwhile, we installed a second, more powerful AI camera \nOAK-D camera3 to perform more advanced computer vision tasks, such as depth detection, \nweed detection and plant identification. We have used this AI camera and developed seamless image stitching for two-dimensional aerial views in ELUA that are more accurate and \nmore visually appealing.  \n\nInitially,  the  user  describes  the  garden’s  contents  to  a  FarmBot  as  a  simple  placement  of \nplants from the provided “plant dictionary” on a garden map, a two-dimensional grid visualized by the web app. FarmBot stores the location of each plant as a datapoint (x, y) on that \nmap. Other emerging plants, if detected by the camera, are treated uniformly as “weeds” that \nshould be managed by the robot. FarmBot’s software has no plant identification algorithm to \ndifferentiate between different weed species. Some “weeds,” however, such as dandelion and \npurslane, are edible, while others, such as red clover, can fix nitrogen and support soil health. \nWe expect that these species could play important roles in an urban polyculture garden and \nincrease urban biodiversity and resilience. Thus, we intend to process images from the AI \ncamera with deep learning models to detect such opportunistic species, record their locations \nin the garden map, and have the robot cultivate all welcome but unanticipated plants.  \n\nMultimodal Sensing and the New Database \n\nIn  addition  to  the  FarmBot  armature,  our  gardens  are  designed  to  benefit  from  additional \nsensors. We have incorporated an array of capacitive soil-moisture sensors connected to a \nmicrocontroller with a WiFi module. Our outdoor garden also includes a personal weather \nstation  connected  to Weather  Underground. With  their  application programming  interface \n(API) service, we can access real-time and historical weather data, as well as a seven-day \nweather forecast from the rooftop. Additional sensors could be similarly installed to measure \nother environmental factors, such as solar radiation, CO2, and air pollution.   \n\nTo incorporate this sensor data into ELUA, we have created a virtual server that hosts our \nown database as well as any API services. This greatly expands ELUA’s capability because \nit connects each FarmBot to other types of open data and services. For example, with weather \nforecast data, ELUA could modify scheduled watering regimens for precipitation and drought.  \n\nMachine Learning and AI \n\nAI is pervasive in this research. Non-experts. including many landscape researchers, often \nthink of an AI system as a general artificial intelligence that addresses multiple goals simultaneously. In ELUA, however, AI algorithms are individually built for specific tasks.  \n\nIn ELUA, the AI camera we added processes images with OpenCV, an open-source computer \nvision  and  machine  learning  software  library.  This  provides  machine  learning  algorithms, \nincluding pre-trained deep neural network modules that can be modified and used for specific \ntasks, such as measuring plant canopy coverage and plant height. Machine learning and AI \nplanning can also be used with the multimodal sensory data described in Section 2.4 to provide data-driven guidance to improve garden management. \n\nAn AI system that relies on reinforcement learning (RL) develops a policy for its behavior \nwhen it is rewarded or punished for the outcome of its actions. Such systems have devised \nunexpected behaviors in Go, chess, and some video game that expanded human players’ understanding of these games and provided new insights (SCHRITTWIESER et al. 2020). Landscape architects and ecologists now also imagine how RL systems might manage the environment and construct wild landscapes (CANTRELL et al. 2017, ZHANG & CANTRELL 2021). One research team conducted RL experiments to prune a polyculture garden with a FarmBot \nto increase biodiversity (PRESTEN et al. 2022). We will perform RL experiments in a simulated environment with a virtual robot and later test the learned policies with a physical robot. \nWe envision a version of ELUA that will evolve and propose novel methods, such as combinations of different watering nozzles and watering paths in different scenarios. We hope some \nunexpected  combinations  will  surprise,  intrigue,  and  inspire  us  with  their  successful  outcomes that help the garden adapt to a changing climate.  \n\nResults and Discussion \n\nIn the fall of 2022, we planted herbs on the rooftop and lettuce and herbs in the indoor garden \nto learn and test the basic functions of the robots. (The indoor ELUA robot in action appears \nin  a  brief  video  at  https:\/\/youtu.be\/VTec_SXO5Lk.)  Both  ELUA  robots  captured  garden \nmaps and carried out watering events as expected, although maintenance and troubleshooting \nare needed from time to time. This is a design-build project and every aspect of ELUA was \nconstructed  by  faculty  and  students.  Our  team  has  gained  hands-on  knowledge  as  it  constructed ELUA. Here, we offer three recommendations.  \n\nFirst, in cities like New York, public and free resources are available for academic research \nand well worth the time to track down the networks of organizations and groups. We received \n3 cubic meters of free, clean mineral soil from the NYC Clean Soil Bank hosted by the NYC \nMayor's Office of Environmental Remediation. The soil was delivered by the crews from the \nNew York Restoration Project. We received 40 bags (1 cubic meter) of compost from the \nNYC Composting Project hosted by Big Reuse. In return, we took the Big Reuse crews to \ntour ELUA, and hope to maintain this relationship. We learned about our current soil mix (⅓ \nmineral  soil,  ⅓  compost,  and  ⅓  perlite)  during  a  free  guided  tour  of  a  green-roof  facility \nhosted by the NYC Department of Parks & Recreation. ELUA would have been far more \ncostly and difficult to construct without these public resources. We encourage prospective \ndevelopers to seek out similar assistance. \n\nSecond, “open-source” offers adaptivity to its users but also forewarns the necessity of substantial troubleshooting. Although FarmBots appears to be user-friendly, some knowledge of \ncomputer science and electrical engineering is required to set up such a system. Researchers \nand research assistants from our Departments of Computer Science successfully overcame \nmany issues during our installation. Moreover, a licensed architect on the team successfully \ndesigned and constructed the garden beds and installed a FarmBot onto the existing load-bearing rooftop structure. A multidisciplinary team of computer scientists and designers is \nhighly recommended to replicate ELUA.  \n\nFinally, institutional knowledge is important in academic research. Institutional structures in \nuniversities, especially public schools, can support or hinder academic research visions. Researchers need to be nimble and adaptive in pursuing their goals. For example, thanks to the \nArchitecture School, the Colleges, and the University, we received multiple seed funds for \nELUA.  The  Architecture  School  also  provided  space  and  infrastructure  to  house  ELUA. \nSome rules, however, could not be bent. Because the University’s security regulations blocked \nnetwork ports used by a FarmBot, we have had to set up alternative 5G Wi-Fi hotspots untill \nthe University can provide a research-only network. We recommend an ample buffer in the \nresearch schedule to account for unexpected circumstances, as well as a good rapport with \nuniversity offices.  \n\nConclusion  \n\nDespite ELUA’s practical focus on urban food production, it is also a thought experiment \nthat challenges landscape architects’ conventional views on agency and intelligence. With \nELUA, we want to formulate a theory that questions how the environment is conceived and \nconstructed.  To  some  extent,  ELUA  offers  a  glimpse  into  an  ecosystem  of  computerized \necology where the relationship between humans and plants is deeply mediated and, at the \nsame time, enabled by sensors, controllers, computer hardware, layers of computer code, and \nonline servers.   \n\nA  problem  in  the  perspective  of  landscape  architecture  is  its  current  conception  of  AI  as \nintelligence embodied in a single agent (CANTRELL & ZHANG 2018). Ideas in posthumanism, \nhowever, such as assemblage and sympoiesis become new concepts to reframe agency and \nintelligence as distributive (BENNETT 2010, HARAWAY 2016, TSING 2015). From this posthu-\nmanist  perspective,  intelligence  should  be  viewed  as  an  emergent  epiphenomenon  arising \nfrom the interactions of an assemblage of actors – humans, AI agents, animals, and plants. \nThis framing sheds light on a new landscape design paradigm based on co-evolution among \nbiotic  and  abiotic  agents.  We  could  allow  AI  systems  and  plant  and  animal  agents  to  co-evolve to create novel ecosystems that inspire us with new methods to construct the land-\nscape.  \n\nIn  this  new  landscape  design  paradigm,  AI  agents  would  no  longer  simply  model  human \nbehavior under human control. Instead, they would become co-creators among human and \nnonhuman  actors.  They  could  offer  novel  approaches  and  long-term  cultivation  strategies \nthat humans can learn from and use to adapt to the changing climate. ELUA is a physical \ndemonstration of this new paradigm of landscape design. It provides empirical evidence that \ncollaboration among AI agents and other human and nonhuman actors is within reach.  \n\nToward Acoustic Landscapes: A Digital Design \nWorkflow for Embedding Noise Reduction in \nGround-forming  \n\nAbstract: Noise pollution is considered the number two environmental health risk in Europe, and there \nis increasing global awareness of the health risks associated with noise exposure. As urbanization expands, a growing number of people are exposed to urban noise, to which airports and large urban infrastructure are significant contributors. Unlike indoor noise, which is extensively addressed using digital \ntools in architecture, there are limited parallel efforts in landscape architecture. In this context, mitigating outdoor noise through ground forming can replace the standard use of sound barriers and offer noise \nreduction means together with recreational use. The paper presents and demonstrates a digital workflow \nfor designing acoustic grounds. The workflow links environmental noise data, parametric design, and \nacoustic simulation in a single design environment. A case study site adjacent to Munich Airport is \nused to demonstrate the workflow and comparatively examine the acoustic performance of different \ndesign patterns. The results indicate a possibility of reducing noise levels through ground forming.  \n\nIntroduction: In Search of a Vast, Horizontal Acoustic Tile \n\nIn  2011,  noise  pollution  was  named  the  number  two  environmental  health  risk  in  Europe \n(WORLD HEALTH ORGANIZATION 2011). Since then, the World Health Organization (WHO) \nhas  constantly  been  updating  the  health  risks  associated  with  noise  exposure  (WORLD \nHEALTH ORGANIZATION  2022).  As  urban  areas  expand,  the  number  of  people  exposed  to \nurban  noise  grows.  Airports  and  large  urban  infrastructure  significantly  contribute  to  this \nnoise (BOUCSEIN et al. 2017). In addition, the propagation of noise caused by transport infrastructure has been shown to increase through poor urban design (MORILLAS et al. 2018). Existing methods for mitigating outdoor noise typically consist of prefabricated, vertical indus-\ntrial acoustic walls. In contrast to acoustics in architecture, where digital tools are used to \ndesign and fabricate site-customized acoustic tiling, outdoor noise is not  met with similar \nmeans. However, preliminary examples indicate that formed grounds could mitigate sound. \nDespite this potential, there is a lack of dedicated methods for creating acoustic grounds in \nlandscape architecture. Mitigating noise through acoustic grounds could be beneficial for urban airports, which are typically bordered by buffering open spaces. In such areas, ground \nforming can provide noise mitigation as well as public recreational use. \n\nContext and Objective \n\nDigital tools enable the introduction of preciseness into landscape architecture design and \nmaking (CANTRELL & MEKIES 2018). Preciseness is defined here as the process of highly-articulate tailoring of a design for mitigating a natural phenomenon. In this context, the design of acoustic grounds requires linking environmental data relating to noise to a landscape \ndesign aiming to mitigate it. The research seeks to promote noise mitigation through what \ncan be viewed as the horizontal, ground-made, site-tailored version of an acoustic tile. To this \nend, the paper presents a digital design workflow for embedding noise reduction and simulating \nacoustic performance in landscape architecture. The workflow is based on a method for incorporating  acoustic  analysis  in  landscape  architecture  design  developed  by  the  authors  (BARSINAI et al. 2023). This is demonstrated through a case study site in Hallbergmoos, adjacent to \nthe  Munich  airport,  which  is  amongst  the  ten  busiest  airports  in  Europe  (BOUCSEIN et  al. \n2017). Currently, no physical noise reduction measures exist in the area (Figure 1). \n\nState-of-the-art: Design and Simulation of Acoustic Grounds \n\nThere is a growing awareness of the need to protect from noise in outdoor spaces (SORVIG & \nTHOMPSON 2018). In the context of airport noise, mitigation is addressed through three levels: a primary level, which targets the noise source and is applied during the production \nof aircraft; a secondary level, which adapts aircraft arrival and departure procedures; and \na tertiary level which includes measures by the local airport of aviation authority grounds \n(NETJASOV 2012).  \n\nUntil recently, tertiary-level noise mitigation measures around airports did not include the \nformation of acoustic grounds. This possibility is beginning to be explored in landscape architecture projects, demonstrating a capacity to mitigate noise and vibrations through targeted \nground forming. For example, Buitenschot Park demonstrates a reduction of the Schiphol airport noise through the construction of ground ridges and furrows. The park design distorts \nand disperses low-frequency noise waves, which have been reported to reduce the noise surrounding the airport by 10 dB (TASHAKKOR et al. 2020). A similar approach employed ground-\nforming for mitigating vibrations around a MAX Lab IV in Sweden  \n\n(WALLISS & RAHMANN 2016). These two examples challenge the standard practice of constructing absorbing sound barriers surrounding urban noise sources. However, there is still a \nlack of methods for performing noise mitigation through ground forming.  \n\nAcoustic simulation is often performed using stand-alone tools (SAKUMA et al. 2014), and as \nsuch, they do not readily support design iteration. While there are dedicated frameworks to \nintegrate acoustic simulation in architectural design (PETERS 2015), there is a lack of similar \nmethods for embedding noise reduction in landscape architecture design processes. Pachyderm, a recently developed open-source tool, performs ray tracing-based sound propagation \nsimulation and visualization embedded in 3D design environments (VAN DER HARTEN 2013). \nHowever, despite the availability of Pachyderm, there is still a need for methods for applying \nit toward noise reduction in the design of open spaces. The lack of such methods currently \nlimits the possibility of addressing noise in landscape architecture and urban design. \n\nAcoustic Landscape Design Workflow \n\nThe paper addresses these gaps by developing a digital workflow that links noise, design, and \nsimulation for embedding acoustic performance in landscapes. The workflow consolidates \nthe design and simulation in a single digital environment. It consists of noise data analysis, \nthe design of parametric ground formations, and acoustic simulation and evaluation. \n\nNoise Data Analysis: Combining Online and On-Site Measurements  \n\nAirport  noise  consists  of  ground-level  noise  as  well  as  noise  produced  by  aircraft  during \ntakeoff,  landing,  taxiing,  and  idling  stages.  The  Munich  Airport  tracks  noise  in  real-time \nthrough monitoring stations and provides publicly available data (MUNICH AIRPORT 2022). \nHowever, only one of the monitoring stations is positioned on the perimeter of the site. In \naddition, the monitoring stations are situated 4 m above ground. This height is determined by \nthe  Environmental  Noise  Directive  (END)  (EUROPEAN COMMISSION  2002),  as  it  is  where \nreflections from the ground stop playing a major role. Measurements performed above 4 m, \ntherefore, allow the official comparison of different contexts. This calculation method is also \nthe basis for all the noise abatement measures. However, measurements at the height of 4 m \nlimit the possibility of understanding the noise as it is perceived by a listener on-site.  \n\nTo  sense  the  noise  as  it  is  felt  on-site,  the  study  combined  online  data  with  on-site  noise sampling using mobile phones. The use of mobile devices has become an increasingly prevalent method for collecting environmental data (MURPHY & KING 2016). The noise sampling \nwas conducted using five different devices. The devices simultaneously recorded the noise \nlevels during takeoff and landing on five points on-site for 90 consecutive seconds (Fig. 2). \n\nDespite their limited accuracy, and while at this point of the research, no identifiable rela-\ntionship between the official and on-site sampling could be specified, the mobile phone meas-\nurements provided a picture of the felt noise levels on the ground. This noise, therefore, also \nincludes the ground effect which the official measurement stations exclude. While the official \naveraged noise contour (BAVARIAN MINISTRY OF ENVIRONMENT 2021) is limited to the runway areas (Figure 1), the on-site noise sampling recorded peaks of 75 dB and above beyond \nthe airport fence and within Hallbergmoos, underscoring the need for noise abatement in the \narea notwithstanding the averaged noise levels. \n\nDesign: Parametric Ground Formations \nThe design first proposed a basic layout for the park and coupled the desired noise mitigation \nstrategy with urban design considerations. The plan defined the movement paths, program, \nand areas dedicated to acoustic ground-forming (Figure 3). In these areas, the research tested \nformations consisting of mounds with public paths located between them. Four design patterns were tested at three heights: 2.5 m, 5 m, and 7.5 m. These included: high-to-low (HL), \nundulating mounds in gradually decreasing heights (7.5\/5\/2.5 m – 0.5 m); low-to-high (LH), \nundulating  mounds  in  gradually  increasing  heights  (0.5  m  -2.5\/5\/7.5  m);  constant  height \nmounds (CM), featuring uniformly sized undulating mounds (tested in 2.5\/5\/7.5 m); and constant heigh solid ground (CS), an elevated ground without any undulation mounds (tested in \n2.5\/5\/7.5 m). The width of the mounds was set to 21 m to provide an inclination and slope \nthat allow public accessibility even in the higher-mound instances (Figure 3).  \n\nAcoustic Simulation and Evaluation \n\nThe simulation process includes several aspects:  \n\n1)  A  base  model  –  the  base  model  aimed  to  reproduce  the on-site  conditions  and  noise \nlevels  as  measured  before  any  ground  modification.  In  construction,  base  models  are \noften referred to as 'digital twins,' a digital environment that simulates the existing condition in the physical environment (BOSCHERT & ROSEN 2016). The topography and the \nbuilt fabric were created using Blender with imported layers derived from Shuttle Radar \nTopography Mission (SRTM) data, a GIS data source with a 9-16 m accuracy. The model \nwas then placed in a bounding box to support the acoustic simulations.  \n\n2)  Noise source (emitter) – the noise source was introduced into the model and situated on \ntakeoff lane 08R\/26L at a level of 75 dB. The simulation works as a transfer path that \ndisperses the noise. The transfer path holds a noise spectrum with several frequencies. \nHowever, simulations, including the presented ones, rarely include all frequencies.  \n\n3)  Simulation tool – for simulating sound propagation, the research employed Pachyderm \nRC 26, an open-source tool that integrates acoustic simulation and visualization in a 3D \ndesign environment (VAN DER HARTEN 2013). Pachyderm provided a ray tracing-based \nmethod and was integrated into Grasshopper and then linked to the base model. This \nintegration allowed performing the design and the simulations in the same digital environment. The research employed an i7 processor, 32GB of RAM, and an Nvidia Quadro \n1000 graphics card which could not perform a full-site acoustic simulation due to insufficient processing power, memory, and graphic processing.  \n\n4)  Noise sampling grid and points (receivers) – to address the simulation challenge, the \nstudy  developed  a  method  for  sampling  the  acoustic  performance  using  a  grid  with \n20\/20m size cells. Within this grid, three listener points were positioned as noise receivers at a height of 1.65 m (Figure 4). Point 1 was closest to the airport runway, point 2 \nwas in the middle of the site, and point 3 was in the residential area of Hallbergmoos. \n\nEvaluation – while the simulation calculated noise levels, the evaluation focused on the relative reduction in the noise levels as measured in the model before and after the design intervention and reformed grounds. The focus on the reduction levels allowed us to analyze noise \nreduction as a trend and compare the acoustic performance of the different design scenarios. \n\nResults \n\nThe results of the simulations, summarized in the table (Table 1) and graph (Figure 5), can \nbe viewed through three aspects: listener points, design, and height. Each scenario is referred \nto according to the initials of the design pattern, followed by the height in m (i. e., CS2.5). \n\nPerformance by Listener Point \n\nPoint 1: The best noise mitigation was achieved here with HL5 (28.4 dB reduction) followed \nby CS2.5 (27.5 dB reduction), C7.5, and CS7.5 (27.4 dB reduction). Last ranked the LH 2.5 \n(1.3 dB reduction).  \n\nPoint 2: The best noise mitigation was achieved with C5 (26.4 dB), poorest performance \nwith LH2.5 (1.3 dB reduction).  \n\nPoint 3: The best mitigation is achieved with CS7.5 (21.9 dB reduction), followed by C5 \n(21.6 dB), then CS5 and HL7.5 with a similar noise reduction (20.5 dB reduction). The poorest performance was CS2.5 (16.2 dB).  \n\nPerformance by Design Pattern \n\nHigh-to-low (HL): This design showed the most effective noise reduction levels at point 1 \nfor all heights. The best performance was achieved with 5 m mounds which showed an average reduction of 23.9 dB across the three points.  \n\nLow-to-high (LH): In this design, there was a significant difference in effectivity between \nthe lower mound patterns (2.5 m) and the 5 and 7 m high ones. The best average reduction \nacross the three points was attained by the 5 m high mounds (23.1 dB).  \n\nConstant  mounds  (C):  This  design  demonstrated  highly  effective  noise  reduction  levels. \nThe highest effectivity was attained by the CM2.5 (24.7 dB), followed by CS7.5 (24.7 dB), \nand CS5 (24.1 dB).  \n\nConstant solid height (CS): This design demonstrated that CS5 performed better than CS2.5 \n(4.3 – 2.2 dB difference), CS 7.5 performed better than CS5 at point 1, but CS5 performed \nbetter than CS 7.5 m at points 2 and 3. The average reduction of CS5 and 7.5 m was equal.  \n\nPerformance by Height \n\n2.5  m:  Constant  mounds  perform  best  at  all  points,  followed  by  the  constant  solid.  LH \nshowed the poorest performance at points 1 and 2 and then a significant increase in performance once height was reached toward point 3. At point 3, HL and LH performed with a \nnegligible difference.  \n\n5 m: At this height, the HL pattern demonstrated the best performance at point 1. In average \nperformance, however, constant mounds outperformed HL with an average reduction of 24.1 \ndB compared to 23.8 dB by HL. CS followed with an average reduction of 20.67 dB.  \n\n7.5 m: At this height, HL, C, and CS all lost effectiveness with distance. The LH section \nperformed marginally better at point 2 than at point 1 (0.4 dB). All the designs at this height \nshowed the lowest noise reduction at point 3. \n\nDiscussion \n\nAcoustic Performance Trends \n\nIn line with existing works, the results indicate a possibility of reducing noise levels through \nground forming. A few noteworthy trends can be summarized based on the acoustic performance results:  \n\n1)  Higher does not equal better – while we would expect the highest mounds to perform \nbetter,  the  simulations  showed  that  performance  is  impacted  more  by  design  than  by \nheight. The  best-performed mitigation,  HL5,  was not  achieved  by  the  highest design. \nThe lowest height, C2.5, outperformed other designs and showed an equal performance \nto C7.5. In addition, in comparing the same design at different heights, such as in the HL \npattern, the best performance was shown at 5m rather than 7.5 m.  \n\n2)  The benefit of patterns – the results indicate the benefit of the constant mounds (CM) \npattern in relation to constant solid ground (CS) for mitigating noise. This trend can be \nclearly seen by comparing the CS2.5 m to the other patterns, as well as in the high average performance of CM in relation to the CS 5 pattern.  \n\n3)  High-to-low  outperforms  low-to-high  mound  patterns–  overall,  the  patterns  that \nranged from high to low performed better than the designs ranging from low to high. A \nsignificant  difference  was  seen  with  the  LH2.5  pattern,  which  had  the  lowest  performance (1.3 dB reduction) compared to the other results. An exception is LH 7.5, with \nslightly better performance than HL7.5 at point 2. This trend may indicate that patterns \nincreasing in height in the direction of the noise dispersion provide less effective mitigation unless they are high enough to form a barrier adjacent to the noise source, which \nexplains the improved performance of LH5 and LH7.5.  \n\n4)  Constant height outperforms inclined, high-to-low slopes – constant mounds (CM) \nshow great effectivity regardless of their height, and mounds as low as 2.5 m can yield \nsignificant noise reduction. This result aligns with the effectivity demonstrated around \nthe Schiphol airport, where constant-height ridges and furrows were used and reportedly \nreduced the noise levels by 10 dB (TASHAKKOR et al. 2020). However, in comparison to \nridges, mounds can offer more accessible and versatile public use throughout the park, \nnot limiting public activity to the furrows. \n\nContribution and Current Limitations  \n\nThe paper contributed a novel digital workflow for designing acoustic grounds. The work-flow provides and demonstrates a step-by-step guide for parametrically designing, prototyping, simulating, and evaluating noise mitigation through ground forming. The digital work-\nflow includes several steps – noise analysis, parametric design, and acoustic simulations, and \nallows for comparatively evaluating ground formations to understand their noise mitigation \neffectivity.  \n\nThe  workflow  was  demonstrated  in  a  site  adjacent  to  the  Munich  airport.  The  parametric \ndesigns featured three patterns of undulating mounds and one constant-height solid ground \nat  three different  heights.  The  acoustic  evaluation  was  performed  by  comparing  the  noise \nlevels  before  and  after  the  ground  modification  in  selected  points  within  the  simulation \nmodel. The results indicate the benefit of using constant height, undulating mounds rather \nthan inclined patterns of higher flat elevated grounds as a noise mitigation strategy.  \n\nDue to the complexity of the task at hand, the study faced several limitations, which will be \naddressed in future work. First, the complexity of acoustic simulations increases significantly \nwith the size of the tested area and, along with them, the computing time. This complexity is \na  current  obstacle  in  using  such  tools  in  landscape  architecture.  In  the  future,  this  can  be addressed with improved processing power, memory, and graphics processing capabilities. \nAlternatively, a different simulation method with a lower sampling rate could be used. The site  could  also  be  divided  into  smaller  parts,  simulated  separately  before  their  results  are \ncombined. Second, the research focused on noise propagation and did not look at: the frequency aspect; the effects of weather, a factor known to influence noise; and the effect of \nnoise absorption on the ground surface and the way different ground covers may contribute \nto reducing noise transmission. Finally, future work will also look at additional design patterns, varying heights, and regularity vs. irregularity and consider these factors in relation to \nmultiple noise emitters in various locations. \n\nConclusion and Outlook \n\nThe presented workflow allowed us to comparatively assess the acoustic performance of different landscape designs and discern trends associated with their design features. This contributes to the capacity to embed acoustic performance in landscape architecture and mitigate \nnoise pollution through ground forming. The digital workflow can be used for addressing \nnoise around other airports as well as around other sources of urban noise or large transportation infrastructure. As such, the workflow also promotes a broader endeavor – the development  of  dedicated  methods  which  link  environmental  data  and  parametric  design  toward \nforming performative grounds in response to environmental challenges. \n\nUrban Agriculture:  \nClimate-Responsive Design Strategies for \nBlue Infrastructure in the Context of Singapore \n\nAbstract: Global climate change poses various threats to densely developed cities and their urban infrastructures. As an archipelago and product of many significant land reclamation efforts over the centuries, Singapore is most vulnerable to rising seawater levels and faces increasing climate change-related challenges, including intense rainstorms, water scarcity, food shortage, and extreme heat. This \npaper proposes a Synergy System, or climate-responsive computational design method, to create a new \ntypology of urban agriculture integrated with the existing infrastructure. This study employs performance-based generative design to generate typologies and optimize them in terms of driving factors \nsuch  as  food  production  and  microclimate  adjustment.  The  performance  evaluation  model  as  a  tool \nsupports the design of multifunctional and climate-responsive infrastructure typologies. \n\nIntroduction: Climate Challenges in Singapore \n\nAs a highly urbanized city, Singapore has suffered from complex challenges related to climate change, putting climate adaptation in the spotlight for future urban development. Singapore’s main climate crisis includes intense rainstorms, water scarcity, food shortage, and \nextreme heat (NATIONAL CLIMATE CHANGE SECRETARIAT 2022). For instance, frequent extreme rainstorms have put overwhelming stress on the stormwater infrastructure and have caused flash floods in urban areas (PUB 2022). Half of Singapore’s fresh water supply relies \non imports from Malaysia (ROMAN & CHEOK 2016), which will end in 2060. In addition, \n90% of Singapore's consumer food is imported, motivating local food production to achieve \n30% food self-sufficiency by 2030 (TENG & MONTESCLAROS 2019).  \n\nThe increasing challenges on urban infrastructure and residents’ daily lives have raised increased concerns about building a climate-resilient city for the future. The concept of urban climate  resilience  emphasizes  city  and  urban  infrastructure  as  a  complex  adaptive  system \nwith the ability to maintain basic functions in the face of climate disruptions (MEEROW et al. \n2016).  \n\nThe main climate challenges Singapore faces are closely related to three aspects: stormwater \ninfrastructure, urban agriculture, and microclimate. The synergies between them serve as the \nbasic  logic  for  building  climate-responsive  infrastructures.  Concrete  canals,  one  typical \nstormwater infrastructure, cannot accommodate peak flows during extreme rainstorms and \nare ineffectively utilized during the dry season. They are required to be transformed into a \nnew generation of infrastructure bolstering ecosystem services (LIQUETE et al. 2015). This \ncan be achieved by integrating a new typology of urban agriculture with the concrete canals, \nwhich promotes “the well-being of urban ecosystems and resilience in a circular economy.”(DEKSISSA et al. 2021). \nMoreover, decentralized urban farming integrated with underutilized \nspaces is a sustainable way to enhance local food production (SINGAPORE FOOD AGENCY \n2021). Utilizing the rainfall collected in canals for food production contributes to water conservation,  which  is  highly  imperative  to  sustainable  vertical  farming  (ASSOCIATION  FOR \nVERTICAL FARMING et al. 2015). Furthermore, the food-growing structures provide shading \nfor  microclimate  mitigation,  as  vegetation  shading  can  effectively  reduce  solar  heat  gain \n(OLGYAY 1963).  \n\nIn terms of the identified research gap, the synergies among the above three aspects have not \nbeen fully investigated and implemented into a computationally driven design strategy. A \nnew approach is required to explore the material flow of this synergy system and design a \nclimate-responsive typology based on its performance on food production and microclimate.  \n\nCore Synergies \n\nThe core synergies are summarized as follows (Figure 1): The rainfall collected in the stormwater infrastructure can be supplied for food production, while the growing plants provide \nvegetation  shading  for  cooling  the  microclimate.  Stormwater  infrastructure  in  connection \nwith urban agriculture can increase drainage capacity, offer accessible community spaces, \nimprove green features, and create comfortable microclimates.  \n\nThe synergies set the fundamental logic for a new computational design approach to transform existing monofunctional concrete canals into an adaptable and multifunctional infrastructure  typology  for the future. They  not only serve  as a  drainage  facility,  but  also  as  a \nresponsive landscape that interacts with the water. They not only sustain an industrial food \nproduction factory, but also provide diverse spaces for community interaction. Establishing \nthis infrastructure typology requires a systematic approach that explores and evaluates the \nenvironmental interactions related to rainfall and sunlight. This complexity is viewed as a \npositive challenge, to create a new design language connecting the green, the blue, and the \ngrey elements of a city to produce new and vibrant patches of local identity. \n\nClimate-responsive Design Methodology  \n\nComputational Design & Performance-based Design \n\nThe proposed design method aims to generate and optimize a climate-responsive typology \nbuilt on the domains of computational design and performance-based design (CHAOWEN & \nFRICKER 2021). Computational design thinking understands architecture as a dynamic system \ncomposed  of  interactions  between  elements,  rather  than  as  a  static  entity  (MENGES  & \nAHLQUIST 2011). Working with systems rather than forms is the connecting thread between \nspace-making  and  environmental  challenges  of  design.  Performance-based  design  underscores the value of environmental performance that reflects how architecture continually interacts with the surrounding environment. Performance-based design method combined with \ncomputational design has potentials in generating a climate-responsive typology. First, as a \nsystematic approach, computational design enables designers to focus on the connections and \nmaterial flows between the three identified elements and exploit their synergies; second, this \nmethod takes environmental performance as a design driver that facilitates the generation and \noptimization of design solutions. The infrastructure can no longer be seen as static built environments, but as “’dynamic’ self-constructing, living, breathing, and even artificially intelligent (thinking) environments” (CANTRELL & MEKIES 2018, 28).  \n\nPerformance Evaluation Model \n\nThis study develops a new performance evaluation model for the generation and optimization \nof climate-responsive infrastructure by establishing the relationship between the parameters \nand performance related to the synergy system. Within the synergy system, three subsystems \nare defined and connected with the material and energy flow of water and sunlight: the water \nsystem, the food production system, and the microclimate system.  \n\nBased on the connection, the performance criteria and parameters are defined that inform \nhow to build the three subsystems (Figure 2). Firstly, the focus is set on the catchment area \nof the canal and the calculation of runoff variability and water storage capacity, informing \nthe amount of food that can be grown. Secondly, the food production system establishes a \ncomputational model and defines a set of performance evaluation criteria for the food production condition and capacity, including direct sun hours, yield, food type, and water consumption. This paper takes a planting tower from a previous study as the prototype and extracts its relevant parameters (SONG et al. 2022). Lastly, the microclimate system measures \nthe thermal comfort of public spaces, which refers to the radiation performance of the space \nshaded by planting geometries. The Grasshopper plug-ins, Ladybug and Honeybee, are used \nas tools for the simulation and visualization of direct sun hours and radiation. Therefore, the \nkey performance of the model is derived from three subsystems: direct sun hours, yield, water \nconsumption, and radiation of the shaded area. \n\nForm Optimization Experiment \nThe  performance  simulation  starts  with  the  adjusted  prototype  planting  tower  introduced \nabove to explore the impact of different geometric parameters on the performance of food \nproduction and microclimate (Figure 3). Four metrics of performance need to be evaluated: \nyield, direct sun hours, water consumption, and solar radiation of the shaded area. The simulation experiments explore the impact of the variation of three parameters of the planting geometry on these performances: slope, orientation, and curvature. The footprint of the planting tower was kept constant (12.5m2) in all experiments. \n\nThe results can be summarized below: \n\n1. When the slope is in the domain ranges from 60 to 75 degrees, the performance of direct \nsun  hours  and  yield  is  balanced  well.  The  area  with  radiation  lower  than  200W\/m²  is  the \nlargest when the shape of the footprint is similar to a square. \n\n2. The performance of direct sun hours and radiation performs best when the planting surface \nis facing east and west. It can be taken as the main direction of the design. \n\n3. The variation of vertical curvature creates planting areas with different direct sun hours, \nwhich is ideal for producing various types of vegetables. The yield and shaded area are pos-\nitively correlated with horizontal curvature(D), and performance can reach the optimal point \nwhen it is above 0.4m.  \n\nThese main findings inform the designer how to adjust and optimize the form to balance the \noverall performance and achieve the desired state. It ignites the thought that environmental \nperformance should also be considered as an essential design trigger, especially in climate-responsive infrastructure design. In addition to the described performance of food production and thermal comfort, the design needs to consider other aspects, such as function, structure, \nand spatial aesthetics. Nevertheless, the introduced computational workflow offers designers \nan iterative tool to measure the environmental performance of different design solutions and \nunderstand the relationship between parameters and performance (FRICKER 2022). This tool \nfacilitates design trade-offs between environmental performance and other aspects of design \nto enhance the overall quality of infrastructures.  \n\nDesign Speculation for New Urban Typology  \n\nWater Volume Calculation \n\nThe prerequisite for designing a food production factory is establishing a dynamic water system with associated flow processes, specifying the amount of water flowing into the canal \nand used for food production. The first step is identifying the catchment area and the population it serves; the second is calculating the dynamic water supply and consumption for the specific site to deduce the maximum volume of water storage. \n\nFirstly, the upper stream catchment of the Jurong canal can be roughly depicted based on \nland contours and simulation of water distribution using Kangaroo plug-in in Grasshopper. \nThe area is around 9,560,000m² (Figure 4). Among the eight districts in this catchment area, \nHong Kah  and Yuhua West are  the  two  adjacent  to  the  Jurong  Canal with  76,560 people \nliving there. The goal for food production is to reach 30% of the annual food consumption of \nthese populations, which implies an ideal yield of about 370 tons of leafy vegetables. Secondly, this system pumps water during heavy rainstorms to reduce peak flow in the canal and store them to use during the dry season. Taking the rainfall data in 2021 as a reference, the \nmaximum water volume of storage is roughly 4,000 m3, informing the generation of water \nstorage space.  \n\nWater flow and plant growth give this system a dynamic character, where the water storage \nlevel and the amount of food production adjust according to the rainfall patterns. This feedback  mechanism  enables  the  system  to  cope  with  extreme  rainfall  weather  by  effectively \nrelieving the pressure of heavy rainfall on the urban drainage system. This performance echoes the original purpose of developing climate-responsive water infrastructure. \n\nDesign Generation \n\nThe design generation begins with the selection of the optimized type of planting geometry \nby comparing the performance of different forms (Figure 5). The generated geometry of two \nparallel curves has the best overall performance, in line with the results of the simulation \nexperiments. The yield is higher due to the large horizontal curvature (D), which maximizes \nplanting area and allows sufficient sunlight to reach both sides. Moreover, the twisted surfaces  provide  enough  shaded  spaces  with  good  thermal  comfort.  The  key  to  this  iterative \nprocess lies in balancing the performance of yield, water consumption, and solar radiation, \nthus producing sufficient food and creating comfortable public spaces. \n\nThe  design  generation  includes  the  generation  of  planting  geometry,  building  details,  and \nlandscape. First, planting geometry is generated based on the selected type and optimized \naccording to the performance on yield, direct sun hours, and radiation, which is evaluated by \nthe computational model built in Grasshopper. The finalized geometry produces the targeted \nyield and provides several public spaces with solar radiation below 200 w\/m². Second is the \ngeneration of the water distribution system and functional spaces. The water storage space is \nset with a certain amount of flexibility added to the maximum demand to cope with the seasonal variation of future rainfall. The final step is to create a responsive landscape by reshaping the terrain according to water and pedestrian flow.\nGround-level planting areas for flood retention reduce the drainage pressure for the canal during peak periods. Overall, the generated example, the food factory on the lively riverfront offers communal space for people to \nmeet and allow new activities to emerge in the neighbourhood. \n\nConclusion and Discussion \n\nThe  design  of  climate-responsive  infrastructure  typology  driven  by  environmental  performance  is  of  vital  concern  for  creating  resilient  urban  habitats  in  the  future,  especially  for \nintensely developed cities like Singapore. The study fills in the existing gap in the computational design method for generating and optimizing an urban agricultural typology integrated with stormwater infrastructure that responds to climate change. The study explores the impacts of various geometric parameters on the performance for food production and thermal comfort, which serve as the guidelines for finding optimal design solutions for the typology. This design workflow demonstrates the iterative processes of design optimization according \nto the balance of the performance on yield, water consumption and solar radiation, which can \nbe applied to the renewal of other concrete canals. \n\nThis study presents a speculative design proposal combining multiple parameters \ninto a single design model instead of considering the economics of implementation \nand feasibility of the design. The discussion focuses on two aspects: Firstly, how much \neach performance factor contributes to the overall change in the design was not explicitly \nstated in the study, which might depend on the objectives of the design. Future research can \nhence set several design scenarios and discuss the contribution of multiple factors respectively. Secondly, social aspects, such as how to involve people in the food production process, deserve more careful consideration in order to ensure the long-term success of the endeavor. \nIn addition, project planning requires the collaboration of multiple stakeholders, which has \nbeen a constraint to large-scale government implementation of food production in the past. \n\nVisualizing and Clustering Eye Tracking within 3D \nVirtual Environments \n\nAbstract: Visual perception is one of the most important sensory processes for most of the population. \nThis process plays a key role in how we navigate and way find in urban environments. A wide range of \nliterature offers insight into the relationship between the structure of urban spaces and navigability, as \nwell as literature identifying how individual differences play a role in how well people can recall elements and navigate environments. Measurement techniques that reveal these differences are often captured as procedurally based evaluations after individuals have navigated through an environment. However, these valuations do not necessarily help us understand the process of how observations link to \nrecall and navigation. In this paper, we show a new technique for conducting eye tracking in 3D virtual \nenvironments to assess the process of observation in urban environments. Further, we demonstrate how \nclustering techniques can be used to improve eye tracking data generated in these 3D environments. \nThe techniques we provide can offer a new means to better understand how form, function, and design \nelements are observed. \n\nIntroduction \n\nIn navigation, the visual perception of an environment plays a significant role in decision-making, as well as informs knowledge about the properties of spaces and the relationships of \nobjects that form the collective environment. One of the ways researchers have attempted to \nunderstand the decisions we make during navigation is to create highly controlled experiments using virtual environments (BRUNS & CHAMBERLAIN 2019). However, many of the \nprevious experiments lack a comparable diversity of objects, routes, scales, and relationships \nbetween these elements in comparison to the real world. The benefit of virtual environments, \nparticularly with modern gaming engines, is that the designer can control all elements within \nthe environment. This offers a means to simplify a problem and employ a more deductive \nscientific process, but it may come at the cost of understanding how perception works holistically within complex spaces. Unfortunately, quantifying perception holistically would require new methods for analyzing the process of perception. Further, a method like this would need to be implemented in complex environments, which can be self-defeating if it requires an oversimplification of the environment itself to operate. Thus, finding a technique that enables both the employment of complex virtual environments and a seamless integration of \nanalyzing  perception  holistically  would  be  a  major  step  in  understanding  the  relationship \nbetween human and environmental interactions. \n\nDesigning spaces for intuitive navigation is an important process for urban designers, campus \n(e. g. business parks) planners, and outdoor recreation trail designers. There are many design \nproblems to undertake in these instances, with navigation and wayfinding within the set of \nissues. Both these processes require individuals to recognize spatial patterns, comprehend \nrelationships of elements, make determinations of how to focus their attention, and remember \nimportant objects or spaces. There have been many approaches to assessing these processes, \nsuch  as  measuring  response  times  and  accuracy  in  remembering  landmarks  or  locations \n(CHRASTIL & WARREN 2015, ERICSON & WARREN 2020, GAGNON et al. 2018, WEISBERG et \nal. 2014) and assessing map drawings of paths and spatial layout (BRUNS & CHAMBERLAIN \n2019, GARDONY et al. 2016, WANG & SCHWERING 2015). However, these measures are usually done post hoc rather than in real time. Further, the measures are usually procedurally \nbased (e. g., memory recall), rather than processes based (formation of memories). To improve our understanding of how process-based navigational activities unfold, we need to understand what drives perception and decision-making. A better understanding could help designers support meaningful relationships between objects to facilitate these perceptual processes. Fortunately, computational techniques can be created and then combined with cognitive science and urban and landscape design principles to better understand how individuals \nobserve and make inferences about those spaces. \n\nEye tracking is one technique that has been used by researchers to better understand the process of observation. It has been used for decades to understand how and why an individual \nfocuses on particular objects, areas, and elements of space. Implementations of eye tracking \nhave been primarily conducted in 2D environments (e. g. looking at a screen or flat image). \nThis includes architectural-related studies (XIANGMIN et al. 2021, ZHANG et al. 2019), with \nlandscape studies emphasizing 2D static images (DUPONT et al. 2016). In landscape and architectural studies, eye tracking is used to identify fixations within scenes, and in psychology \ncan help describe visual attention and arousal (KIM & LEE 2021). With many metrics that \ncan be analyzed from these data, broadly, one major advantage is to provide an objective \nmeasure of perception (DUPONT et al. 2014). Yet, relative to 2D eye tracking studies, there \nis little literature showcasing implementation in 3D dynamic environments. \n\nIn this study, we combine the generation of virtual environments and eye tracking to visualize \nindividual observational patterns in a virtual space. We extend previous work (FERNBERG et \nal. 2022) to showcase a new open-source software package we developed, as well as an analytical framework for representing these data. This paper deviates from the previous by showing specific visualizations and analyses of large datasets that have been analyzed, whereas the previous version was introducing the construct. The purpose of this study is to showcase how eye tracking data can be represented in a dynamic 3D environment and how those data can be analyzed using mathematical clustering mechanisms. We ask, to what extent can eye \ntracking be implemented in 3D gaming environments and analyzed post-hoc to determine \nfixations of objects within virtual urban spaces? \n\nData Collection from the Virtual Environment \n\nFor this work, we employ the Unity gaming engine and prefabricated 3D assets (from Kitbash) to create a procedurally generated urban environment which can be explored in VR. \nThe design of the environment was not intended to be complex or realistic world because this \nis not necessary for the primary purpose of implementing eye tracking and testing different \nclustering techniques. The environment consisted of 40 x 100-meter-long blocks, where each \nblock was one of five different architectural styles. The purpose of this setup was to observe \nif the pattern of clustering was different closer to transitions between different architectural \nstyles compared to areas where changes did not exist. However, in this study, we were merely \nattempting to identify how we might cluster data, the actual test of these transition zones is \nmeant for a later study. For now, all elements are static, the user can make observations freely, \nbut cannot change their location or speed of experience. Further, we have not included any \nother cues, such as sound, lights, or atmospheric changes. Each object was placed along a \ntwo-lane road in succession, with variable spacing between each building.  \n\n\nThe eye tracking software we developed, was created for implementation in the Unity gaming \nengine  only.  For  this  implementation,  the  Vive  Eye  Pro  virtual  reality  headset  was  used. \nWithin Unity, the headset was established as the user camera and the scripts were then associated with this camera. Movement through the environment was maintained at a consistent \nspeed, but the viewer can fully move their head around. The eye tracking software stores the \nlocation and rotation of the user’s eyes at every frame that gets rendered (about 60\/sec). The \ndata from each eye is averaged to create one point and one direction. This direction is, of \ncourse, where the user is looking. Using this information, we create an invisible virtual ray \nthat extends from the eye outwards (see Figure 2). Once this ray hits an object, the collision \npoint (location of the intersection of the eye tracking ray and the surface of the object) is \nrecorded along with the object’s name and position (recorded for accurate reproduction of \nthe data before participation). Other metrics are recorded and computed such as eye angle \n(looking left\/right\/etc.), distance from eye to collision, and whether they are blinking or not. \nThe figure below is a representation of rays produced along the route as a user looks at objects \non the buildings’ surfaces. \n\nThe data produced from a single experiment can result in a substantial number of data points \ncollected. With such a vast amount of data being produced, it is important to identify the most \nrelevant data that could provide researchers with meaningful interpretations of observational \npatterns. So, we needed to identify ways to reduce the amount of data by reducing noise and \njitter. Then, we needed to cluster the remaining data into meaningful groups, referred to as \nfixations. From this data, we can determine the total dwell time and total fixation count for \nspecific areas of interest. The areas of interest are regions in the environment that are important (HOLMQVIST et al. 2011) and could be identified as specific objects of general areas \nalong an object. \n\nTo  produce  clusters  from  denoised  data,  we  tested  a  clustering  method  called  DBSCAN. \nDBSCAN stands for Density-Based Spatial Clustering of Applications with Noise. This technique uses an unsupervised machine-learning algorithm to identify clusters of observations. \nAs the name implies, it uses the spatial density of the data points (in any number of dimensions) to create clusters and eliminate noise. One important function of this algorithm is that \nyou can use more than the 3-dimensional distance to find spatial density. It can include factors \nsuch as eye rotation and time in its calculations. This can be useful because in a dynamic \nenvironment participants can first look at an object in the distance, then as they move forward \nthrough an environment, look back at the object again. This dynamic  facet of 3D gamine \nenvironments makes it critically important to ascertain what is a fixation across distances, \nversus random noise that could have been part of a rapid eye movement across an area and \nalong an object. \n\nImplementation and Outcomes \n\nIn this section we highlight the results from the clustering technique to show: 1) the volume \nof data produced by a single participant, 2) the observational patterns of the participant, and \n3) the effects of implementing the clustering algorithm on the previous two. In this section, \nwe provide context to the implementation (for each of these three), takeaways from our experience, and general statistics to highlight an overview of the outcomes. \n\nIn our experiment, a single individual produced 39404 observations over the entire 9 minutes \nand 35 seconds of the experience. This averaged about sixty-eight observations per second. \n\nThe rate of eye tracking data collection depends upon Unity’s internal update function, which \nis the same as the framerate. Framerate is affected by how many objects are in view and need \nto be processed by the GPU. Therefore, the framerate can vary throughout the experiment. \nWhile it can be helpful to maintain a high-frequency rate to minimize motion sickness and \nimprove realism, it is unknown the extent to which the rate of data collection would impact \nthe results, for whatever results are being sought. \n\nUsing these data, we developed a simple metric to highlight how often an individual may \nlook at objects versus other elements in the environment. In our implementation, the objects \nwere buildings, and the other elements included the ground (terrain), the street, and the sky. \nIn our implementation, the ground and street are objects because they have a surface with a \ncollider that enables the collection of eye tracking data points when the vector of the observation intersects with that surface. Unlike buildings, these two surfaces are continuous through-out  the  entire  environment,  whereas  buildings  are  separate  objects.  Our  eye  tracking  also indirectly collected observations of the sky (or distant void), in which there is a frame with no distinct object with a collision surface. Figure 3 shows global statistics of the proportion of observations made between the sky, terrain, road, and buildings. The figure also compares those data after removing saccades. Saccades and their removal are explained below. \n\nEye tracking data can be difficult to interpret. This is particularly true in 3D, where there are \nvery few studies that have attempted to validate how observational patterns in 3D are associated  with  meaningful outcomes  of  navigation (UGWITZ  et  al.  2022).  One  crucial  step  in \ngenerating interpretations of data is to remove irrelevant data (e. g., noise), such as saccades. \nA saccade is essentially a rapid view of an object, then a focus away from that object with \nanother quick return to the original object. In terms of perception, little to no information is \ngleaned during a saccade. Therefore, in addition to general noise (single random observation \nin space), eliminating saccades can also help streamline the data analysis. \n\nHowever, identifying these saccadic movements requires playing with the clustering parameters. This is because eye tracking data is generated based on a collision point for each frame, \nbut how the algorithm determines if a single data point belongs to a cluster or not is a little \ntricky. To reduce noise and eliminate saccades, we implemented DBSCAN. DBSCAN takes \nthe {X, Y, Z} vector position where it collided with the object, but also the time dimension \nof when it collided. Clusters are determined by locational and temporal similarities of vectors \nby turning two parameters. First, epsilon is the distance threshold from one observation to \nanother (in 4D). Second, minimum points is the number of minimum points that constitute a \ncluster. Our parameters were an epsilon of two meters and a minimum points of seven, which \nrepresents roughly a tenth of a second or the approximate minimum amount of time for a \nfixation. Again, Figure 3 highlights the global statistics before and after the removal of saccades, or points that did not belong to a cluster.  \n\nFigure 4 further depicts an example of different clusters using different colored dots. In this \nfigure, similar colored dots represent a single observational point. Find the set of green dots \nright below the purple dots. The large cluster of green dots shares a similar proximity with a \nsingle black dot right on the roof ridge. This black dot seems to be part of that green dot \ncluster. However, DBSCAN identified that the observation point represented as the black dot \nshould not belong to a cluster. This was because the observational point was created several \nseconds prior as part of an earlier saccade (singular rapid observation), whereas the other \nobservations were made in sequence (suggesting a focal point or area). \n\nDiscussion and Conclusion \n\n3D gaming platforms offer the ability to produce vast amounts of user-centric data. Having \ntools to analyze these data can help designers identify environmental cues or triggers that \ncould influence the perception of a design or plan. Eye-tracking offers a non-intrusive, process-based technique for collecting very precise observations within a space. However, finding a robust algorithm to cluster thousands of eye data points is essential to making meaningful interpretations of these perceptions. Using the software we produced, these patterns can be visualized and reduced for making assessments about areas or objects favored by users. DBSCAN is one of several techniques available but has been shown to produce good \nresults (ESTER et al. 1996). This paper was not intended to conduct a systematic comparison \nacross these techniques and variations, but instead to demonstrate the potential for eye tracking data in combination with a clustering technique to produce useful data. \n\nThe next major step in this research is to understand how these data can be related to meaningful observations to help form decision-making and recall. Understanding this link can help \ndesigners better associate the placement and patterns of objects, such as landmarks (BRUNS \n& CHAMBERLAIN 2019), within the environment to improve wayfinding and navigation. As \nThus,  some  next  research  questions  are:  to  what  extent  do  eye  tracking  observations  in  a \ndynamic 3D virtual environment correlate with memory recall, navigational decisions, and \npattern recognition about the overall design of the environment? More broadly, to what extent \ncan eye tracking help us understand how individuals form mental maps? In our experience, \nwe  noticed  several  situations  where  individuals  were  following  unique  building  features, \npeering through passageways, and scanning the topography of buildings. While these observations are anecdotal and with limited data, they do suggest these data could help validate \nthe importance of or focus on different architectural forms, textures, and aesthetics. \n\nImplementing eye tracking in 3D-controlled virtual environments shows promise for aiding \nthe examination of observational processes. This will have relevance in multiple fields. Certainly,  eye-tracking  has  been  used  in  3D  gaming,  but  studies  in  psychology,  architecture, \nurban design, interior design, and landscape architecture could benefit from having access to \nindividual patterns of observation data. Eye tracking is a well-established technique but employing it within 3D environments and determining how to associate these data with meaningful interpretations will provide new opportunities and insights for landscape studies.  \n

Parametric Planting Design: Algorithmic Methods \nfor Resilient Communities \n\nAbstract: Parametric applications in landscape architecture are gaining traction as designers realize the full potential of script-based analysis in various stages of design. Planting design is one realm of parametric landscape architecture that is traditionally done manually with books, websites, or other research on hand, thereby keeping its application within the grasp of landscape designers. This discussion proposes a method of using algorithmic design to analyze and specify plant species based on four different measures. Further, it is possible to expand this method in the form of a browser-based program for non-designers to take part in resilient landscape planting. \n\nIntroduction \n\nThe origin of computation-driven landscape analysis and design is often attributed to Carl \nSteinitz’s 1966 land evaluation and the SYMAP print of the Delmarva Peninsula (STEINITZ \n2014). Subsequent decades brought advancements in processing power and user interface, \nallowing a variety of software to gain traction in the design field including Photoshop, AutoCAD, and specifically for landscape architects, LANDCADD (ERVIN 2020, MACDOUGALL\n1984). ERVIN (2020) also describes the rise of optimization software and use of algorithmically-generated landscapes in response to the formation of the internet (ERVIN & HASBROUCK\n2001). As such, the success of spatial design computer applications has led to at least a partial \nreliance on digital workflows in the design process, if not a large portion of the work. \n\nIn an effort to explore emerging landscape architectural frontiers, designers echoed Steinitz’ \nexperimentation  and  began  programming  new  tools  for  greater  flexibility  in  their  work \n(CANTRELL &  MEKIES 2018). Development of programs continued with some tools being \ncodified  as  permanent  sub-tools,  such  as  Grasshopper  within  the  3D  modelling  software \nRhino. \n\nGeneral investigations of parametric landscape design problems can exist in the form of blog \nposts  (GENERATIVE LANDSCAPES),  online  videos,  and  academic  papers  (SERDAR & KAYA\n2019). Commercial tools have also been created and added to aid in the digital landscape \ndesign process (LANDKIT). Notable built projects include Eda U. Gerstacker Grove by Stoss \nLandscape Urbanism at University of Michigan, where student desire lines, drainage, and \nparametric bench profiles were incorporated into an algorithm to generate a site model that \nresponds to and supports the pedestrian experience (REED 2018). \n\nExisting Research \n\nWhile parametricism in landscape architecture is an ever-expanding area of study, limited \nresearch has been conducted on the use of algorithmic workflows regarding ecological factors including species selection and planting location. \n\nA thesis by Roasliina Luminiitty (2021) from Aalto University examines parametric planting \ndesign’s integration in the landscape design progress. LUMINIITTY (2021) analyzes prior software used for landscape design, as well as more modern investigations into algorithmic landscape architecture. The paper offers a detailed explanation into the components of parametric \nplanting design and offers a framework for digital planting design workflows, which can be \nexpanded further with the inclusion of measurements and real-world data to inform the final \nresult. Parametric patterns can be tailored for design continuity and be ecologically developed \nby an algorithmic plant selection process to create a holistic planting concept. \n\nOLIN Lab’s Tech- and Eco Labs have also developed research into digital workflows for \nplanting design. The process utilizes AutoCAD, Rhino, Grasshopper, Python, LandFX, and \nAdobe Suite products to derive functional planting plans for use in a landscape architecture \noffice setting (AREVALO 2020). The process is broken down into four parts: (1) Investigating \nplants as living material, (2) Speculating and experimenting with parametric components, (3) \n3D Spatial and aesthetic analysis, and (4) Seasons and time. AREVALO (2020) states that this \nworkflow was successful for the office-side design process, but documentation was still prepared manually, which requires work by a landscape architect. \n\nLandKit is a Grasshopper plug-in developed by LANDAU Design+Technology that creates \ncustom  components  in Grasshopper  for  users  to  more  effectively  design  fundamentals  including with specific components called TopoKit, PavingKit, and PlantKit (LANDKIT). What \nsets PlantKit apart from other parametric planting tools is that it does not automatically assign \nspecies to the plants it generates, but rather establishes certain plant typologies to be determined later by the user. The plant typologies refer to similar sizes, environmental considerations, and biodiversity, which gives the end user more agency when specifying species and \naccounts for regional climate variations. \n\nThe creation of these products is testament to years of dedicated research into accurate and \nefficient planting algorithms, for use in a landscape architecture office. The development of \ndifferent algorithms and tools has taken off regarding landscape design and will continue to \nbring new and improved iterations into the field. However, this computation-driven analysis \nis mostly locked behind software with intense learning curves and high price points. With the \ngoal of simplifying communication between designer and computer, parametric application \ndevelopers should also strive to lower the barrier of entry for the use of these tools. \n\nDigital Equivalents to Planting Design Concepts \n\nBefore attempting to develop any parametric tools, it is critical to understand the concepts \nbehind existing ecologically sound landscapes. Traditional landscape design practice includes \nresearching native or naturalized plants in a specific region, while placing them in a pattern \ncorresponding  to  a  design  intent.  This  varies  from  project  to  project,  but  is  generally  the \nformat of the planting design strategy. Many different categories of planting information exist \nfor each plant, and can be addressed through different ways to fit the project’s goals. \n\nQualitative information exists as a subjective rationale in landscape design. This may include \naesthetic considerations, natural plant communities (dependent on location and ecosystems), \nand features included on a site and how the site functions as a whole. In the digital realm \nthese  cannot  be  quantified,  though  studies  have  investigated  various  methods  to  evaluate \nlandscape perception (KARMANOV 2009). Use of qualitative data or input is still important, \nhowever, as it establishes “the meaning individuals or groups ascribe to a social or human \nproblem (CRESWELL 2014). Use of this type of information can be presented in the setup of \na project, or change with user preferences. \n\nQuantitative information is a numerical type of data representation where all possible results \nare accounted for, and often presented numerically. In landscape architecture, common uses \nof quantitative data are found in climate data, topography, and geotechnical properties. Data \ncan also be extracted from the site itself through analysis tools and simulations, unearthing \nunderlying layers of data otherwise hidden. \n\nPlanting for a Post-Wild World (RAINER AND WEST 2015) describes the structure of a designed landscape through a series of layers: a structural layer, groundcover layer, seasonal \nfiller layer, and dynamic filler. The clear distinction between individual plants work together \nto  form  the  identity  of  a  garden  which  can  establish  character  even before  more  complex \ndesign motifs take place. Additionally, thinking of plants in a binary manner lends itself to \ndigital applications where a machine must be programmed to receive input and output information in a highly controlled manner. \n\nRAINER AND WEST (2015)  also  signify  the  importance  of  employing  ecological  strategies \nwithin plantings to promote resilience in plant communities. “Resiliency” is a commonly used \nterm referring to the ecological health of a landscape and its ability to recover after periods \nof distress (RAINER & WEST 2015), but it also can be interpreted as a human community’s \nability to recover from a disturbance (FLINT 2010). Given the difficulty of evaluating a multifaceted  concept  such  as  resilience,  we  can  instead  look  at  establishing  environmentally \nsound  starting  points  (namely  regionally  accurate  plant  spreadsheets)  in  order  to  generate \nresilient planting communities. \n\nSoftware for this algorithm process utilizes the Grasshopper tool in Rhinoceros 3D. Because \nthis software allows for algorithmic design approaches, a single input can trigger a variety of \nsubsequent processes and analyses, culminating in an algorithm-derived final product. \n\nPreparation for this tool included development of a plant list extracted from eastern Nebraska \nnursery stock listings to ensure success in the Nebraska landscape. In total, 198 unique species \nand 80 cultivars or varieties were identified and constructed in a spreadsheet with important \ninformation such as mature height and width, shade tolerance, salt tolerance, drought tolerance, bloom timings and color, nativity to Nebraska, and hardiness zone range. All plants \nwere parsed based on their landscape function: overstory conifer, overstory deciduous, understory conifer, understory deciduous, perennial, tall grass, groundcover, and annual. \n\nAlgorithm \n\nGrid \n\nA  site’s  surface  can  be  divided  into  a  grid  of  any  size,  though  standard  1-,  2,  and  5-foot \nsquares work best. The grid allows for easy analysis of site features such as elevation, edge \nproximities, and sun exposure. The ideal scale for this depends on the overall scale of the \nsite, with smaller sites requiring a higher level of detail. The ideal resolution for a 7,000 sq. \nft.  (650  m2)  site  can  be  2  feet,  while  larger  sites  may  need  5-foot  resolution  to  minimize \ncomputing time. \n\nPlant and Environment Scoring \n\nA surface in Rhino is referenced in Grasshopper where four analyses take place: Elevation, \nShade, Salt intensity, and Structure proximity (Fig. 1). The interplay between envi-\nronmental factors plays a large role in identifying a “best fit” species for a particular location \non a site (CZAJA et al. 2020). Elevation analysis takes note of local high and low points on \nthe  site,  and  corresponds  with  low  points  requiring  less  drought  tolerant  plants  and  high \npoints requiring more drought tolerant plants. Shade analysis looks at sun exposure on the \nsite from existing buildings and trees to accurately place plants with regards to sunlight hours. \nSalt tolerance measures look at a point’s distance from paving surfaces or curves to account \nfor  road  salt  accumulation  in  winter  months  near  the  planting  surface  peripheries.  Lastly, \nstructure proximity  refers  to the distance between  a plant  and  a  structure, preferring  slow \ngrowth nearer to the structure to reduce risk of root damage to the foundation. \n\nThe  “environmental  scores”  (elevation,  sun  exposure,  and  salt  intensity) of each  potential \nplanting spot on the site are compared to each “plant score” of a particular plant typology \n(Fig. 2). The difference between the “environmental score” and “plant score” determines the \nresiliency of the proposed plant, with a lesser difference resulting in higher probability of \nresilience. It is possible for the algorithm to compare all 278 plants for every potential location, though it would leave too many options available for the user and result in an unclear \ndirection. Parsing plants into specific landscape structures provides opportunity for a better \nstructured landscape (RAINER & WEST 2015). \n\nFlexibility \n\nThe  uniform  analysis  and  subsequent  visualization  of  a  landscape  allows  for  a  variety  of \nplanting  regimes  to  occur.  Planting  locations  can  be  derived  from  the  algorithm  itself,  or \ndecided by a user making informed decisions from the data. \n\nAlgorithm-derived  planting  plans  can  be  applied  in  a  few  ways,  provided  a  distinction  is \nmade for the specific plant typology being used in each spot (overstory, understory, tall grass, \netc.).  Grids,  attractor  curves,  and  random  points  are  options  when  considering  automatic \nplanting proposals (Fig. 3). Further exploration in parametric design tools such as Grasshop-\nper may offer informed layouts with emphasis on user comfort and more complex designs. \n\nThe user  may  defer  to  stylistic  choices based on  a  desired  theme  (naturalistic  landscapes, \nEnglish gardens, etc.). For manual placement of plants, collections of points can be projected \nonto the site surface and analysis be drawn for those, where inputted plant patterns and sizes \nare matched to the “best fit” plant for that location. The variability of planting styles allows \nfor highly unique landscapes designed by the end user. To aid in this process, planting pattern \ndiagrams were developed to demonstrate the core principles of various landscape styles. A \nfew selected styles being presented to the user show successful patterns easily replicable from \nan amateur designer’s perspective and increase the appearance of legible design intent. \n\nAlgorithm to Browser-based Tool \n\nThis algorithm can be interpreted as a backend process for a planting design tool intended \nfor people inexperienced with landscape design. Given that the tool is able to suggest planting \nstrategies from topographic information, it is possible to derive this information from other \nsources using real-world data and leave the user with freedom to focus on designing their \nspace. Further, incorporating heterogeneous (containing structure and hierarchy, biodiverse) \nlandscape  design  in  homeowner-designed  landscapes  improves  landscape  perception \n(KHACHATRYAN et al. 2020). These positive attributes prompted the idea of a browser-based \ntool that can aid in the creation of a homeowner’s landscape design. \n\nTranslating a Grasshopper script to a programming language is a fairly straightforward task, \ngiven  that  Grasshopper  is  in  essence  a  visual  coding  language.  Python  and  Javascript  are \npopular programming languages capable of creating interactive maps, ones which users could \nuse to select site boundaries in their respective regions. An application programming interface (API) allows for communication between two or more computer applications, such as \nan individual computer requesting data from a large online database. Integration of Open-StreetMap (OSM) and United States Geological Survey (USGS) API allows for up-to-date \ninterpretation of landscapes with OSM providing location data, and USGS providing elevation data. \n\nOpenStreetMap is a free, open-source online mapping service that uses volunteer-provided \ninformation to gather location data, along with deriving maps from Bing aerial imagery and \nother mapping techniques (OPENSTREETMAP). Overpass API is a resource for an application \nto request read-only data in a variety of formats for any particular use due to the open-source \nnature of the service. To obtain specific site data, a bounding box is drawn over a map and \ncoordinate boundaries are established. The software requests any road and building geometry \nintersecting or within the boundaries from Overpass, which can be interpreted and shown in \nthe map view. \n\nThe National Map (TNM) is a project by the USGS’s National Geospatial Program to con-\nsolidate  downloadable  products  into  one  location  for  all  public  and  private  use  (UNITED \nSTATES GEOLOGICAL SURVEY). The TNMAccess API allows developers access to multiple \ndatasets, and will use the highest resolution dataset for the desired location request. To obtain \naccurate elevation data, the Elevation Point Query Service returns the elevation in requested \nunits at a specified latitude and longitude. Coordinates from the initial OSM bounding box \ncan be used to create a rectangular array of coordinate points and sent as a request to TNMAccess, where surface analysis can begin. Once a site is selected, the user can demarcate structures, roads, and potential barriers to plants that are present but not recorded to cull any areas \nincapable of supporting plant life. \n\nThe development of a user interface or user experience (UI\/UX) can lower the barrier of entry \nto individual landscape design. User interface is considered the format in which users see and \noperate the software, which should contain simple and concise language to explain the concepts at play in landscape design such as elements of analysis, plant environment descriptions, and list of results provided by the algorithm. This is considered front end development: \nthe side that the user is allowed to see. All the user’s inputs are relayed to the back end of a \nsoftware to be analyzed before a response is sent back to the front with a clear visual result \n(Fig.4). \n\nUser experience is the act of using the software and experiencing it through various steps to \nproduce a valid result. The flow of this process includes clear language to describe what each \ncomponent is and how it changes the result. This includes the language and response of any \nanalysis performed by the application. The goal of this experience is to provide the user with \na simplified approach to landscape design, performing site-specific landscape analysis in the \nback end to produce a tailored result for further consideration. \n\nDiscussion \n\nThe creation of a digital planting tool geared towards the general public provides an accessible platform that can elevate the ecological diversity and architectural quality of typically \nunderutilized landscapes. The use of this proposed process does not necessarily end with the \nindividual user in a single-family home setting, but can be applied in a broader application \nfor use in community organizations and people interested in improving the landscape of their \ncommunity spaces. \n\nWhile the project does accurately complete the task of planting design, it performs mainly as \nbackend development with complex inputs. Further exploration into user interface and user \nexperience front end could improve the clarity of language and process of the tool, and ultimately may be able to compile a custom document regarding maintenance and further resources for the end user for future planning. Further back-end analysis of landscape can increase the accuracy of the results regarding unique species preferences, or the variable shade from vertical layers of vegetation. \n\nCertain limitations apply to the accuracy and scope of an accessible planting tool, with datasets  needing  to  be  researched  and  formatted  to  a  uniform  spreadsheet.  One  approach  to \nexpanding this process into a United States-wide resource would be the use of the Federal \nHighway Administration’s Ecoregional Revegetation Application (ERA). This resource is a \ncompiled list of plant species and related information found in ecoregions across the entire \nUnited States, including Alaska and Hawaii (STEINFELD et al. 2007). \n\nThrough  this  framework,  it  is  possible  to  begin  the  development  of  a  tool  that  brings  informed, site-specific planting information to the general public. \n

Robots in the Garden: Artificial Intelligence and \nAdaptive Landscapes  \n\nAbstract: This paper introduces ELUA, the Ecological Laboratory for Urban Agriculture, a \ncollaboration among landscape architects, architects and computer scientists who specialize \nin  artificial  intelligence,  robotics  and  computer  vision.  ELUA  has  two  gantry  robots,  one \nindoors and the other outside on the rooftop of a 6-story campus building. Each robot can \nseed, water, weed, and prune in its garden. To support responsive landscape research, ELUA \nalso includes sensor arrays, an AI-powered camera, and an extensive network infrastructure. \nThis  project  demonstrates  a  way  to  integrate  artificial  intelligence  into  an  evolving  urban \necosystem, and encourages landscape architects to develop an adaptive design framework \nwhere design becomes a long-term engagement with the environment.  \n\nIntroduction \n\nIn the discipline of landscape architecture, a major epistemological framework has assumed \nthat the environment is a closed and static system that can be measured, predicted, and conceivably controlled by technology (LYSTRA 2014). The reality of severe climate change challenges this view. Although advancements in industrial technology have given humans some control over their environment, carbon continues to be released into the atmosphere at unprecedented rates. While science rigorously measures and predicts the increasingly grim im-\npact of human decisions, quantities of computer-processed data and complex control policies \nhave yet to provide straightforward solutions to climate change. This paper argues for a research paradigm where artificial intelligence (AI) helps adapt landscapes to a changing environment rather than control them. It considers the role AI can play within this new focus on adaptivity, and how they can contribute to an adaptive design framework that requires a long-term engagement with the environment. \n\nELUA, the Ecological Laboratory for Urban Agriculture, offers a case study for an evolving \necosystem, embedded with AI, that responds to the uncertainties of a changing climate. In a \ncollaborative endeavor among computer scientists, landscape architects and architects, two \ncommercial gantry robots and an extensive infrastructure support cultivation in two polyculture  gardens (Figure  1).  Our  work  includes  construction  and  customization  of  the  robots, \nincorporation of sensor arrays, an AI camera, and network infrastructure, as well as the design \nand construction of the garden beds.  \n\nIn the past two decades, many landscape programs have built laboratories with machinery \nand a “lab culture” as both research and education infrastructure. Examples include Alexander Robinson’s work at the Landscape Morphologies Lab of the University of Southern California(ROBINSON  &  DAVIS  2018);  Bradley Cantrell  and Xun  Liu’s work  with hydromorphology tables at the University of Virginia and Harvard University (LIU 2020); Matthew Seibert’s work at Milton Land Lab;1 and Ilmar Hurkxken and Christophe Girot’s Robotic \nLandscape work at ETH Zurich (HURKXKENS 2020). Each of these develops landscape laboratories that integrate physical spaces with customized tools and machinery. \n\nThis phenomenon mirrors the 21st-century development in landscape theory that prioritizes \ndynamic landscape processes and ecological evolution over static forms. Landscapes are imagined to evolve with recursive and process-based strategies over time, instead of as a one-time construction. Projects such as the Fresh Kills and Downsview Park competitions in the early 2000s weres examples of this design paradigm (CZERNIAK 2001, REED & LISTER 2014). Since then, many scholars have incorporated a broad range of ideas and concepts from both sciences and humanities to diversify and develop that paradigm. They include multispecies \nco-production,  novel  ecology,  feral  ecology,  and  cyborg  landscapes  (HOUSTON,  HILLIER, \nMACCALLUM, STEELE & BYRNE 2018, KLOSTERWILL 2019, PROMINSKI 2014). In addition, new tools have been imagined for integration into landscape systems that would execute process-based strategies and co-evolve with other landscape actors (CANTRELL & HOLTZMAN \n2015). \n\nOur research contributes to this body of work in theory and practice. We view an intelligent \nsystem, like its human counterparts, as an imperfect agent, rather than an omniscient, omnipotent black box. The perspective  of  collaborative  intelligence (EPSTEIN  2015) provides  an emergent, constructive view of artificially intelligent agents that participate in and support a collaborative  design  process.  We  envision  an  alternative  future  where  technology  plays  a more integral role in adaptation to rapidly changing environments. \n\nThis paper documents the design, construction, and preliminary testing of ELUA, and provides practical recommendations for such landscape laboratories. It also reflects on the ramifications of ELUA for landscape design and argues for a new research paradigm where AI \nis  an  integral  part  of  evolving  ecosystems.  From  our  perspective,  landscape  design  is  no \nlonger a finished product, but a long-term engagement and collaboration with an assemblage \nof actors, including AI systems, that co-creates an evolving ecosystem.  \n\nTechnologies and Design-build  \n\nELUA has two sites within the Spitzer School of Architecture at City College of New York, \nan outdoor garden on a rooftop and an indoor garden in a communal area near the landscape \nstudios. The outdoor garden (shown in Figures 1 and 2) focuses on growing food; the indoor \ngarden (shown in Figures 1 and 3) is used for education, prototype research, and experimental \ndevelopment.  \n\nInitial Hardware and Software \n\nBoth ELUA robots are from FarmBot,2 a California-based firm that designs and markets open-\nsource commercial gardening robots, and develops web applications for users to interface with \nthose robots. These are gantry robots that operate in three dimensions and employ interchange-\nable tool heads to rake soil, plant seeds, water plants, and weed. FarmBots are highly customi-\nzable; users can design and replace most parts to suit their individual needs. For ELUA, we have \ndesigned and 3D-printed our own watering nozzles, seeders, seed troughs, and camera mounts. \n\nFarmBot’s supporting code for farm design and robot control is also open source; users can \ncustomize  it  through  an  online  web  app.  This  allows  us  to  revise  or  replace  the  provided \nexecutable programs and to introduce new functionality into ELUA. The basic FarmBot code \nvisualizes garden designs before planting, photographs the garden, and provides primitive \nsensing and behaviors. \n\nCustomization for Robot-assisted Gardening  \n\nWe customized each of ELUA’s robots in several ways for our indoor and outdoor gardens, \nand both systems function as intended. ELUA’s rooftop robot has 2-meter tracks from a third-party vendor tailored to the spatial parameters of its site; they replace FarmBot’s original (x-axis) 1.5-meter robot tracks. To install the tracks on the I-beams on the rooftop, we designed \nand built our own joints. We developed planters made with standard milk crates lined with a \nlayer of geo-fabric. This modular approach provides flexibility to the entire rooftop design \nand  installation.  The  5'x5'  structural  frames  are  custom-built  with  10-foot,  16-gauge  steel \ndrywall studs and tracks, cut to size and assembled on-site with L-shaped corner clips. The \nstructural frames fit between two I-beams and support milk crate planters or wooden planting \nboxes (Figures 1, 2 and 4). As shown in Figures 1 and 3, the indoor system consists of a \nblack-pipe armature for the robot and mobile garden beds, instead of gantry tracks fixed directly onto the garden beds as suggested by FarmBot Inc.. This armature design allows us to \nremove and replace mobile garden beds if needed without deconstructing the entire gantry.  \n\nThe rooftop garden will eventually be used by a student group to produce food. In contrast, \nthe indoor garden is intended for more advanced experiments, where we will prototype and \ndevelop new algorithms, tool heads, and operations to be used for both robots.  \n\nEach FarmBot includes a camera that photographs the garden, with software to roughly stitch \nthe images together. We developed algorithms to improve image mosaicing (DICKSON et al. \n2002, MOLINA & ZHU 2014). Meanwhile, we installed a second, more powerful AI camera \nOAK-D camera3 to perform more advanced computer vision tasks, such as depth detection, \nweed detection and plant identification. We have used this AI camera and developed seamless image stitching for two-dimensional aerial views in ELUA that are more accurate and \nmore visually appealing.  \n\nInitially,  the  user  describes  the  garden’s  contents  to  a  FarmBot  as  a  simple  placement  of \nplants from the provided “plant dictionary” on a garden map, a two-dimensional grid visualized by the web app. FarmBot stores the location of each plant as a datapoint (x, y) on that \nmap. Other emerging plants, if detected by the camera, are treated uniformly as “weeds” that \nshould be managed by the robot. FarmBot’s software has no plant identification algorithm to \ndifferentiate between different weed species. Some “weeds,” however, such as dandelion and \npurslane, are edible, while others, such as red clover, can fix nitrogen and support soil health. \nWe expect that these species could play important roles in an urban polyculture garden and \nincrease urban biodiversity and resilience. Thus, we intend to process images from the AI \ncamera with deep learning models to detect such opportunistic species, record their locations \nin the garden map, and have the robot cultivate all welcome but unanticipated plants.  \n\nMultimodal Sensing and the New Database \n\nIn  addition  to  the  FarmBot  armature,  our  gardens  are  designed  to  benefit  from  additional \nsensors. We have incorporated an array of capacitive soil-moisture sensors connected to a \nmicrocontroller with a WiFi module. Our outdoor garden also includes a personal weather \nstation  connected  to Weather  Underground. With  their  application programming  interface \n(API) service, we can access real-time and historical weather data, as well as a seven-day \nweather forecast from the rooftop. Additional sensors could be similarly installed to measure \nother environmental factors, such as solar radiation, CO2, and air pollution.   \n\nTo incorporate this sensor data into ELUA, we have created a virtual server that hosts our \nown database as well as any API services. This greatly expands ELUA’s capability because \nit connects each FarmBot to other types of open data and services. For example, with weather \nforecast data, ELUA could modify scheduled watering regimens for precipitation and drought.  \n\nMachine Learning and AI \n\nAI is pervasive in this research. Non-experts. including many landscape researchers, often \nthink of an AI system as a general artificial intelligence that addresses multiple goals simultaneously. In ELUA, however, AI algorithms are individually built for specific tasks.  \n\nIn ELUA, the AI camera we added processes images with OpenCV, an open-source computer \nvision  and  machine  learning  software  library.  This  provides  machine  learning  algorithms, \nincluding pre-trained deep neural network modules that can be modified and used for specific \ntasks, such as measuring plant canopy coverage and plant height. Machine learning and AI \nplanning can also be used with the multimodal sensory data described in Section 2.4 to provide data-driven guidance to improve garden management. \n\nAn AI system that relies on reinforcement learning (RL) develops a policy for its behavior \nwhen it is rewarded or punished for the outcome of its actions. Such systems have devised \nunexpected behaviors in Go, chess, and some video game that expanded human players’ understanding of these games and provided new insights (SCHRITTWIESER et al. 2020). Landscape architects and ecologists now also imagine how RL systems might manage the environment and construct wild landscapes (CANTRELL et al. 2017, ZHANG & CANTRELL 2021). One research team conducted RL experiments to prune a polyculture garden with a FarmBot \nto increase biodiversity (PRESTEN et al. 2022). We will perform RL experiments in a simulated environment with a virtual robot and later test the learned policies with a physical robot. \nWe envision a version of ELUA that will evolve and propose novel methods, such as combinations of different watering nozzles and watering paths in different scenarios. We hope some \nunexpected  combinations  will  surprise,  intrigue,  and  inspire  us  with  their  successful  outcomes that help the garden adapt to a changing climate.  \n\nResults and Discussion \n\nIn the fall of 2022, we planted herbs on the rooftop and lettuce and herbs in the indoor garden \nto learn and test the basic functions of the robots. (The indoor ELUA robot in action appears \nin  a  brief  video  at  https:\/\/youtu.be\/VTec_SXO5Lk.)  Both  ELUA  robots  captured  garden \nmaps and carried out watering events as expected, although maintenance and troubleshooting \nare needed from time to time. This is a design-build project and every aspect of ELUA was \nconstructed  by  faculty  and  students.  Our  team  has  gained  hands-on  knowledge  as  it  constructed ELUA. Here, we offer three recommendations.  \n\nFirst, in cities like New York, public and free resources are available for academic research \nand well worth the time to track down the networks of organizations and groups. We received \n3 cubic meters of free, clean mineral soil from the NYC Clean Soil Bank hosted by the NYC \nMayor's Office of Environmental Remediation. The soil was delivered by the crews from the \nNew York Restoration Project. We received 40 bags (1 cubic meter) of compost from the \nNYC Composting Project hosted by Big Reuse. In return, we took the Big Reuse crews to \ntour ELUA, and hope to maintain this relationship. We learned about our current soil mix (⅓ \nmineral  soil,  ⅓  compost,  and  ⅓  perlite)  during  a  free  guided  tour  of  a  green-roof  facility \nhosted by the NYC Department of Parks & Recreation. ELUA would have been far more \ncostly and difficult to construct without these public resources. We encourage prospective \ndevelopers to seek out similar assistance. \n\nSecond, “open-source” offers adaptivity to its users but also forewarns the necessity of substantial troubleshooting. Although FarmBots appears to be user-friendly, some knowledge of \ncomputer science and electrical engineering is required to set up such a system. Researchers \nand research assistants from our Departments of Computer Science successfully overcame \nmany issues during our installation. Moreover, a licensed architect on the team successfully \ndesigned and constructed the garden beds and installed a FarmBot onto the existing load-bearing rooftop structure. A multidisciplinary team of computer scientists and designers is \nhighly recommended to replicate ELUA.  \n\nFinally, institutional knowledge is important in academic research. Institutional structures in \nuniversities, especially public schools, can support or hinder academic research visions. Researchers need to be nimble and adaptive in pursuing their goals. For example, thanks to the \nArchitecture School, the Colleges, and the University, we received multiple seed funds for \nELUA.  The  Architecture  School  also  provided  space  and  infrastructure  to  house  ELUA. \nSome rules, however, could not be bent. Because the University’s security regulations blocked \nnetwork ports used by a FarmBot, we have had to set up alternative 5G Wi-Fi hotspots untill \nthe University can provide a research-only network. We recommend an ample buffer in the \nresearch schedule to account for unexpected circumstances, as well as a good rapport with \nuniversity offices.  \n\nConclusion  \n\nDespite ELUA’s practical focus on urban food production, it is also a thought experiment \nthat challenges landscape architects’ conventional views on agency and intelligence. With \nELUA, we want to formulate a theory that questions how the environment is conceived and \nconstructed.  To  some  extent,  ELUA  offers  a  glimpse  into  an  ecosystem  of  computerized \necology where the relationship between humans and plants is deeply mediated and, at the \nsame time, enabled by sensors, controllers, computer hardware, layers of computer code, and \nonline servers.   \n\nA  problem  in  the  perspective  of  landscape  architecture  is  its  current  conception  of  AI  as \nintelligence embodied in a single agent (CANTRELL & ZHANG 2018). Ideas in posthumanism, \nhowever, such as assemblage and sympoiesis become new concepts to reframe agency and \nintelligence as distributive (BENNETT 2010, HARAWAY 2016, TSING 2015). From this posthu-\nmanist  perspective,  intelligence  should  be  viewed  as  an  emergent  epiphenomenon  arising \nfrom the interactions of an assemblage of actors – humans, AI agents, animals, and plants. \nThis framing sheds light on a new landscape design paradigm based on co-evolution among \nbiotic  and  abiotic  agents.  We  could  allow  AI  systems  and  plant  and  animal  agents  to  co-evolve to create novel ecosystems that inspire us with new methods to construct the land-\nscape.  \n\nIn  this  new  landscape  design  paradigm,  AI  agents  would  no  longer  simply  model  human \nbehavior under human control. Instead, they would become co-creators among human and \nnonhuman  actors.  They  could  offer  novel  approaches  and  long-term  cultivation  strategies \nthat humans can learn from and use to adapt to the changing climate. ELUA is a physical \ndemonstration of this new paradigm of landscape design. It provides empirical evidence that \ncollaboration among AI agents and other human and nonhuman actors is within reach.  \n

Toward Acoustic Landscapes: A Digital Design \nWorkflow for Embedding Noise Reduction in \nGround-forming  \n\nAbstract: Noise pollution is considered the number two environmental health risk in Europe, and there \nis increasing global awareness of the health risks associated with noise exposure. As urbanization expands, a growing number of people are exposed to urban noise, to which airports and large urban infrastructure are significant contributors. Unlike indoor noise, which is extensively addressed using digital \ntools in architecture, there are limited parallel efforts in landscape architecture. In this context, mitigating outdoor noise through ground forming can replace the standard use of sound barriers and offer noise \nreduction means together with recreational use. The paper presents and demonstrates a digital workflow \nfor designing acoustic grounds. The workflow links environmental noise data, parametric design, and \nacoustic simulation in a single design environment. A case study site adjacent to Munich Airport is \nused to demonstrate the workflow and comparatively examine the acoustic performance of different \ndesign patterns. The results indicate a possibility of reducing noise levels through ground forming.  \n\nIntroduction: In Search of a Vast, Horizontal Acoustic Tile \n\nIn  2011,  noise  pollution  was  named  the  number  two  environmental  health  risk  in  Europe \n(WORLD HEALTH ORGANIZATION 2011). Since then, the World Health Organization (WHO) \nhas  constantly  been  updating  the  health  risks  associated  with  noise  exposure  (WORLD \nHEALTH ORGANIZATION  2022).  As  urban  areas  expand,  the  number  of  people  exposed  to \nurban  noise  grows.  Airports  and  large  urban  infrastructure  significantly  contribute  to  this \nnoise (BOUCSEIN et al. 2017). In addition, the propagation of noise caused by transport infrastructure has been shown to increase through poor urban design (MORILLAS et al. 2018). Existing methods for mitigating outdoor noise typically consist of prefabricated, vertical indus-\ntrial acoustic walls. In contrast to acoustics in architecture, where digital tools are used to \ndesign and fabricate site-customized acoustic tiling, outdoor noise is not  met with similar \nmeans. However, preliminary examples indicate that formed grounds could mitigate sound. \nDespite this potential, there is a lack of dedicated methods for creating acoustic grounds in \nlandscape architecture. Mitigating noise through acoustic grounds could be beneficial for urban airports, which are typically bordered by buffering open spaces. In such areas, ground \nforming can provide noise mitigation as well as public recreational use. \n\nContext and Objective \n\nDigital tools enable the introduction of preciseness into landscape architecture design and \nmaking (CANTRELL & MEKIES 2018). Preciseness is defined here as the process of highly-articulate tailoring of a design for mitigating a natural phenomenon. In this context, the design of acoustic grounds requires linking environmental data relating to noise to a landscape \ndesign aiming to mitigate it. The research seeks to promote noise mitigation through what \ncan be viewed as the horizontal, ground-made, site-tailored version of an acoustic tile. To this \nend, the paper presents a digital design workflow for embedding noise reduction and simulating \nacoustic performance in landscape architecture. The workflow is based on a method for incorporating  acoustic  analysis  in  landscape  architecture  design  developed  by  the  authors  (BARSINAI et al. 2023). This is demonstrated through a case study site in Hallbergmoos, adjacent to \nthe  Munich  airport,  which  is  amongst  the  ten  busiest  airports  in  Europe  (BOUCSEIN et  al. \n2017). Currently, no physical noise reduction measures exist in the area (Figure 1). \n\nState-of-the-art: Design and Simulation of Acoustic Grounds \n\nThere is a growing awareness of the need to protect from noise in outdoor spaces (SORVIG & \nTHOMPSON 2018). In the context of airport noise, mitigation is addressed through three levels: a primary level, which targets the noise source and is applied during the production \nof aircraft; a secondary level, which adapts aircraft arrival and departure procedures; and \na tertiary level which includes measures by the local airport of aviation authority grounds \n(NETJASOV 2012).  \n\nUntil recently, tertiary-level noise mitigation measures around airports did not include the \nformation of acoustic grounds. This possibility is beginning to be explored in landscape architecture projects, demonstrating a capacity to mitigate noise and vibrations through targeted \nground forming. For example, Buitenschot Park demonstrates a reduction of the Schiphol airport noise through the construction of ground ridges and furrows. The park design distorts \nand disperses low-frequency noise waves, which have been reported to reduce the noise surrounding the airport by 10 dB (TASHAKKOR et al. 2020). A similar approach employed ground-\nforming for mitigating vibrations around a MAX Lab IV in Sweden  \n\n(WALLISS & RAHMANN 2016). These two examples challenge the standard practice of constructing absorbing sound barriers surrounding urban noise sources. However, there is still a \nlack of methods for performing noise mitigation through ground forming.  \n\nAcoustic simulation is often performed using stand-alone tools (SAKUMA et al. 2014), and as \nsuch, they do not readily support design iteration. While there are dedicated frameworks to \nintegrate acoustic simulation in architectural design (PETERS 2015), there is a lack of similar \nmethods for embedding noise reduction in landscape architecture design processes. Pachyderm, a recently developed open-source tool, performs ray tracing-based sound propagation \nsimulation and visualization embedded in 3D design environments (VAN DER HARTEN 2013). \nHowever, despite the availability of Pachyderm, there is still a need for methods for applying \nit toward noise reduction in the design of open spaces. The lack of such methods currently \nlimits the possibility of addressing noise in landscape architecture and urban design. \n\nAcoustic Landscape Design Workflow \n\nThe paper addresses these gaps by developing a digital workflow that links noise, design, and \nsimulation for embedding acoustic performance in landscapes. The workflow consolidates \nthe design and simulation in a single digital environment. It consists of noise data analysis, \nthe design of parametric ground formations, and acoustic simulation and evaluation. \n\nNoise Data Analysis: Combining Online and On-Site Measurements  \n\nAirport  noise  consists  of  ground-level  noise  as  well  as  noise  produced  by  aircraft  during \ntakeoff,  landing,  taxiing,  and  idling  stages.  The  Munich  Airport  tracks  noise  in  real-time \nthrough monitoring stations and provides publicly available data (MUNICH AIRPORT 2022). \nHowever, only one of the monitoring stations is positioned on the perimeter of the site. In \naddition, the monitoring stations are situated 4 m above ground. This height is determined by \nthe  Environmental  Noise  Directive  (END)  (EUROPEAN COMMISSION  2002),  as  it  is  where \nreflections from the ground stop playing a major role. Measurements performed above 4 m, \ntherefore, allow the official comparison of different contexts. This calculation method is also \nthe basis for all the noise abatement measures. However, measurements at the height of 4 m \nlimit the possibility of understanding the noise as it is perceived by a listener on-site.  \n\nTo  sense  the  noise  as  it  is  felt  on-site,  the  study  combined  online  data  with  on-site  noise sampling using mobile phones. The use of mobile devices has become an increasingly prevalent method for collecting environmental data (MURPHY & KING 2016). The noise sampling \nwas conducted using five different devices. The devices simultaneously recorded the noise \nlevels during takeoff and landing on five points on-site for 90 consecutive seconds (Fig. 2). \n\nDespite their limited accuracy, and while at this point of the research, no identifiable rela-\ntionship between the official and on-site sampling could be specified, the mobile phone meas-\nurements provided a picture of the felt noise levels on the ground. This noise, therefore, also \nincludes the ground effect which the official measurement stations exclude. While the official \naveraged noise contour (BAVARIAN MINISTRY OF ENVIRONMENT 2021) is limited to the runway areas (Figure 1), the on-site noise sampling recorded peaks of 75 dB and above beyond \nthe airport fence and within Hallbergmoos, underscoring the need for noise abatement in the \narea notwithstanding the averaged noise levels. \n\nDesign: Parametric Ground Formations \nThe design first proposed a basic layout for the park and coupled the desired noise mitigation \nstrategy with urban design considerations. The plan defined the movement paths, program, \nand areas dedicated to acoustic ground-forming (Figure 3). In these areas, the research tested \nformations consisting of mounds with public paths located between them. Four design patterns were tested at three heights: 2.5 m, 5 m, and 7.5 m. These included: high-to-low (HL), \nundulating mounds in gradually decreasing heights (7.5\/5\/2.5 m – 0.5 m); low-to-high (LH), \nundulating  mounds  in  gradually  increasing  heights  (0.5  m  -2.5\/5\/7.5  m);  constant  height \nmounds (CM), featuring uniformly sized undulating mounds (tested in 2.5\/5\/7.5 m); and constant heigh solid ground (CS), an elevated ground without any undulation mounds (tested in \n2.5\/5\/7.5 m). The width of the mounds was set to 21 m to provide an inclination and slope \nthat allow public accessibility even in the higher-mound instances (Figure 3).  \n\nAcoustic Simulation and Evaluation \n\nThe simulation process includes several aspects:  \n\n1)  A  base  model  –  the  base  model  aimed  to  reproduce  the on-site  conditions  and  noise \nlevels  as  measured  before  any  ground  modification.  In  construction,  base  models  are \noften referred to as 'digital twins,' a digital environment that simulates the existing condition in the physical environment (BOSCHERT & ROSEN 2016). The topography and the \nbuilt fabric were created using Blender with imported layers derived from Shuttle Radar \nTopography Mission (SRTM) data, a GIS data source with a 9-16 m accuracy. The model \nwas then placed in a bounding box to support the acoustic simulations.  \n\n2)  Noise source (emitter) – the noise source was introduced into the model and situated on \ntakeoff lane 08R\/26L at a level of 75 dB. The simulation works as a transfer path that \ndisperses the noise. The transfer path holds a noise spectrum with several frequencies. \nHowever, simulations, including the presented ones, rarely include all frequencies.  \n\n3)  Simulation tool – for simulating sound propagation, the research employed Pachyderm \nRC 26, an open-source tool that integrates acoustic simulation and visualization in a 3D \ndesign environment (VAN DER HARTEN 2013). Pachyderm provided a ray tracing-based \nmethod and was integrated into Grasshopper and then linked to the base model. This \nintegration allowed performing the design and the simulations in the same digital environment. The research employed an i7 processor, 32GB of RAM, and an Nvidia Quadro \n1000 graphics card which could not perform a full-site acoustic simulation due to insufficient processing power, memory, and graphic processing.  \n\n4)  Noise sampling grid and points (receivers) – to address the simulation challenge, the \nstudy  developed  a  method  for  sampling  the  acoustic  performance  using  a  grid  with \n20\/20m size cells. Within this grid, three listener points were positioned as noise receivers at a height of 1.65 m (Figure 4). Point 1 was closest to the airport runway, point 2 \nwas in the middle of the site, and point 3 was in the residential area of Hallbergmoos. \n\nEvaluation – while the simulation calculated noise levels, the evaluation focused on the relative reduction in the noise levels as measured in the model before and after the design intervention and reformed grounds. The focus on the reduction levels allowed us to analyze noise \nreduction as a trend and compare the acoustic performance of the different design scenarios. \n\nResults \n\nThe results of the simulations, summarized in the table (Table 1) and graph (Figure 5), can \nbe viewed through three aspects: listener points, design, and height. Each scenario is referred \nto according to the initials of the design pattern, followed by the height in m (i. e., CS2.5). \n\nPerformance by Listener Point \n\nPoint 1: The best noise mitigation was achieved here with HL5 (28.4 dB reduction) followed \nby CS2.5 (27.5 dB reduction), C7.5, and CS7.5 (27.4 dB reduction). Last ranked the LH 2.5 \n(1.3 dB reduction).  \n\nPoint 2: The best noise mitigation was achieved with C5 (26.4 dB), poorest performance \nwith LH2.5 (1.3 dB reduction).  \n\nPoint 3: The best mitigation is achieved with CS7.5 (21.9 dB reduction), followed by C5 \n(21.6 dB), then CS5 and HL7.5 with a similar noise reduction (20.5 dB reduction). The poorest performance was CS2.5 (16.2 dB).  \n\nPerformance by Design Pattern \n\nHigh-to-low (HL): This design showed the most effective noise reduction levels at point 1 \nfor all heights. The best performance was achieved with 5 m mounds which showed an average reduction of 23.9 dB across the three points.  \n\nLow-to-high (LH): In this design, there was a significant difference in effectivity between \nthe lower mound patterns (2.5 m) and the 5 and 7 m high ones. The best average reduction \nacross the three points was attained by the 5 m high mounds (23.1 dB).  \n\nConstant  mounds  (C):  This  design  demonstrated  highly  effective  noise  reduction  levels. \nThe highest effectivity was attained by the CM2.5 (24.7 dB), followed by CS7.5 (24.7 dB), \nand CS5 (24.1 dB).  \n\nConstant solid height (CS): This design demonstrated that CS5 performed better than CS2.5 \n(4.3 – 2.2 dB difference), CS 7.5 performed better than CS5 at point 1, but CS5 performed \nbetter than CS 7.5 m at points 2 and 3. The average reduction of CS5 and 7.5 m was equal.  \n\nPerformance by Height \n\n2.5  m:  Constant  mounds  perform  best  at  all  points,  followed  by  the  constant  solid.  LH \nshowed the poorest performance at points 1 and 2 and then a significant increase in performance once height was reached toward point 3. At point 3, HL and LH performed with a \nnegligible difference.  \n\n5 m: At this height, the HL pattern demonstrated the best performance at point 1. In average \nperformance, however, constant mounds outperformed HL with an average reduction of 24.1 \ndB compared to 23.8 dB by HL. CS followed with an average reduction of 20.67 dB.  \n\n7.5 m: At this height, HL, C, and CS all lost effectiveness with distance. The LH section \nperformed marginally better at point 2 than at point 1 (0.4 dB). All the designs at this height \nshowed the lowest noise reduction at point 3. \n\nDiscussion \n\nAcoustic Performance Trends \n\nIn line with existing works, the results indicate a possibility of reducing noise levels through \nground forming. A few noteworthy trends can be summarized based on the acoustic performance results:  \n\n1)  Higher does not equal better – while we would expect the highest mounds to perform \nbetter,  the  simulations  showed  that  performance  is  impacted  more  by  design  than  by \nheight. The  best-performed mitigation,  HL5,  was not  achieved  by  the  highest design. \nThe lowest height, C2.5, outperformed other designs and showed an equal performance \nto C7.5. In addition, in comparing the same design at different heights, such as in the HL \npattern, the best performance was shown at 5m rather than 7.5 m.  \n\n2)  The benefit of patterns – the results indicate the benefit of the constant mounds (CM) \npattern in relation to constant solid ground (CS) for mitigating noise. This trend can be \nclearly seen by comparing the CS2.5 m to the other patterns, as well as in the high average performance of CM in relation to the CS 5 pattern.  \n\n3)  High-to-low  outperforms  low-to-high  mound  patterns–  overall,  the  patterns  that \nranged from high to low performed better than the designs ranging from low to high. A \nsignificant  difference  was  seen  with  the  LH2.5  pattern,  which  had  the  lowest  performance (1.3 dB reduction) compared to the other results. An exception is LH 7.5, with \nslightly better performance than HL7.5 at point 2. This trend may indicate that patterns \nincreasing in height in the direction of the noise dispersion provide less effective mitigation unless they are high enough to form a barrier adjacent to the noise source, which \nexplains the improved performance of LH5 and LH7.5.  \n\n4)  Constant height outperforms inclined, high-to-low slopes – constant mounds (CM) \nshow great effectivity regardless of their height, and mounds as low as 2.5 m can yield \nsignificant noise reduction. This result aligns with the effectivity demonstrated around \nthe Schiphol airport, where constant-height ridges and furrows were used and reportedly \nreduced the noise levels by 10 dB (TASHAKKOR et al. 2020). However, in comparison to \nridges, mounds can offer more accessible and versatile public use throughout the park, \nnot limiting public activity to the furrows. \n\nContribution and Current Limitations  \n\nThe paper contributed a novel digital workflow for designing acoustic grounds. The work-flow provides and demonstrates a step-by-step guide for parametrically designing, prototyping, simulating, and evaluating noise mitigation through ground forming. The digital work-\nflow includes several steps – noise analysis, parametric design, and acoustic simulations, and \nallows for comparatively evaluating ground formations to understand their noise mitigation \neffectivity.  \n\nThe  workflow  was  demonstrated  in  a  site  adjacent  to  the  Munich  airport.  The  parametric \ndesigns featured three patterns of undulating mounds and one constant-height solid ground \nat  three different  heights.  The  acoustic  evaluation  was  performed  by  comparing  the  noise \nlevels  before  and  after  the  ground  modification  in  selected  points  within  the  simulation \nmodel. The results indicate the benefit of using constant height, undulating mounds rather \nthan inclined patterns of higher flat elevated grounds as a noise mitigation strategy.  \n\nDue to the complexity of the task at hand, the study faced several limitations, which will be \naddressed in future work. First, the complexity of acoustic simulations increases significantly \nwith the size of the tested area and, along with them, the computing time. This complexity is \na  current  obstacle  in  using  such  tools  in  landscape  architecture.  In  the  future,  this  can  be addressed with improved processing power, memory, and graphics processing capabilities. \nAlternatively, a different simulation method with a lower sampling rate could be used. The site  could  also  be  divided  into  smaller  parts,  simulated  separately  before  their  results  are \ncombined. Second, the research focused on noise propagation and did not look at: the frequency aspect; the effects of weather, a factor known to influence noise; and the effect of \nnoise absorption on the ground surface and the way different ground covers may contribute \nto reducing noise transmission. Finally, future work will also look at additional design patterns, varying heights, and regularity vs. irregularity and consider these factors in relation to \nmultiple noise emitters in various locations. \n\nConclusion and Outlook \n\nThe presented workflow allowed us to comparatively assess the acoustic performance of different landscape designs and discern trends associated with their design features. This contributes to the capacity to embed acoustic performance in landscape architecture and mitigate \nnoise pollution through ground forming. The digital workflow can be used for addressing \nnoise around other airports as well as around other sources of urban noise or large transportation infrastructure. As such, the workflow also promotes a broader endeavor – the development  of  dedicated  methods  which  link  environmental  data  and  parametric  design  toward \nforming performative grounds in response to environmental challenges. \n

Urban Agriculture:  \nClimate-Responsive Design Strategies for \nBlue Infrastructure in the Context of Singapore \n\nAbstract: Global climate change poses various threats to densely developed cities and their urban infrastructures. As an archipelago and product of many significant land reclamation efforts over the centuries, Singapore is most vulnerable to rising seawater levels and faces increasing climate change-related challenges, including intense rainstorms, water scarcity, food shortage, and extreme heat. This \npaper proposes a Synergy System, or climate-responsive computational design method, to create a new \ntypology of urban agriculture integrated with the existing infrastructure. This study employs performance-based generative design to generate typologies and optimize them in terms of driving factors \nsuch  as  food  production  and  microclimate  adjustment.  The  performance  evaluation  model  as  a  tool \nsupports the design of multifunctional and climate-responsive infrastructure typologies. \n\nIntroduction: Climate Challenges in Singapore \n\nAs a highly urbanized city, Singapore has suffered from complex challenges related to climate change, putting climate adaptation in the spotlight for future urban development. Singapore’s main climate crisis includes intense rainstorms, water scarcity, food shortage, and \nextreme heat (NATIONAL CLIMATE CHANGE SECRETARIAT 2022). For instance, frequent extreme rainstorms have put overwhelming stress on the stormwater infrastructure and have caused flash floods in urban areas (PUB 2022). Half of Singapore’s fresh water supply relies \non imports from Malaysia (ROMAN & CHEOK 2016), which will end in 2060. In addition, \n90% of Singapore's consumer food is imported, motivating local food production to achieve \n30% food self-sufficiency by 2030 (TENG & MONTESCLAROS 2019).  \n\nThe increasing challenges on urban infrastructure and residents’ daily lives have raised increased concerns about building a climate-resilient city for the future. The concept of urban climate  resilience  emphasizes  city  and  urban  infrastructure  as  a  complex  adaptive  system \nwith the ability to maintain basic functions in the face of climate disruptions (MEEROW et al. \n2016).  \n\nThe main climate challenges Singapore faces are closely related to three aspects: stormwater \ninfrastructure, urban agriculture, and microclimate. The synergies between them serve as the \nbasic  logic  for  building  climate-responsive  infrastructures.  Concrete  canals,  one  typical \nstormwater infrastructure, cannot accommodate peak flows during extreme rainstorms and \nare ineffectively utilized during the dry season. They are required to be transformed into a \nnew generation of infrastructure bolstering ecosystem services (LIQUETE et al. 2015). This \ncan be achieved by integrating a new typology of urban agriculture with the concrete canals, \nwhich promotes “the well-being of urban ecosystems and resilience in a circular economy.”(DEKSISSA et al. 2021). \nMoreover, decentralized urban farming integrated with underutilized \nspaces is a sustainable way to enhance local food production (SINGAPORE FOOD AGENCY \n2021). Utilizing the rainfall collected in canals for food production contributes to water conservation,  which  is  highly  imperative  to  sustainable  vertical  farming  (ASSOCIATION  FOR \nVERTICAL FARMING et al. 2015). Furthermore, the food-growing structures provide shading \nfor  microclimate  mitigation,  as  vegetation  shading  can  effectively  reduce  solar  heat  gain \n(OLGYAY 1963).  \n\nIn terms of the identified research gap, the synergies among the above three aspects have not \nbeen fully investigated and implemented into a computationally driven design strategy. A \nnew approach is required to explore the material flow of this synergy system and design a \nclimate-responsive typology based on its performance on food production and microclimate.  \n\nCore Synergies \n\nThe core synergies are summarized as follows (Figure 1): The rainfall collected in the stormwater infrastructure can be supplied for food production, while the growing plants provide \nvegetation  shading  for  cooling  the  microclimate.  Stormwater  infrastructure  in  connection \nwith urban agriculture can increase drainage capacity, offer accessible community spaces, \nimprove green features, and create comfortable microclimates.  \n\nThe synergies set the fundamental logic for a new computational design approach to transform existing monofunctional concrete canals into an adaptable and multifunctional infrastructure  typology  for the future. They  not only serve  as a  drainage  facility,  but  also  as  a \nresponsive landscape that interacts with the water. They not only sustain an industrial food \nproduction factory, but also provide diverse spaces for community interaction. Establishing \nthis infrastructure typology requires a systematic approach that explores and evaluates the \nenvironmental interactions related to rainfall and sunlight. This complexity is viewed as a \npositive challenge, to create a new design language connecting the green, the blue, and the \ngrey elements of a city to produce new and vibrant patches of local identity. \n\nClimate-responsive Design Methodology  \n\nComputational Design & Performance-based Design \n\nThe proposed design method aims to generate and optimize a climate-responsive typology \nbuilt on the domains of computational design and performance-based design (CHAOWEN & \nFRICKER 2021). Computational design thinking understands architecture as a dynamic system \ncomposed  of  interactions  between  elements,  rather  than  as  a  static  entity  (MENGES  & \nAHLQUIST 2011). Working with systems rather than forms is the connecting thread between \nspace-making  and  environmental  challenges  of  design.  Performance-based  design  underscores the value of environmental performance that reflects how architecture continually interacts with the surrounding environment. Performance-based design method combined with \ncomputational design has potentials in generating a climate-responsive typology. First, as a \nsystematic approach, computational design enables designers to focus on the connections and \nmaterial flows between the three identified elements and exploit their synergies; second, this \nmethod takes environmental performance as a design driver that facilitates the generation and \noptimization of design solutions. The infrastructure can no longer be seen as static built environments, but as “’dynamic’ self-constructing, living, breathing, and even artificially intelligent (thinking) environments” (CANTRELL & MEKIES 2018, 28).  \n\nPerformance Evaluation Model \n\nThis study develops a new performance evaluation model for the generation and optimization \nof climate-responsive infrastructure by establishing the relationship between the parameters \nand performance related to the synergy system. Within the synergy system, three subsystems \nare defined and connected with the material and energy flow of water and sunlight: the water \nsystem, the food production system, and the microclimate system.  \n\nBased on the connection, the performance criteria and parameters are defined that inform \nhow to build the three subsystems (Figure 2). Firstly, the focus is set on the catchment area \nof the canal and the calculation of runoff variability and water storage capacity, informing \nthe amount of food that can be grown. Secondly, the food production system establishes a \ncomputational model and defines a set of performance evaluation criteria for the food production condition and capacity, including direct sun hours, yield, food type, and water consumption. This paper takes a planting tower from a previous study as the prototype and extracts its relevant parameters (SONG et al. 2022). Lastly, the microclimate system measures \nthe thermal comfort of public spaces, which refers to the radiation performance of the space \nshaded by planting geometries. The Grasshopper plug-ins, Ladybug and Honeybee, are used \nas tools for the simulation and visualization of direct sun hours and radiation. Therefore, the \nkey performance of the model is derived from three subsystems: direct sun hours, yield, water \nconsumption, and radiation of the shaded area. \n\nForm Optimization Experiment \nThe  performance  simulation  starts  with  the  adjusted  prototype  planting  tower  introduced \nabove to explore the impact of different geometric parameters on the performance of food \nproduction and microclimate (Figure 3). Four metrics of performance need to be evaluated: \nyield, direct sun hours, water consumption, and solar radiation of the shaded area. The simulation experiments explore the impact of the variation of three parameters of the planting geometry on these performances: slope, orientation, and curvature. The footprint of the planting tower was kept constant (12.5m2) in all experiments. \n\nThe results can be summarized below: \n\n1. When the slope is in the domain ranges from 60 to 75 degrees, the performance of direct \nsun  hours  and  yield  is  balanced  well.  The  area  with  radiation  lower  than  200W\/m²  is  the \nlargest when the shape of the footprint is similar to a square. \n\n2. The performance of direct sun hours and radiation performs best when the planting surface \nis facing east and west. It can be taken as the main direction of the design. \n\n3. The variation of vertical curvature creates planting areas with different direct sun hours, \nwhich is ideal for producing various types of vegetables. The yield and shaded area are pos-\nitively correlated with horizontal curvature(D), and performance can reach the optimal point \nwhen it is above 0.4m.  \n\nThese main findings inform the designer how to adjust and optimize the form to balance the \noverall performance and achieve the desired state. It ignites the thought that environmental \nperformance should also be considered as an essential design trigger, especially in climate-responsive infrastructure design. In addition to the described performance of food production and thermal comfort, the design needs to consider other aspects, such as function, structure, \nand spatial aesthetics. Nevertheless, the introduced computational workflow offers designers \nan iterative tool to measure the environmental performance of different design solutions and \nunderstand the relationship between parameters and performance (FRICKER 2022). This tool \nfacilitates design trade-offs between environmental performance and other aspects of design \nto enhance the overall quality of infrastructures.  \n\nDesign Speculation for New Urban Typology  \n\nWater Volume Calculation \n\nThe prerequisite for designing a food production factory is establishing a dynamic water system with associated flow processes, specifying the amount of water flowing into the canal \nand used for food production. The first step is identifying the catchment area and the population it serves; the second is calculating the dynamic water supply and consumption for the specific site to deduce the maximum volume of water storage. \n\nFirstly, the upper stream catchment of the Jurong canal can be roughly depicted based on \nland contours and simulation of water distribution using Kangaroo plug-in in Grasshopper. \nThe area is around 9,560,000m² (Figure 4). Among the eight districts in this catchment area, \nHong Kah  and Yuhua West are  the  two  adjacent  to  the  Jurong  Canal with  76,560 people \nliving there. The goal for food production is to reach 30% of the annual food consumption of \nthese populations, which implies an ideal yield of about 370 tons of leafy vegetables. Secondly, this system pumps water during heavy rainstorms to reduce peak flow in the canal and store them to use during the dry season. Taking the rainfall data in 2021 as a reference, the \nmaximum water volume of storage is roughly 4,000 m3, informing the generation of water \nstorage space.  \n\nWater flow and plant growth give this system a dynamic character, where the water storage \nlevel and the amount of food production adjust according to the rainfall patterns. This feedback  mechanism  enables  the  system  to  cope  with  extreme  rainfall  weather  by  effectively \nrelieving the pressure of heavy rainfall on the urban drainage system. This performance echoes the original purpose of developing climate-responsive water infrastructure. \n\nDesign Generation \n\nThe design generation begins with the selection of the optimized type of planting geometry \nby comparing the performance of different forms (Figure 5). The generated geometry of two \nparallel curves has the best overall performance, in line with the results of the simulation \nexperiments. The yield is higher due to the large horizontal curvature (D), which maximizes \nplanting area and allows sufficient sunlight to reach both sides. Moreover, the twisted surfaces  provide  enough  shaded  spaces  with  good  thermal  comfort.  The  key  to  this  iterative \nprocess lies in balancing the performance of yield, water consumption, and solar radiation, \nthus producing sufficient food and creating comfortable public spaces. \n\nThe  design  generation  includes  the  generation  of  planting  geometry,  building  details,  and \nlandscape. First, planting geometry is generated based on the selected type and optimized \naccording to the performance on yield, direct sun hours, and radiation, which is evaluated by \nthe computational model built in Grasshopper. The finalized geometry produces the targeted \nyield and provides several public spaces with solar radiation below 200 w\/m². Second is the \ngeneration of the water distribution system and functional spaces. The water storage space is \nset with a certain amount of flexibility added to the maximum demand to cope with the seasonal variation of future rainfall. The final step is to create a responsive landscape by reshaping the terrain according to water and pedestrian flow.\nGround-level planting areas for flood retention reduce the drainage pressure for the canal during peak periods. Overall, the generated example, the food factory on the lively riverfront offers communal space for people to \nmeet and allow new activities to emerge in the neighbourhood. \n\nConclusion and Discussion \n\nThe  design  of  climate-responsive  infrastructure  typology  driven  by  environmental  performance  is  of  vital  concern  for  creating  resilient  urban  habitats  in  the  future,  especially  for \nintensely developed cities like Singapore. The study fills in the existing gap in the computational design method for generating and optimizing an urban agricultural typology integrated with stormwater infrastructure that responds to climate change. The study explores the impacts of various geometric parameters on the performance for food production and thermal comfort, which serve as the guidelines for finding optimal design solutions for the typology. This design workflow demonstrates the iterative processes of design optimization according \nto the balance of the performance on yield, water consumption and solar radiation, which can \nbe applied to the renewal of other concrete canals. \n\nThis study presents a speculative design proposal combining multiple parameters \ninto a single design model instead of considering the economics of implementation \nand feasibility of the design. The discussion focuses on two aspects: Firstly, how much \neach performance factor contributes to the overall change in the design was not explicitly \nstated in the study, which might depend on the objectives of the design. Future research can \nhence set several design scenarios and discuss the contribution of multiple factors respectively. Secondly, social aspects, such as how to involve people in the food production process, deserve more careful consideration in order to ensure the long-term success of the endeavor. \nIn addition, project planning requires the collaboration of multiple stakeholders, which has \nbeen a constraint to large-scale government implementation of food production in the past. \n

Visualizing and Clustering Eye Tracking within 3D \nVirtual Environments \n\nAbstract: Visual perception is one of the most important sensory processes for most of the population. \nThis process plays a key role in how we navigate and way find in urban environments. A wide range of \nliterature offers insight into the relationship between the structure of urban spaces and navigability, as \nwell as literature identifying how individual differences play a role in how well people can recall elements and navigate environments. Measurement techniques that reveal these differences are often captured as procedurally based evaluations after individuals have navigated through an environment. However, these valuations do not necessarily help us understand the process of how observations link to \nrecall and navigation. In this paper, we show a new technique for conducting eye tracking in 3D virtual \nenvironments to assess the process of observation in urban environments. Further, we demonstrate how \nclustering techniques can be used to improve eye tracking data generated in these 3D environments. \nThe techniques we provide can offer a new means to better understand how form, function, and design \nelements are observed. \n\nIntroduction \n\nIn navigation, the visual perception of an environment plays a significant role in decision-making, as well as informs knowledge about the properties of spaces and the relationships of \nobjects that form the collective environment. One of the ways researchers have attempted to \nunderstand the decisions we make during navigation is to create highly controlled experiments using virtual environments (BRUNS & CHAMBERLAIN 2019). However, many of the \nprevious experiments lack a comparable diversity of objects, routes, scales, and relationships \nbetween these elements in comparison to the real world. The benefit of virtual environments, \nparticularly with modern gaming engines, is that the designer can control all elements within \nthe environment. This offers a means to simplify a problem and employ a more deductive \nscientific process, but it may come at the cost of understanding how perception works holistically within complex spaces. Unfortunately, quantifying perception holistically would require new methods for analyzing the process of perception. Further, a method like this would need to be implemented in complex environments, which can be self-defeating if it requires an oversimplification of the environment itself to operate. Thus, finding a technique that enables both the employment of complex virtual environments and a seamless integration of \nanalyzing  perception  holistically  would  be  a  major  step  in  understanding  the  relationship \nbetween human and environmental interactions. \n\nDesigning spaces for intuitive navigation is an important process for urban designers, campus \n(e. g. business parks) planners, and outdoor recreation trail designers. There are many design \nproblems to undertake in these instances, with navigation and wayfinding within the set of \nissues. Both these processes require individuals to recognize spatial patterns, comprehend \nrelationships of elements, make determinations of how to focus their attention, and remember \nimportant objects or spaces. There have been many approaches to assessing these processes, \nsuch  as  measuring  response  times  and  accuracy  in  remembering  landmarks  or  locations \n(CHRASTIL & WARREN 2015, ERICSON & WARREN 2020, GAGNON et al. 2018, WEISBERG et \nal. 2014) and assessing map drawings of paths and spatial layout (BRUNS & CHAMBERLAIN \n2019, GARDONY et al. 2016, WANG & SCHWERING 2015). However, these measures are usually done post hoc rather than in real time. Further, the measures are usually procedurally \nbased (e. g., memory recall), rather than processes based (formation of memories). To improve our understanding of how process-based navigational activities unfold, we need to understand what drives perception and decision-making. A better understanding could help designers support meaningful relationships between objects to facilitate these perceptual processes. Fortunately, computational techniques can be created and then combined with cognitive science and urban and landscape design principles to better understand how individuals \nobserve and make inferences about those spaces. \n\nEye tracking is one technique that has been used by researchers to better understand the process of observation. It has been used for decades to understand how and why an individual \nfocuses on particular objects, areas, and elements of space. Implementations of eye tracking \nhave been primarily conducted in 2D environments (e. g. looking at a screen or flat image). \nThis includes architectural-related studies (XIANGMIN et al. 2021, ZHANG et al. 2019), with \nlandscape studies emphasizing 2D static images (DUPONT et al. 2016). In landscape and architectural studies, eye tracking is used to identify fixations within scenes, and in psychology \ncan help describe visual attention and arousal (KIM & LEE 2021). With many metrics that \ncan be analyzed from these data, broadly, one major advantage is to provide an objective \nmeasure of perception (DUPONT et al. 2014). Yet, relative to 2D eye tracking studies, there \nis little literature showcasing implementation in 3D dynamic environments. \n\nIn this study, we combine the generation of virtual environments and eye tracking to visualize \nindividual observational patterns in a virtual space. We extend previous work (FERNBERG et \nal. 2022) to showcase a new open-source software package we developed, as well as an analytical framework for representing these data. This paper deviates from the previous by showing specific visualizations and analyses of large datasets that have been analyzed, whereas the previous version was introducing the construct. The purpose of this study is to showcase how eye tracking data can be represented in a dynamic 3D environment and how those data can be analyzed using mathematical clustering mechanisms. We ask, to what extent can eye \ntracking be implemented in 3D gaming environments and analyzed post-hoc to determine \nfixations of objects within virtual urban spaces? \n\nData Collection from the Virtual Environment \n\nFor this work, we employ the Unity gaming engine and prefabricated 3D assets (from Kitbash) to create a procedurally generated urban environment which can be explored in VR. \nThe design of the environment was not intended to be complex or realistic world because this \nis not necessary for the primary purpose of implementing eye tracking and testing different \nclustering techniques. The environment consisted of 40 x 100-meter-long blocks, where each \nblock was one of five different architectural styles. The purpose of this setup was to observe \nif the pattern of clustering was different closer to transitions between different architectural \nstyles compared to areas where changes did not exist. However, in this study, we were merely \nattempting to identify how we might cluster data, the actual test of these transition zones is \nmeant for a later study. For now, all elements are static, the user can make observations freely, \nbut cannot change their location or speed of experience. Further, we have not included any \nother cues, such as sound, lights, or atmospheric changes. Each object was placed along a \ntwo-lane road in succession, with variable spacing between each building.  \n\n\nThe eye tracking software we developed, was created for implementation in the Unity gaming \nengine  only.  For  this  implementation,  the  Vive  Eye  Pro  virtual  reality  headset  was  used. \nWithin Unity, the headset was established as the user camera and the scripts were then associated with this camera. Movement through the environment was maintained at a consistent \nspeed, but the viewer can fully move their head around. The eye tracking software stores the \nlocation and rotation of the user’s eyes at every frame that gets rendered (about 60\/sec). The \ndata from each eye is averaged to create one point and one direction. This direction is, of \ncourse, where the user is looking. Using this information, we create an invisible virtual ray \nthat extends from the eye outwards (see Figure 2). Once this ray hits an object, the collision \npoint (location of the intersection of the eye tracking ray and the surface of the object) is \nrecorded along with the object’s name and position (recorded for accurate reproduction of \nthe data before participation). Other metrics are recorded and computed such as eye angle \n(looking left\/right\/etc.), distance from eye to collision, and whether they are blinking or not. \nThe figure below is a representation of rays produced along the route as a user looks at objects \non the buildings’ surfaces. \n\nThe data produced from a single experiment can result in a substantial number of data points \ncollected. With such a vast amount of data being produced, it is important to identify the most \nrelevant data that could provide researchers with meaningful interpretations of observational \npatterns. So, we needed to identify ways to reduce the amount of data by reducing noise and \njitter. Then, we needed to cluster the remaining data into meaningful groups, referred to as \nfixations. From this data, we can determine the total dwell time and total fixation count for \nspecific areas of interest. The areas of interest are regions in the environment that are important (HOLMQVIST et al. 2011) and could be identified as specific objects of general areas \nalong an object. \n\nTo  produce  clusters  from  denoised  data,  we  tested  a  clustering  method  called  DBSCAN. \nDBSCAN stands for Density-Based Spatial Clustering of Applications with Noise. This technique uses an unsupervised machine-learning algorithm to identify clusters of observations. \nAs the name implies, it uses the spatial density of the data points (in any number of dimensions) to create clusters and eliminate noise. One important function of this algorithm is that \nyou can use more than the 3-dimensional distance to find spatial density. It can include factors \nsuch as eye rotation and time in its calculations. This can be useful because in a dynamic \nenvironment participants can first look at an object in the distance, then as they move forward \nthrough an environment, look back at the object again. This dynamic  facet of 3D gamine \nenvironments makes it critically important to ascertain what is a fixation across distances, \nversus random noise that could have been part of a rapid eye movement across an area and \nalong an object. \n\nImplementation and Outcomes \n\nIn this section we highlight the results from the clustering technique to show: 1) the volume \nof data produced by a single participant, 2) the observational patterns of the participant, and \n3) the effects of implementing the clustering algorithm on the previous two. In this section, \nwe provide context to the implementation (for each of these three), takeaways from our experience, and general statistics to highlight an overview of the outcomes. \n\nIn our experiment, a single individual produced 39404 observations over the entire 9 minutes \nand 35 seconds of the experience. This averaged about sixty-eight observations per second. \n\nThe rate of eye tracking data collection depends upon Unity’s internal update function, which \nis the same as the framerate. Framerate is affected by how many objects are in view and need \nto be processed by the GPU. Therefore, the framerate can vary throughout the experiment. \nWhile it can be helpful to maintain a high-frequency rate to minimize motion sickness and \nimprove realism, it is unknown the extent to which the rate of data collection would impact \nthe results, for whatever results are being sought. \n\nUsing these data, we developed a simple metric to highlight how often an individual may \nlook at objects versus other elements in the environment. In our implementation, the objects \nwere buildings, and the other elements included the ground (terrain), the street, and the sky. \nIn our implementation, the ground and street are objects because they have a surface with a \ncollider that enables the collection of eye tracking data points when the vector of the observation intersects with that surface. Unlike buildings, these two surfaces are continuous through-out  the  entire  environment,  whereas  buildings  are  separate  objects.  Our  eye  tracking  also indirectly collected observations of the sky (or distant void), in which there is a frame with no distinct object with a collision surface. Figure 3 shows global statistics of the proportion of observations made between the sky, terrain, road, and buildings. The figure also compares those data after removing saccades. Saccades and their removal are explained below. \n\nEye tracking data can be difficult to interpret. This is particularly true in 3D, where there are \nvery few studies that have attempted to validate how observational patterns in 3D are associated  with  meaningful outcomes  of  navigation (UGWITZ  et  al.  2022).  One  crucial  step  in \ngenerating interpretations of data is to remove irrelevant data (e. g., noise), such as saccades. \nA saccade is essentially a rapid view of an object, then a focus away from that object with \nanother quick return to the original object. In terms of perception, little to no information is \ngleaned during a saccade. Therefore, in addition to general noise (single random observation \nin space), eliminating saccades can also help streamline the data analysis. \n\nHowever, identifying these saccadic movements requires playing with the clustering parameters. This is because eye tracking data is generated based on a collision point for each frame, \nbut how the algorithm determines if a single data point belongs to a cluster or not is a little \ntricky. To reduce noise and eliminate saccades, we implemented DBSCAN. DBSCAN takes \nthe {X, Y, Z} vector position where it collided with the object, but also the time dimension \nof when it collided. Clusters are determined by locational and temporal similarities of vectors \nby turning two parameters. First, epsilon is the distance threshold from one observation to \nanother (in 4D). Second, minimum points is the number of minimum points that constitute a \ncluster. Our parameters were an epsilon of two meters and a minimum points of seven, which \nrepresents roughly a tenth of a second or the approximate minimum amount of time for a \nfixation. Again, Figure 3 highlights the global statistics before and after the removal of saccades, or points that did not belong to a cluster.  \n\nFigure 4 further depicts an example of different clusters using different colored dots. In this \nfigure, similar colored dots represent a single observational point. Find the set of green dots \nright below the purple dots. The large cluster of green dots shares a similar proximity with a \nsingle black dot right on the roof ridge. This black dot seems to be part of that green dot \ncluster. However, DBSCAN identified that the observation point represented as the black dot \nshould not belong to a cluster. This was because the observational point was created several \nseconds prior as part of an earlier saccade (singular rapid observation), whereas the other \nobservations were made in sequence (suggesting a focal point or area). \n\nDiscussion and Conclusion \n\n3D gaming platforms offer the ability to produce vast amounts of user-centric data. Having \ntools to analyze these data can help designers identify environmental cues or triggers that \ncould influence the perception of a design or plan. Eye-tracking offers a non-intrusive, process-based technique for collecting very precise observations within a space. However, finding a robust algorithm to cluster thousands of eye data points is essential to making meaningful interpretations of these perceptions. Using the software we produced, these patterns can be visualized and reduced for making assessments about areas or objects favored by users. DBSCAN is one of several techniques available but has been shown to produce good \nresults (ESTER et al. 1996). This paper was not intended to conduct a systematic comparison \nacross these techniques and variations, but instead to demonstrate the potential for eye tracking data in combination with a clustering technique to produce useful data. \n\nThe next major step in this research is to understand how these data can be related to meaningful observations to help form decision-making and recall. Understanding this link can help \ndesigners better associate the placement and patterns of objects, such as landmarks (BRUNS \n& CHAMBERLAIN 2019), within the environment to improve wayfinding and navigation. As \nThus,  some  next  research  questions  are:  to  what  extent  do  eye  tracking  observations  in  a \ndynamic 3D virtual environment correlate with memory recall, navigational decisions, and \npattern recognition about the overall design of the environment? More broadly, to what extent \ncan eye tracking help us understand how individuals form mental maps? In our experience, \nwe  noticed  several  situations  where  individuals  were  following  unique  building  features, \npeering through passageways, and scanning the topography of buildings. While these observations are anecdotal and with limited data, they do suggest these data could help validate \nthe importance of or focus on different architectural forms, textures, and aesthetics. \n\nImplementing eye tracking in 3D-controlled virtual environments shows promise for aiding \nthe examination of observational processes. This will have relevance in multiple fields. Certainly,  eye-tracking  has  been  used  in  3D  gaming,  but  studies  in  psychology,  architecture, \nurban design, interior design, and landscape architecture could benefit from having access to \nindividual patterns of observation data. Eye tracking is a well-established technique but employing it within 3D environments and determining how to associate these data with meaningful interpretations will provide new opportunities and insights for landscape studies.  \n

Concepts and Techniques for Large-Scale Mapping \nof Urban Vegetation Using Mobile Mapping Point \nClouds and Deep Learning \n\nAbstract: In urban environments, roadside vegetation provides important ecosystem services. Reliable \nand up-to-date  information  on  urban  vegetation  is therefore  needed  as  a  basis  for  sustainable urban design and regular tasks such as vegetation maintenance. Mobile laser scanning (MLS), i. e., the use of \nvehicle-mounted laser scanners, offers strong potential for capturing 3D point clouds of road environ-\nments on a large scale at a low cost. In this paper, the potential and challenges of using MLS for vegetation mapping are discussed. To lay a foundation for MLS-based inventories of roadside vegetation, a \nconcept for the automatic detection and analysis of vegetation in MLS point clouds using deep learning \nis presented. The proposed workflow covers vegetation detection and classification, delineation of individual trees, and estimation of tree attributes. In a case study, an initial implementation of the work-flow is tested using MLS datasets from two German cities and the results are evaluated through visual \ninspection. It is demonstrated that the proposed deep-learning approach is able to detect and classify \nvegetation in MLS point clouds of complex urban road scenes. When delineating individual trees, accurate results are obtained for solitary trees and trees with little canopy overlap, while the delineation \nof trees with strongly overlapping canopies needs further improvement in some cases. The results indicate that geometric tree attributes such as tree height and trunk diameter can be accurately estimated \nfrom MLS point clouds if the accuracy of the preceding processing steps is sufficiently high. \n\nIntroduction \n\nIn urban environments, roadside vegetation provides important ecosystem services, including \nsequestering carbon, mitigating air pollution, regulating microclimate, providing habitat, and \npromoting human well-being (SÄUMEL et al. 2016). Urban trees also help mitigate the effects \nof  climate  change  through  local  cooling  and  stormwater  absorption  (PATAKI  et  al.  2021). \nTherefore, maintaining and expanding roadside vegetation is essential for sustainable urban \ndevelopment. Reliable and up-to-date information on urban vegetation is needed to guide the \ndesign of urban green spaces toward the provision of ecosystem services (ELDERBROCK et al. \n2020)  and  to  develop  appropriate  green  space  management  programs  (SCHIPPERIJN  et  al. \n2005). Many municipalities, especially in North America and Europe, therefore, conduct inventories of public green spaces. These inventories often focus on surveying individual trees, \ni. e., mapping the location of individual trees, and collecting tree attributes such as tree species, height, and trunk diameter (MA et al. 2021). Since manual vegetation inventories are\ncostly and time-consuming, the use of LiDAR systems (Light Detection and Ranging) for\nautomated or semi-automated vegetation mapping has become an important research topic.\nThese systems capture the environment in the form of high-resolution 3D point clouds and\ncan be used with various acquisition platforms. The acquisition can be categorized as terrestrial laser scanning (TLS) with tripod-mounted laser scanners, personal laser scanning (PLS) \nwith handheld or backpack-mounted laser scanners, mobile laser scanning (MLS) with vehicle-mounted laser scanners, unmanned aerial vehicle-borne laser scanning (UAV-LS), and \nairborne laser scanning (ALS). Compared to TLS, PLS, and UAV-LS, the use of vehicle-mounted laser scanners significantly reduces the acquisition effort, while providing 3D point \nclouds with higher resolution and fewer occlusions than ALS. Because of these characteristics, MLS is a well-suited technology for the large-scale mapping of roadside vegetation and \nthus could become a complement or alternative to conventional vegetation surveys. Compared to conventional field surveys, MLS-based vegetation mapping would reduce labor and \ncost, while providing a richer, three-dimensional representation of vegetation. To realize the \npotential of MLS for vegetation mapping, an automated approach is needed to derive semantic information about vegetation from raw 3D point clouds. To lay a foundation for building \nsuch a system, this paper presents a general concept for the automatic detection and analysis \nof  vegetation  in  MLS  point  clouds.  In  contrast  to  previous  work,  the  proposed  workflow \nbuilds on a modern deep-learning approach for 3D point cloud segmentation. In a case study, \nan initial implementation of the proposed workflow is tested on MLS datasets from two cities \nand first results are provided. \n\nPotential of MLS-Based Vegetation Inventory \n\nCompared to conventional field surveys, MLS-based vegetation inventories would provide \nseveral advantages: First, the labor and cost of vegetation surveys would be reduced, allowing \nlarger areas to be mapped and vegetation inventories to be updated more frequently (e. g., \nquarterly to cover all seasons). Second, capturing vegetation in the form of 3D point clouds \nwould provide additional and more detailed data on urban vegetation. For example, shrubs \nand hedges could be mapped, which are not recorded in most conventional vegetation surveys \ndespite their ecological value and aesthetic impact. Furthermore, conventional tree invento-\nries usually only capture a limited number of tree attributes (ÖSTBERG et al. 2013). Using 3D \npoint clouds, additional geometric tree attributes such as trunk orientation or crown volume \ncould be captured (HERRERO-HUERTA et al. 2018). 3D point clouds could even be used to \nmodel the entire branching structure of trees (DU et al. 2019). Overall, the data collected in \nMLS-based  vegetation inventories could be used to build  comprehensive  tree information \nmodels, as proposed by SHU et al. (2022). Such information models would address the information needs of a wide range of stakeholders, including city officials, arborists, ecologists, \nand  landscape  architects.  For  landscape  architects,  information  derived  from  MLS-based \nvegetation inventories could be particularly useful for the following applications: (1) At the \nbeginning  of  the  design  process,  more  detailed  plant  models  could  be  created  to  enable  a \nmore accurate representation and analysis of existing vegetation. While generic plant models \nhave been commonly used to visualize vegetation (OEHLKE et al. 2015), plant models derived \nfrom  3D point  clouds  could  be  used  to  create  more  realistic  visualizations  of  vegetation. \nMoreover,  plant  models  derived  from  3D  point  clouds  could  also  be  used  to  estimate  the \necosystem services and disservices provided by existing vegetation. For example, the shading \nprovided by trees could be modeled, or the carbon storage and oxygen release potential of \nvegetation could be estimated (SCHOLZ et al. 2018). (2) Conducting MLS-based vegetation \nsurveys on a regular basis could also provide ground truth data for building and validating \nsimulation models of plant growth (WHITE et al. 2022). More accurate simulation of plant \ngrowth would support decisions between different planting regimes in the design of green \nspaces. (3) Once a certain planting regime has been established, MLS could be used to continuously monitor the green space (e. g., growth and condition). In this way, design decisions \ncould be evaluated, and vegetation maintenance measures could be planned and aligned with \nthe design goals. \n\nChallenges in MLS-Based Vegetation Inventory \n\nWhile MLS offers significant potential for the large-scale mapping of roadside vegetation, \nseveral challenging data characteristics must be considered when developing systems to automatically process MLS point clouds for vegetation mapping: \n\nLarge data volume: MLS produces large amounts of data with hundreds of points per square \nmeter. To be able to process MLS point clouds of large road segments or entire city districts, \nall processing steps must be automated and implemented efficiently. This requires algorithms \nthat allow parallel processing with modern multicore systems or graphics cards. \n\nVarying point density: The point density of MLS point clouds depends on the scanner type, \nthe acquisition speed, and the distance to the scanner trajectory. Systems for processing MLS \npoint clouds must therefore be robust to varying point densities. \n\nOcclusions: In MLS point clouds, vegetation  may be completely or partially occluded by \nother objects. The algorithms for detecting and analyzing vegetation in MLS point clouds \nmust therefore be able to cope with incomplete data, i. e., 3D point clouds that cover only a \npart of the surface.  \n\nLimited per-point attributes: Most LiDAR systems provide the 3D coordinates and reflection intensity for each scanned point. More advanced systems can capture additional attributes such as surface color (e. g., from panoramic images), temperature, or humidity. To support a wide range of scanner types, however, algorithms for vegetation detection and analysis should only rely on point coordinates and reflection intensity as input attributes. \n\nIntegration of  multi-temporal MLS data: Approaches for storing and processing  multi-temporal MLS data are needed to enable continuous vegetation monitoring. Since inaccuracies  can  occur  in  the  georeferencing  of  MLS  point  clouds,  techniques  for  co-registering \n3D point  clouds  from  different  acquisition  runs  are  needed.  In  addition,  approaches  are \nneeded to increase the coverage and merge redundant information from MLS point clouds \nacquired at different times and to identify areas that have changed between acquisition runs.  \n\nA Concept for the Detection and Analysis of Vegetation in \n\nMLS Point Clouds Using Deep Learning \n\nIn the following, a concept for the automatic detection and analysis of vegetation in MLS \npoint clouds is presented. The proposed workflow is divided into three steps: (1) In the first \nstep, deep-learning models are used to extract vegetation points from raw MLS point clouds \nand classify them into different vegetation types. (2) In the second step, the tree points detected  by  a  deep-learning  model  are  segmented  into  individual  trees.  (3)  Using  the  point \nclouds of individual trees, tree attributes such as tree height and trunk diameter are derived. \n\nDetection and Classification of Vegetation \n\nBesides vegetation, urban MLS point clouds contain a variety of other objects such as city \nfurniture, vehicles, and buildings. An automated approach is required to segment 3D point \nclouds of such complex scenes into vegetation points and non-vegetation points. In addition, \ndifferent vegetation types, such as low vegetation and trees, need to be distinguished. \n\nRelated Work \n\nWhile the present work aims to detect both low vegetation and trees, most previous work has \nfocused on tree detection in MLS point clouds. To segment urban MLS point clouds into tree \npoints and non-tree points, many works use either rule-based approaches (HAO et al. 2022, \nHUI et al. 2022) or statistical machine learning approaches (WEINMANN et al. 2017, CHEN et \nal. 2019). While rule-based approaches are usually not able to detect other vegetation types \nthan trees and are often very dataset-specific, statistical machine learning approaches often \nlack the capability to combine geometric features of different spatial scales. The recent work \nof CHEN et al. (2021) is among the first to use a deep-learning approach for vegetation detection in urban MLS point clouds. However, the PointNLM architecture proposed in their work \nis trained on hand-crafted geometric features of supervoxels and does not yet exploit the full \npotential of recent deep-learning architectures for 3D point cloud segmentation. \n\nMethodology \n\nIn general, deep-learning architectures for processing 3D point clouds can be divided into \narchitectures that operate on intermediate representations of point clouds such as 2D images \nor 3D voxel grids, and architectures that process point clouds directly (BELLO et al. 2020). \nOur workflow is built upon architectures that process 3D point clouds without intermediate \nrepresentations. These architectures usually are more efficient than architectures that use intermediate representations and are designed to self-learn geometric features at different spatial scales. Recent examples of such architectures include KP-FCNN (THOMAS et al. 2019), \na fully convolutional neural network (FCNN) based on a kernel-point (KP) convolution, and \nRandLA-Net (HU et al. 2020), “an efficient and lightweight neural architecture to directly \ninfer per-point semantics for large-scale point clouds” based on random sampling (Rand) and \nlocal feature aggregation (LA). In our implementation, the KP-FCNN Rigid architecture is \nused. Different variants of this architecture exist, targeting different processing tasks such as \nclassification  or  semantic  segmentation  of  3D  point  clouds.  In  this  work,  the  detection  of \nvegetation in MLS point clouds and its classification into different vegetation types are modeled as a single semantic segmentation task. To this end, models are trained to distinguish the \nfollowing classes: \n\nLow vegetation includes all types of low vegetation, e. g., shrubs, hedges, and potted plants. \n\nTree trunk includes tree trunks, defined as the segment ranging from the base of a trunk to \nthe first branching. \n\nTree branch includes the main branches of a tree that are not covered by foliage. \n\nTree crown includes tree foliage and the branches and twigs covered by it.  \n\nOther includes all non-vegetation points, e. g., ground, buildings, and city furniture. \n\nThis classification scheme is more fine-grained than the classification schemes used in previous studies. Segmenting trees into trunk, branch, and crown areas provides additional semantic information that can be used to delineate individual trees and estimate certain tree \nattributes. However, the proposed classification scheme also requires more detailed ground \ntruth annotations to train deep-learning models, which increases the annotation effort. \n\nSince large-scale MLS point clouds usually contain millions of points, they cannot be processed as a whole by deep-learning models. Therefore, our workflow includes two preprocessing steps to prepare raw MLS point clouds for processing by deep-learning models (Figure 1). First, the resolution of the large-scale point clouds is reduced by grid subsampling. \nSubsequently, small subsections of fixed size (4 m radius, 4096 points) are sampled from the \ndownsampled large-scale point clouds. These small-scale point clouds are processed by the \ndeep-learning model. The model predictions are mapped to the large-scale point clouds and \nare interpolated for points that were not covered by the small-scale point clouds. \n\nDelineation of Individual Trees \n\nThe deep-learning approach described in the previous section performs point-wise segmentation, where each point is assigned to a semantic class. However, for points that are classified \nas tree points, the deep-learning approach does not provide information about which individual tree a point belongs to. Therefore, an additional processing step is required to segment \nthe tree points identified by a deep-learning model into individual trees. Especially in areas \nwith high tree density and overlapping tree canopies, delineating individual trees can be a \nchallenging task. \n\nRelated Work \n\nIn  previous  work,  different  algorithms  have  been  proposed  to  delineate  neighboring  trees \nwith overlapping crowns, including graph-based approaches (ZHONG et al. 2017), clustering \napproaches (LI et al. 2021), and region growing approaches (LI et al. 2016). Some of these \napproaches rely on the correct detection of tree trunks and are therefore not robust to occlusions and misclassifications of tree trunks. Additionally, many algorithms for delineating individual trees are based on voxel representations of 3D point clouds, which limits their accuracy. \n\nMethodology \n\nTo improve robustness to incomplete data and achieve more accurate segmentation of overlapping tree canopies, we propose a multi-step approach to delineate individual trees. The \nproposed approach is inspired by several previous works (WU et al. 2013, ZHONG et al. 2017, \nXU et al. 2020, YANG et al. 2020) and consists of the following steps: \n\n1)  Identification of tree locations: In the first step, the locations of individual trees are \nidentified. To improve robustness against incomplete data, tree trunks, main branches, \nas well as treetops are considered for identifying tree locations. To identify tree locations \nbased on tree trunks and main branches, trunk and branch points identified by the deep-learning approach are clustered using the DBSCAN algorithm (ESTER et al. 1996). Adjacent clusters with similar growth direction are merged and the midpoints of the remaining clusters are used as approximate tree locations. To identify tree locations based on crown tops, a 2D canopy height model is constructed and searched for local maxima. \nThe positions of local maxima whose distance from the already found tree locations is \nabove a threshold are added to the set of tree locations. \n\n2)  Coarse delineation of individual trees: The tree locations obtained in the previous step \nare used to determine the coarse boundaries of the individual trees and to identify regions \nwith overlapping tree canopies. Different algorithms can be used for this purpose, e. g., \n2D Voronoi segmentation can be performed (ZHONG et al. 2017), or a canopy height \nmodel can be constructed and segmented using the 2D marker-controlled Watershed algorithm (KORNILOV & SAFONOV 2018). For the implementation in this work, a combination of both algorithms is used. \n\n3)  Refined delineation of overlapping tree canopies: If the coarse tree delineation indicates that two trees are close to each other, their canopies may overlap. In such cases, \nthe segmentation of the tree canopy is refined. Different approaches can be used to delineate  trees  with  overlapping  canopies,  including  graph-based  approaches,  clustering \napproaches,  or  region  growing  approaches.  Our  workflow  uses  a  region  growing  approach since it reflects the natural growth direction of trees and allows the delineation of \ntrees with different shapes. Specifically, we implement a custom, density-based region \ngrowing algorithm that is inspired by the DBSCAN algorithm (ESTER et al. 1996). In \nthis algorithm, for each tree to be processed, a set of seed points is selected (i. e., points \nthat belong to the tree with a high degree of certainty). In an iterative process, neighbor \npoints of the seed points are assigned to the respective tree, if they have not yet been \nassigned to another tree. Neighbor points that satisfy the core point criterion as defined \nin the DBSCAN algorithm (ESTER et al. 1996) become seed points themselves. To ensure  that  neighboring trees  grow  evenly,  points  are  sorted according  to  their  distance \nfrom the crown boundary determined during coarse tree delineation and processed in \nthat order. \n\n4)  Removal of implausible trees: In the final processing step, trees with implausible shape \nor size are discarded. Specifically, trees with few points and trees whose height is below \na threshold are filtered out. \n\nEstimation of Tree Attributes \n\nAfter obtaining point clouds representing individual trees, different tree attributes can be estimated. Most existing studies focus on the estimation of geometric tree attributes (HERRERO-HUERTA et al. 2018, WU et al. 2013, XU et al. 2020), while few authors also derive non-geometric attributes such as tree species or vitality (WU et al. 2018, CHEN et al. 2019). Since \n3D point clouds are particularly suitable for deriving geometric tree attributes, we also focus \non these attributes. However, algorithms for estimating non-geometric tree attributes such as \ntree species, carbon storage capacity, or oxygen release potential may be integrated into the \nworkflow in the future. For the estimation of the attributes tree location (WU et al. 2013), tree \nheight, trunk direction, crown width (HERRERO-HUERTA et al. 2018), trunk diameter at breast \nheight (CHEN et al. 2019), and crown volume (LI et al. 2020), we adopt the approaches used \nin previous work. Other tree attributes, namely under-branch height, and crown base height, \ncan  directly  be  derived  from  the  deep-learning-based  segmentation  of  trees  into  trunk, \nbranches, and crown. \n\nCase Study \n\nA test application was implemented to demonstrate the potential of the concept presented in \nthis paper. MLS point clouds collected in the cities of Essen, Germany, and Hamburg, Germany, were used to evaluate the test application. The point clouds were acquired using Trimble MX8 scanners in the leaf-on season. We manually annotated the point clouds and split \nthem into a training set, a validation set, and a test set. In the following, some preliminary \nresults for the test set are shown. \n\nFigure 2 shows exemplary results of the deep-learning-based vegetation detection and clas-\nsification.  As  can  be  seen  there,  large  portions  of  the  vegetation  are  segmented  correctly. \nHowever, several smaller segmentation errors can be identified: In multiple cases, low veg-\netation and tree crowns are confused. In addition, some pole-like objects are misclassified as \ntrees. There are also a few cases in which tree trunks are missed by the deep-learning model. \n\nResults of the delineation of individual trees are shown in Figure 3. While solitary trees and \nadjacent trees with little canopy overlap are correctly delineated in most cases, the results for \nthe delineation of trees with strongly overlapping canopies are mixed. Trees whose crown \nhas a large extent are over-segmented in several cases, and some parts of tree crowns with \nlow point density are missed by the region growing algorithm. \n\nFigure 4 shows some results of the estimation of tree attributes. As can be seen there, accurate \nestimates of geometric tree attributes are obtained if the accuracy of the preceding processing \nsteps is sufficiently high. When large parts of a tree are missed during tree segmentation, \nattributes such as tree height, crown width, and crown volume are often underestimated. In \ncases where multiple trees are recognized as a single tree, the crown width and crown volume \nare often overestimated. \n\nDiscussion and Conclusion  \n\nIn this work, a concept for the automatic detection and analysis of vegetation in MLS point \nclouds has been presented. The implementation of the concept produced promising results \nfor representative MLS point clouds from two cities. However, to approach the accuracy of \nmanual vegetation mapping, the method needs to be further improved. Since the accuracy of \nvegetation detection and classification affects the accuracy of the following processing steps, \nfurther improvement of the deep-learning approach for vegetation detection and classifica-\ntion would be of major benefit. Despite this need for improvement, the preliminary results of \nthis work suggest that the proposed deep-learning approach can detect and classify vegetation \nin complex street scenes that would be difficult to model using rule-based approaches. However, this comes at a price: The training of deep-learning models requires extensive annotated \ntraining data and high computing power of graphics hardware. To improve the practicality of \nthe approach, techniques to reduce the labeling effort (e. g., active learning or transfer learning) and improve model speed (e. g., model pruning) could be incorporated into the work-\nflow. \n\nWhile  the  test  application  presented  in  this  paper  was  limited  to  capturing  geometric  tree \nattributes,  it  would  be  desirable  to  derive  even  richer  tree  information  models  to  cover  a \nbroader range of use cases. For example, detailed models of tree branching structures could \nbe derived from 3D point clouds to enable estimation of aboveground biomass and carbon \nstorage capacity, as well as realistic vegetation visualization. Furthermore, it would be useful \nto integrate approaches for processing multi-temporal MLS data into the workflow. In this \nway, point clouds representing vegetation in leaf-on and leaf-off conditions could be combined. Capturing vegetation in leaf-off conditions would avoid the occlusion of woody components by foliage and thus facilitate the acquisition of woody biomass and the delineation \nof individual trees. In addition, approaches for predicting non-geometric tree attributes such \nas tree species and tree vitality could also be integrated into the workflow, e. g., by combining \n3D point clouds with spectral data from panoramic images or aerial photographs. \n\nSince MLS is a cost-effective method to survey very large areas, the present work focused \non vegetation mapping using MLS. However, MLS is only suitable for capturing vegetation \nin the proximity of drivable roads,  while PLS or UAV-LS  are  more suitable for  mapping \nvegetation in parks or private gardens. To provide a complete mapping of urban vegetation, \nthe concept presented in this work should be transferred to other LiDAR platforms. Since \nPLS point clouds have similar characteristics to MLS point clouds and a generic deep-learning approach is used in this work, transferring the approach to PLS point clouds should be \npossible with little effort. \n\nBuilding on the concept presented in this paper, a data processing tool could be developed \nfor large-scale and cost-effective urban vegetation mapping. Such a tool would enable continuous monitoring of urban vegetation and thus provide a basis for sustainable design and \nmaintenance of urban green spaces. In particular, it would enhance the study of ecosystem \nservices provided by urban vegetation and could thus help to guide the design of urban green \nspaces towards the provision of ecosystem services. \n

Ecological Robotics \n\nAbstract: This research presents a novel method for paste-based robotic planting. Our method for robotically extruding seeds in a paste of clay and planting media enables precise, algorithmic planting. \nThis additive manufacturing process builds microtopography, while planting seeds. With this 3D printing process designers can engage with the geomorphological and ecological processes that shape landscapes. Microtopography can be designed to direct flows of water, while planting can be designed to \nfoster biodiversity, form ecotones, and control erosion. As a proof of concept, we demonstrate how \nalgorithms can generate precise planting patterns  such as pseudorandom gradients. We envision  unmanned ground vehicles with seed printing systems planting entire landscapes with algorithmic designs. \n\nIntroduction \n\nResearch on autonomous construction in architecture has explored the novel creative, material, tectonic, performative, and aesthetic potential for the computational design of the built \nenvironment (GRAMAZIO & KOHLER 2014, MENGES 2015). Similarly, the autonomous construction and planting of landscape promises unique aesthetic opportunities and new ways of \nengaging with ecology and geomorphology. Designers have experimented with robotic processes for constructing landforms such as soil 3D printing (MITTERBERGER & DERME 2019, \n2020) and autonomous excavators (JUD ET AL. 2021, HURKXKENS ET AL. 2022). Robotic processes for planting have been developed such as vacuum seeding robots (GOLDBERG 1995, \nFARMBOT 2020, PRESTEN et al. 2021), autonomous seed drilling tractors (GROß 2013), and \nseed sowing with unmanned aerial systems (MOHAN et al. 2021). While sowing seeds is an \nimprecise process with low survival rates, seed drilling is more precise and has higher survival rates, but mechanically disturbs soil, increasing the risk of soil erosion. Our paste-based \nextrusion method for autonomous planting has millimeter precision, high survival rates, does \nnot disturb soil, and creates microtopography. Potential applications include landscape architecture, land art, ecological restoration, and precision agriculture. \n\nMethods \n\nIn our method for robotic planting, seeds are extruded in a paste of clay, planting media, and \nwater (Fig. 1). As an additive manufacturing process, paste-based extrusion of seeds builds \nlandforms layer by layer. The proportions of the paste are calibrated so that it can be extruded \nsmoothly, while supporting seed germination. Clay is used for plasticity for the sake of ex-\ntrusion. Planting media is used to provide nutrition for plants, retain water, and provide pore \nspace for root growth. Water is used to wet the clay and germinate the seeds. The paste is 3D \nprinted, i. e. extruded, directly onto soil. After printing, the seeds embedded in the paste have \nthe shelter, nutrients, and moisture they need to germinate. Once the seeds have germinated, \nthe roots of the seedlings grow into the soil below. \n\nAs a proof of concept, we developed a prototype with a linear actuator ram mounted on a 6-axis robotic arm. Industrial robots are reliable, versatile systems that can easily be adapted to \nnew tasks, making them well suited for creative experimentation with novel material processes  (GRAMAZIO  & KOHLER  2014,  16).  For  this  prototype,  we  used  a  UR10e  industrial robotic arm because its 12.5 kg payload was enough for a large extruder with 2000 ml of paste and its reach of 1300 mm allowed for a large build space. Grasshopper, a visual programming environment for computational design (MCNEEL 2021), was used to generate geometry for robot path planning. The Robots ex Machina framework (GARCÍA DEL CASTILLO Y LÓPEZ 2019) was used to control the robot and extruder.  \n\nTo test this method, a series of planting patterns were robotically printed in the lab. We tested \ndesigns such as space filling curves, landforms derived from trigonometric waves, landforms \nderived from cellular texturing, landforms derived from procedural noise (Fig. 2 & Fig. 3), \nand generative typography (Fig. 4). For ease of printing and cultivation in a laboratory setting, designs were printed in growing trays and stored on racks with grow lights. Each 250 \nby 250 mm tray was filled with planting media as a substrate for the print. We used plants \nsuch as perennial ryegrass (Lolium perenne), annual ryegrass (Lolium multiflorum), arugula \n(Eruca vesicaria), radish (Raphanus sativus), alfalfa (Medicago sativa), Siberian kale (Brassica napus) and broccoli (Brassica oleracea var. italica). For the landforms, the extruder was \nfilled with layers of different seeds to create an elevation gradient of species. Over the course \nof the study, the prints were photographed daily to record the growth of the plants. \n\nResults \n\nThe planting designs printed cleanly and precisely as the crisp letterforms in Figure 4 demonstrate. Plants grew most healthily and vigorously in prints that were 5 or 10 mm tall, composed of 1 or 2 layers, because the seedlings’ roots had easier access to the porous, nutrient rich substrate of planting  media below. Furthermore, plants grew  more vigorously in narrower forms with widths of 20-40 mm because this ensured that seedlings had less competition and more access to sunlight and substrate. While paste-based extrusion of seeds creates microtopography, the scale of appropriate landforms is highly constrained by growing conditions.  \n\nFuture Work \n\nTo further this research, we are investigating alternative media for the paste, testing different \ntypes of extruders, integrating sensors into the system, and integrating the system onto an \nunmanned ground vehicle for landscape-scale planting (Fig. 5). We are testing pastes composed of biochar that release nutrients slowly and biopolymers that biodegrade rapidly. We are integrating moisture sensors, depth sensing, lidar scanners, and multispectral imaging for adaptive planting and monitoring. Using these sensors, we plan to conduct experiments with controls, replicates, and quantitative measures to assess the efficacy of this method with different pastes. To plant at landscape-scale, we plan to integrate the robot arm, extruder, and sensors onto an unmanned ground vehicle with real-time kinematic positioning. We plan to \nuse lidar, positional data, and simultaneous localization and mapping algorithms for autonomous navigation and for positioning the extruder relative to the ground in real time. For field \ntrials, we will use lidar and multispectral imaging on unmanned ground and aerial vehicles \nto conduct repeated surveys at high spatial and temporal resolution to assess plant growth.  \n\nConclusion \n\nWith paste-based robotic planting, computational designs for planting patterns can be autonomously seeded with high precision. While this experiment was conducted in the lab, robotic \nplanting could be done at scale in the field with unmanned ground vehicles. With generative \ndesign enacted by field robots, landscape architects would be able to design dynamic landscapes as ongoing performances – as ecological processes guided by design interventions. \nUnmanned aerial systems could  collect imagery and elevation datasets at high spatial and \ntemporal resolution that could inform the ongoing design and management of landscapes. As \nunmanned aerial systems monitor how landscapes evolve, unmanned ground vehicles could \nadaptively plant and replant in response, catalyzing new assemblages of plants and wildlife. \nWe hypothesize that algorithmic planting based on ecological principles could foster spatial \nheterogeneity, complexity, and thus biodiversity. We envision field robotics giving rise to an \nalgorithmic aesthetic of ecology.  \n\nNew media scholar Laura Marks describes algorithmic aesthetics as a semiotic process of \nenfolding and unfolding, a process in which infinite possibility is transcribed into information \nand then image (MARKS 2010). This is a performative aesthetics of infinity and contingency \n– an aesthetics that explores what is revealed and what is hidden; an aesthetic in which creativity is a  means of discovering the infinite. Design projects like  GRAMAZIO KOHLER Research’s  Endless  Wall  (2011),  SNØHETTA’S  MAX  IV  Laboratory  Landscape  (2016),  and \nMAEID’S Magic Queen (2021) evoke such an algorithmic aesthetic. With systems for precise \nautonomous planting, landscape architects would have the means to express ecological complexity  and  contingency  with  a  visibly  algorithmic  logic.  Computational  design  processes \nsuch as procedural noise, cellular noise, and fractional Brownian motion (Figures 2, 3 & 6) \ncould be used to generate planting patterns  with high spatial heterogeneity and ecological \ngradients  between  drifts.  Such  computationally  designed  planting  would  simultaneously \nevoke the accidental and intentional, the actual and virtual. \n

Expanding Digital Design Workflows with Geospatial \nAnalytics: Linking Grasshopper3D with Google \nEarth Engine \n\nAbstract:  The  following  body  of  work  introduces  a  plugin  that  links  the  visual  scripting  language \nGrasshopper3D (GH) to the Google Earth Engine (GEE) in order to easily fetch geospatial information \nrelative to various societal issues and for any geographical area under study, inside the Rhino modelling \nsoftware.  \nAiming  at  expanding the  field  of  Digital  Landscape  Architecture with  novel  content to  analyse  and \ndesign, it provides designers with more than thirty years of historical imagery and scientific datasets, \ncollected in GEE on a daily basis by several institutions around the world. Leveraging the intuitiveness \nof the visual scripting language, it computationally empowers designers with geospatial insights with-\nout the need for any GIS skills and has been proved a successful platform for teaching purposes. Encouraging learning through application, the paper discusses three teaching experiences, which adopted \nthe proposed tool to visualise river dynamics in time, resource-specific maps of land consumption for \ncities and street-sensitive accessibility maps through the additional integration of OpenStreetMap data. \n\nIntroduction \n\nDuring the last three decades, a constellation of computational applications has emerged that \nempowers architects and designers to respond to the challenges of the  AEC and planning \nsectors through highly technological and innovative means. Active since late 2007, the Rhinoceros’s visual programming language: Grasshopper3D (GH), has been proved to be among \nthe most successful examples of this kind. It has offered a visually-intuitive medium to teach \nand compute advanced computational pipeline without writing one line of code, and has become an asset for both the academic and the industrial realms (CASTELO-BRANCO & LEITÃO \n202). Additionally, whether to simulate microclimatic conditions (MACKEY et al.. 2017), calculate structural performances (PREISINGER & MORITZ 2014), or work with georeferenced \ndata (DOGAN et al. 2018) to name a few, over the years GH has collected an extensive amount \nof plugins, developed by an active community of computational designers, to expand its influence in many aspects of the design process and in relationship to the many actors involved. \nFinally, by reshaping the traditional drawing tools through mathematics and functions, it has \nprovided designers with novel ideas to design while deeply influencing all scales of the project, from Digital Fabrication to Digital Landscape Architecture. Placed within this line of \ninvestigation,  the  following  body  of  work  introduces  a  plugin  that  links  Grasshopper  to \nGoogle Earth Engine to instantly fetch selected geospatial layers for any geographical area \nof interest. In this sense, it enables designers to access spatial insights related to more than \nthirty  years  of  remote  sensing  data,  collected  by  a  plethora  of  satellites  and  processed  by \nresearch institutions from all over the world. Answering to the call for data democratization \nwhile rendering large-scale computing accessible to non-experts, the Google Earth Engine \n(GEE)  is  a  “cloud-based  platform  for  planetary-scale  geospatial  analysis  [that  seamlessly \ngives to] not only traditional remote sensing scientists, but also a much wider audience, [access to many] societal issues including deforestation, drought, disaster, disease, food security, \nwater management, climate monitoring and environmental protection” (GORELIK et al. 2017). \nFor this reason, GEE is built around a petabytes-large catalogue of georeferenced data and \nan Application Programming Interface (API) to access and process server-side the same layers; achieving in this manner high speed performances and becoming suitable not only for \nglobal-scale  calculation  processes,  but  also  for  more  explorative  and  experimental  approaches, common in design processes.  \n\nThe Toolkit \n\nAs an entry point for designers to explore geospatial analytics through Google Earth Engine, \nthe toolkit proposed consists mainly of five GH components to import, spatialize, process \nand calculate geospatial raster layers through the Earth Engine API Python library1 and via \nHops. Being a recent development in the Grasshopper3D suite, Hops is the first package to \nefficiently link the visual scripting tool to the real potentialities of the Python programming \nlanguage.  By  externally  running  CPython  code  via  a  Flask  application,  it  allows  Python \nscripts to be implemented in GH unconstrained by the limitations of predefined libraries and \nopen to the vastness of community-driven packages available online.  \n\nBeing one of these contributions, the Earth Engine API is the official Python client library to \ndynamically access GEE. Used within the tailored Flask application, it runs requests from \nthe inputs in GH to the online GEE server and consequently fetches the required information. \nMore precisely, the discussed custom components to connect GH to GEE are: \n\n1)  ee_image: it permits the download of images from GEE for any geographical area of \n\ninterest and functions as the primary component to explore GEE. \n\n2)  ee_imageColl: it enables to work with the more advanced imageCollection typology and, \ncompared to the ee_image, requires extra information in respect to the date, or permitted \ncloud coverage to consequently extract images. \n\n3)  ee_ND: it engages with GEE to create normalised difference indicators on the server side \nby providing multiple bands to work with, and functions as an entry point to the world \nof remote sensing indicators \n\n4)  ee_cumCost: it calculates cumulative cost analysis, which are commonly used to spatialize accessibility, provided a cost to travel over a territory and an initial set of origins \n\n5)  reproject_UTM: an utility component to manage coordinate reference systems and align data fetched from GEE with the outputs of other plugins for GIS operations \n\nThe requirements to use the aforementioned components are kept very concise and focus on \nproviding the maximum flexibility with the minimum amount of inputs, and always comprises: an area of interest to download the image from, a resolution -in metres- to balance the amount of information to be downloaded, and the layer, with respective bands, that we are interested in accessing. Additionally, more inputs can be requested to calibrate the functions of the specific components, like in the case of the ee_ND that requires more than one band to reciprocally subtract, or the ee_cumCost which requires locations of origin for the accessibility analysis to be calculated from. This being said, the toolkit automatizes a series of spatial operations common in Geographical Information Systems (GIS) to deal with raster layers, \nlike is the case of resampling operations to obtain custom resolutions, or mathematical operations to calculate remote sensing indicators. It is important to notice that it does so in the \nbackground, opening up possibilities for the users to interact with the tool only through specifically opinionated inputs in order to facilitate its generic usability and versatility. In this \nsense, the tool aims at providing a simplified pipeline for computational designers to investigate  the  immensity  of  the  Google  Earth  Engine  database  for  design  purposes  through  a \nscarce set of inputs, allowing them to obtain material for further analysis and manipulations \nwith conventional processes – through standard components in Grasshopper3D – in a fast, \nand interactive fashion and without the need to be GIS experts.  \n\nFinally, the open source nature of the tool – a Python Flask application – permits an in-depth \ncustomization of each component – if equipped with enough knowledge of the Python programming language – and it has been proved to be a fruitful case to learn and apply computational logics in a pedagogical sense. It balances levels of complexity  when approaching GIS  processes  through  visual  programming  while  maintaining  the  possibility  to  read  and study the back-end codes when necessary. \n\nLearning Through Application \n\nThrough  one  year  of  teaching  experience,  the  proposed  plugin  has  been  tested  on  several \noccasions and has been proved to be versatile enough for different case studies, enhancing in \na broad sense the toolset that designers possess when approaching a territorial project – for \nvisualisation or analytical purposes – and not focusing on highly specific outputs. In the following section, the paper discusses three such occasions where the methodology has been \nshared with students to analyse river patterns in time, resource-specific maps of land consumption for cities, and street-sensitive accessibility maps through the integration of Open-StreetMap data relative to high resolution street networks.  \n\nMore precisely, the case studies hereby collected are the results of the Geomining lecture for \nthe Master in Landscape Urbanism at the Architectural Association School of Architecture \nin London, the Earthy Indexes workshop at the CAADRIA conference 2022\/23, and the one-week Urban Analytics workshop for the IAAC Global Summer School 2022. \n\nAnalysing River Patterns in Time \n\nThe analysis of river patterns in time is an important tool for understanding the dynamics of \nriver systems and the impacts of natural and human-induced changes on these systems. Used \nto inform a wide range of decisions related to the management and protection of river systems \nand the resources they provide, such as flood risk assessment, water resource management, \nenvironmental impact assessment, and land use planning, it is a fundamental asset for Landscape Architecture, which usually requires tedious data research and modelling.  \n\nUnequipped with a specific plugin, these studies are commonly carried out in GH through \nad-hoc scripting via iterative logics, such as for river meandering and oxbow lake simulation2 \nor water runoff studies which can be used as support material. Despite being excellent case \nstudies to teach iterative logics and loops (i. e. using the Anemone plugin3), they often fail to \nreach a high level of  specificity and end  up in the realm of design exercises compared to \nterritorial studies: fruitful to inspire design processes but insufficient for serious analytical \npurposes.  \n\nOn the other hand, there are several methodologies that can be used to map river dynamics \nin time using GIS, including time-enabled data, dynamic modelling and finally time series \nanalysis. Despite being able to provide highly specific and precise assessment of river dynamics, studies via time-enabled data or computational models are generally expensive or \ndemanding to implement due to the requirements of on-site equipment or highly trained professionals to set up and run hydrologic models. On the contrary, remote sensing has been \nwidely used in the analysis of river patterns in time over the past few decades as it allows for \nthe collection of large amounts of data over a broad area in a relatively short period of time; \npermitting a wide range of spatial and temporal scales to be included in a interoperable medium for the experts of the field to disseminate the results of their research. \n\nIn this sense, the JRC Global Surface Water mapping layer4 offers an unprecedented synthetic image of more than 4 million scans from Landsat 5, 7, and 8 to describe in high-resolution  the long-term changes  happening in river  systems  from early 1984 until the end of \n2021. Hosted in GEE as a multi-band 30m resolution image, it can be easily queried via the \nproposed ee_image component to visualise for any area of interest the patterns of extension, \nseasonality and recurrence of water to name a few. These layers precisely have been class \nmaterial during the Geomining lecture at the Architectural Association School of Architecture where participants drew a synthetic line-map of temporal river dynamics (Figure 1) almost-instantly and without geographical restraints. Taking advantage of the extensive repre-\nsentational possibilities of GH and adopting colour, angle and length as parameters, the map \nreported not only where it is possible to find water resources, but also their permanent loss \nand yearly frequencies, thus providing a wider understanding of the ephemerality of water \ncompared to a standard layer by layer visualisation. Additionally, and only thanks to the implemented pipeline, no particular download was required to compute the analysis. Avoiding \nto redundantly download entire databases by running area-specific queries in GEE is far more \nthan secondary as it prevents common issues concerning not only memory availability but \nalso computational power and computing times on the designer’s machine. \n\nMaps of City Consumption \n\nThe majority of people in the world live in cities, which currently only take up 3% of the \nEarth's surface but have transformed 70% of the planet through human activities (CIESIN \n2016). In this sense, cities around the world are interconnected and constantly exchanging \nresources, but the traditional link between places of consumption and places of extraction \nthat was once vital for a city's prosperity has been disrupted. As geographical proximity became less important for urban success, the environmental impact of this shift was overlooked, \ncontributing to the unsustainable nature of modern society, particularly due to the physical \nseparation of consumption and resource extraction. \n\nAiming to shorten the awareness gap that current planetary urbanisation has produced, the \nEarthy Indexes workshop held by the author and Erzë Dinarama at the CAADRIA conference \n2022\/23 presented a computational methodology – strongly supported by the discussed pipeline – to engage with the concept of ecological footprint at the city scale. More specifically, \nit challenged participants to crossread resource-specific demands of agricultural, pasture or \nforest land with context-specific land availability and land accessibility; finally envisioning \nup to which extension a city would consume if operating only by proximity logics (Figure \n2).  \n\nIn line with another study on Spatialized Metropolitan Ecological Footprints (Neri 2021), \nthe analysis computes pro-city land consumption values to fulfil the annual demand of a selected resource for its entire population and consequently queries exact amounts of land, filtered and ranked by its infrastructural accessibility. It exploits mainly two data layers: the \nGlobCover 20095 for a 300 m resolution global land cover map, and the Oxford’s Global \nFriction Surface 20196 layer to feed a territorial road-sensitive cumulative cost analysis via \nthe ee_cumCost component. More specifically, the latter offers a map where every pixel is \ngiven a speed to travel based on the local road infrastructure at approximately 900 m scale \nand based on a combination of national and global (OSM) data. \n\nFig. 2:  Ecological footprint studies for coffee, beef and wood, for the city of Barcelona as \npart of the Earthy indexes workshop led by Erzë Dinarama and Iacopo Neri at the \nCAADRIA 2022 – Post Carbon conference  \n\nBridging statistical data (e. g., demography and land consumption values) with geographical \ndata (e. g., land use and accessibility maps), this approach offers a fruitful pedagogical platform to engage with territorial indexes, while discussing the role of critical cartography in \nsupport of sustainability-related studies.  \n\nUrban Accessibility Maps \n\nFinally, the proposed pipeline has been adopted to study micro-scale mobility patterns. Reflecting on the aforementioned Oxford Global Friction Surface layer, the ee_cumCost component offers the possibility to alternatively use an ad-hoc friction layer to run cumulative \ncost analysis, therefore, exploiting GEE only for computing purposes and not for data collection. Again, OSM data provides a valuable medium to fulfil this goal, and can be easily accessed in GH via many workflows (i. e. Urbano7, Gismo 8) and geographically aligned with \nthe proposed pipeline via the utility reproject_UTM component. Technically, the cumulative \ncost component welcomes any sort of curve-based geometry to paint an image on the GEE \nserver with custom values and for any provided resolution, permitting the modelling of district-scale isochrone studies unlimited by the coarser standard friction layers of GEE (Figure 3).  \n\nThis was the subject of the one-week Urban Analytics remote workshop for the IAAC 2022 \nsummer school led by the author together with Eugenio Bettucchim, where the international \naudience of participants mapped for their home-towns a series of accessibility maps to various amenities and public services, collectively discussing by comparison the manifold forms \nof the x-minutes city. \n\nOther scholars have been using OSM data to create intuitive pipelines for accessibility studies \nvia network graph (Geoff 2020). Despite being widely used in mobility studies as an excellent \nmedium to represent complex relationships between the different elements of a street network \n(i. e. intersections, roads, and traffic flow), graph modelling requires extensive cleaning operations in its set up phase, which – for a crowd-sourced and in-development database such as OpenStreetMap – may disincentive non-expert users in comfortably interact with the algorithm. Trading specificity over usability, the proposed pipeline suggests a raster based approach  to  model  street-sensitive  accessibility  maps,  solving  the  incongruencies  within  the \nOSM network with a choice of pixel-resolution. \n\nConclusion and Outlook \n\nIn conclusion, the Grasshopper3D addon discussed in this text allows designers to access and \nutilise geospatial data from the Google Earth Engine platform in their design process. The \nplugin consists of five components that import and process geospatial data through the Earth \nEngine  API  Python  library  and  Hops.  The  Earth  Engine  API  is  the  official  Python  client \nlibrary for accessing GEE and is used within a tailored Flask application to fetch the required \ninformation in response to inputs from the GH components. These components allow designers to explore and use GEE data, specifically imagerial data, for various purposes and scales: \nfrom digital fabrication to digital Landscape Architecture, and integrating it with more traditional computational pipelines. \n\nAs proved through one year of teaching experience, this plugin represents a valuable tool for \ndesigners seeking to use geospatial data in their work and expands the capabilities of GH by \nlinking it to GEE's extensive data catalogue and powerful processing capabilities. \n\nFurther steps can be taken to extend the plugin with GEE’s Machine Learning algorithms \nlike the ones used for classification, clustering, regression or feature extraction, to name a \nfew. Related to a higher level of expertise, these algorithms allow to reproduce at will many of the pre-processed layers of GEE, which might be used to accomplish adhoc or higher resolution maps, similarly to the example of the district-scale isochrone studies via externally \nfetched OSM data, as well as to include design inputs in the forecast of their impacts. \n

As we move forward in the 21st century, the world is facing unprecedented global changes \nthat require a new approach to landscape architecture. Resilience has become a crucial factor \nin designing and man-aging our landscapes in response to natural and man-made hazards, \nsuch as climate change, urbanization, and environmental degradation. Therefore, the theme \nof this issue of the Journal of Digital Landscape Architecture, “Future Resilient Landscapes”, \nis timely and relevant. The term “Resilient Landscape” refers to a landscape that can withstand and recover from shocks and stresses caused by  various hazards, including extreme \nweather events, sea level rise, and biodiversity loss. Achieving resilience requires an integrated approach that considers ecological, social, and economic factors and leverages tech-\nnology and innovation. This issue of the journal features a range of articles that showcase \nhow digital tools and techniques can contribute to building resilient landscapes. The articles \ncover various topics related to resilience, including global change and hazard response, landscape and building information modeling, geodesign approaches, digital technologies, and \nrelated case studies. The use of UAV imagery and remote sensing in landscape architecture \nis explored in detail, along with the role of mobile devices, the internet-of-things, and ‘smart’ \nsystems in landscape architecture. Algorithmic design and analysis of landscapes, visualization, animation, and mixed reality landscapes are also dis-cussed. Finally, the issue examines \nthe role of digital fabrication in landscape architecture and how to teach digital landscape \narchitecture in academia and professional practice. In conclusion, this issue of the Journal of \nDigital Landscape Architecture provides a comprehensive overview of the current state of \nresearch and practice in the field of resilient landscapes. We hope that the articles will inspire \nand inform landscape architects, planners, and researchers to adopt a more integrated, col-\nlaborative, and innovative approach to building a sustainable and resilient future. We thank \nall the authors, reviewers, and editors who have contributed to this issue and made it possible. \n\nIf you’ve managed to read this far, then we’re lucky. Didn’t you get the feeling that the lyrics \nseemed somehow interchangeable, terribly generic and oddly impersonal? Did you perhaps \nthink something like “what in the world happened to this guy (the author), wasn’t he writing \nmore reflectively and engagedly before”? Well, then you are spot on. The above part of the \nforeword was written by a chatbot, built on top of large language models, fine-tuned using \nboth supervised and reinforcement learning techniques. Any simpleton can use this relatively \nnew breed of AI technology to generate endless texts while leaning back and staring at the \nscreen of their mobile phone themselves, following, for example, the latest news from the \nNorwegian Flat Earth Society. Or watching cat videos. Or consuming some other compara-\ntively important thing. Great, isn’t it? Now, right now, we have arrived in the digital age. Not \nquite as exciting as we might have thought. Recently, when an exhilarated and nervous young \ninterviewer  asked  the  famous,  now  95-year-old  Noam  Chomsky,  whether  software  like \nChatGPT would replace people’s language learning in the future, for example French, Chomsky twisted the corner of his mouth for a tenth of a second. Then he muttered something like, \n“Don’t worry about it too much”. Anything new is eyed anxiously until it goes out of fashion, \nbecomes commonplace, and then is forgotten. Yes, AI will be-come big, but no, DALL-E \nand the other applications will not put the landscape architect out of work. Let’s be happy \n\nand also a little proud that the DLA conference has been ploughing the field of digital landscape architecture  for  well over 20 years  without getting obsolete or out of fashion. Such \nstamina is the only way to prevent flat hype and create what is called substantial progress. \nProgress is happening slowly but steadily, and each year a new tenuous layer of research and \napplication is laid over the substance that has been worked out so far. Finally, back to the \nmain theme of the conference. Creating or preserving resilient or even sustainable landscapes \nis a noble goal and an important task. We don’t know anything with certainty, but we are \nrather sure that this task cannot be mastered without digital technology and methodology. \nThank you all for working diligently on this expedient challenge. \n\nJörg Rekittke, DLA Veteran \nNorwegian University of Life Sciences (NMBU) \n

Preface \n\nA network of engaged individuals teaching new information technologies at the International \nMaster of Landscape Architecture program MLA at Anhalt University established the annual \nConference on Digital Landscape Architecture DLA at our school in 1999. The DLA has to \ndate been held in Istanbul, Malta, Zurich, Munich, Aschersleben, twice in Boston, and frequently on our local campuses in Bernburg, Dessau and Köthen. In 2020 and 2022; the DLA \nwas hosted by Harvard University. Harvard  was able to organize the DLA 2022 as a full \nhybrid conference when the Pandemic still limited traveling. The Journal Digital Landscape \nArchitecture JoDLA which we have developed for the conference is listed in the international \ncitation database Scopus. This publication is supported academically by eighty reviewers and \nboard members. Here, we wish to thank them all for their committed long-term support.  \n\nHaving 64 papers (from more than 20 countries) which successfully meet the standards of \nthe review process coordinated by the founder of DLA, Prof. Erich Buhmann, and his editorial team once again guarantees a very substantial conference. \n\nThe 24th international conference on digital landscape architecture is now back at our internationally known campus in Dessau. Prof. Dr. Matthias Pietsch, this year's local host, is also \norganizing DLA 2023 as a hybrid conference in collaboration with Prof. Dr. Nicole Uhrig \nand Prof. Trevor Sears. Even now having more than two years of experience in organizing \nvirtual lectures and conferences, meeting all the additional needs for an international conference in a hybrid format is still a challenge and requires many university resources. We are \nvery thankful for the team spirit of so many colleagues at Anhalt University, and to the board \nmembers of the DLA for their support once again. \n\nThis  year’s  main  theme  “Future  Resilient  Landscapes”  is  a  core  issue  in  several  research \nefforts of Anhalt University. Our keynote speakers will widen our view on the challenges \nenvironmental design faces in coping with global change. \n\nAs we are able to work with a digital twin of our globe, we can focus on how to use the tools \nof digital landscape architecture in order to meet the challenges of global warming. \n\nAll positively reviewed papers are available as open access papers at Wichmann publisher \nand the outcome of the conference will be published DLA 2023 in Dessau at https:\/\/www.dla-\nconference.com\/ as in the past. \n\nWe are looking forward to welcoming many of you again in person in Dessau in 2023 and \nhopefully in the following years as well. At the same time, we looking forward to seeing the \nmany participants  who for a variety of reasons  will be virtually attending the 24th Digital \nLandscape Architecture Conference. \n\nKöthen, March 15, 2023 \n\nProf. Dr. Jörg Bagdahn, President Hochschule Anhalt \/ Anhalt University \n\nIntroduction \n\nThe cover of the eighth issue of the Journal of Digital Landscape Architecture JoDLA 8-2023 \nshows imagery, captured using a drone, of the city of Bad Neuenahr-Ahrweiler in Germany, \na region which was severely impacted by a flood disaster in 2021. Showing damage caused \nby severe floods or extreme fires is one of the many ways digital landscape architecture can \ncontribute to Hazard Management, one of the issues of resilient landscape architecture. However, our profession would much prefer to use landscape modelling to prevent some of these \ndisasters. This issue of JoDLA presents the current capacity our profession has for doing so. \n\nAfter being listed in Scopus, the journal is now also listed in DOAJ (Directory of Open Access Journals). Wichmann publisher has made accessible the JoDLA, and its forerunner publication Digital Landscape Architecture, as open access papers since 2013 and therefore provides ten years documentation of research in the area of Digital Landscape Architecture. \n\nThe  DLA  2023  is  organized  by  the  next  generation  of  professors  at  Anhalt  University  in \nDessau, Germany, where the Digital Landscape Architecture – Con was founded.  \n\nProf.  Dr.  Matthias  Pietsch,  the  local  chair  of  the  2023  DLA,  suggested,  after  the  COVID \npandemic, to focus on the issues of our endangered landscape by calling the main theme for \nthis year’s conference and of the JoDLA 2023 Future Resilient Landscapes. \n\nIn addition to the main theme, we have provided a number of other possible areas for submitting papers on current research or outstanding practice in digital landscape architecture. \nWe received 98 extended abstracts and can now present the result of a rigid two-phase double-blind review process. \n\nThe eighth issue of the Journal of Digital Landscape Architecture 8-2023 covers 66 contributions on the following seven current areas of research and prototype applications in digital \nlandscape architecture: \n•  Resilient Landscape, Global Change and Hazard Response  \n•  Landscape and Building Information Modeling (LIM + BIM) and other Standardizations in Digital Landscape Architecture  \n•  Algorithmic Design and Analysis Landscapes  \n•  Geodesign Approaches, Technologies, and Case Studies  \n•  UAV Imagery and Remote Sensing and Digital Fabrication in Landscape Architecture  \n•  Visualization, Animation and Mixed Reality Landscapes (VR, AR)  \n•  Teaching and Hybridization in Digital Landscape Architecture \n\nWe are very pleased that the worldwide academic community continues to grow in spite of \ncontinuing crises. The accepted abstracts come from seventeen countries:  \n\ntwenty-eight entries from the United States, fourteen from Germany, ten from China, five \nentries each from Turkey, four from Canada, three each from Hungary, Italy and Switzerland, \nand two each from Australia, Finland, Indonesia, Netherlands, Norway, and Spain. \n\nAnd from the following countries one entry each was accepted: Brazil, Georgia, and Singapore. We are very happy to have authors from countries that have contributed in the past, as \nwell as those who contributed for the first time. \n\n\nWe hope you will appreciate the eighth edition. The printed copies will be sent out on request \nto all participants before the conference at the end of May 2023. \nYou  will find all the contributions online as open access publications at the  gis.Point and \ngis.Open platforms of Wichmann http:\/\/gispoint.de\/jodla.html. \n\nWe would also like to invite you to the next DLA conference. The 25th international conference on information technology in landscape architecture, Digital  Landscape  Architecture \nDLA 2024 with the main theme “New Trajectories in Computational Urban Landscapes and \nEcology”, will be held from June 5 to 7, 2024 at the Vienna University of Technology, Austria. \n\nThe Journal of Digital Landscape Architecture invites you to submit ideas for special issues \nand topics. Please follow our continuously updated announcements and call for papers and \nposters at www.dla-conference.com. Here you will also find the complete online documentation of the DLA beginning from the year 2013. For earlier contributions of DLA publications, you may ask our JoDLA office. \n\nErich Buhmann, Stephen Ervin, Pia Fricker, Sigrid Hehl-Lange, James Palmer, \nand Matthias Pietsch \n\nAs we move forward in the 21st century, the world is facing unprecedented global changes \nthat require a new approach to landscape architecture. Resilience has become a crucial factor \nin designing and man-aging our landscapes in response to natural and man-made hazards, \nsuch as climate change, urbanization, and environmental degradation. Therefore, the theme \nof this issue of the Journal of Digital Landscape Architecture, “Future Resilient Landscapes”, \nis timely and relevant. The term “Resilient Landscape” refers to a landscape that can withstand and recover from shocks and stresses caused by  various hazards, including extreme \nweather events, sea level rise, and biodiversity loss. Achieving resilience requires an integrated approach that considers ecological, social, and economic factors and leverages tech-\nnology and innovation. This issue of the journal features a range of articles that showcase \nhow digital tools and techniques can contribute to building resilient landscapes. The articles \ncover various topics related to resilience, including global change and hazard response, landscape and building information modeling, geodesign approaches, digital technologies, and \nrelated case studies. The use of UAV imagery and remote sensing in landscape architecture \nis explored in detail, along with the role of mobile devices, the internet-of-things, and ‘smart’ \nsystems in landscape architecture. Algorithmic design and analysis of landscapes, visualization, animation, and mixed reality landscapes are also dis-cussed. Finally, the issue examines \nthe role of digital fabrication in landscape architecture and how to teach digital landscape \narchitecture in academia and professional practice. In conclusion, this issue of the Journal of \nDigital Landscape Architecture provides a comprehensive overview of the current state of \nresearch and practice in the field of resilient landscapes. We hope that the articles will inspire \nand inform landscape architects, planners, and researchers to adopt a more integrated, col-\nlaborative, and innovative approach to building a sustainable and resilient future. We thank \nall the authors, reviewers, and editors who have contributed to this issue and made it possible. \n\nIf you’ve managed to read this far, then we’re lucky. Didn’t you get the feeling that the lyrics \nseemed somehow interchangeable, terribly generic and oddly impersonal? Did you perhaps \nthink something like “what in the world happened to this guy (the author), wasn’t he writing \nmore reflectively and engagedly before”? Well, then you are spot on. The above part of the \nforeword was written by a chatbot, built on top of large language models, fine-tuned using \nboth supervised and reinforcement learning techniques. Any simpleton can use this relatively \nnew breed of AI technology to generate endless texts while leaning back and staring at the \nscreen of their mobile phone themselves, following, for example, the latest news from the \nNorwegian Flat Earth Society. Or watching cat videos. Or consuming some other compara-\ntively important thing. Great, isn’t it? Now, right now, we have arrived in the digital age. Not \nquite as exciting as we might have thought. Recently, when an exhilarated and nervous young \ninterviewer  asked  the  famous,  now  95-year-old  Noam  Chomsky,  whether  software  like \nChatGPT would replace people’s language learning in the future, for example French, Chomsky twisted the corner of his mouth for a tenth of a second. Then he muttered something like, \n“Don’t worry about it too much”. Anything new is eyed anxiously until it goes out of fashion, \nbecomes commonplace, and then is forgotten. Yes, AI will be-come big, but no, DALL-E \nand the other applications will not put the landscape architect out of work. Let’s be happy \n\nand also a little proud that the DLA conference has been ploughing the field of digital landscape architecture  for  well over 20 years  without getting obsolete or out of fashion. Such \nstamina is the only way to prevent flat hype and create what is called substantial progress. \nProgress is happening slowly but steadily, and each year a new tenuous layer of research and \napplication is laid over the substance that has been worked out so far. Finally, back to the \nmain theme of the conference. Creating or preserving resilient or even sustainable landscapes \nis a noble goal and an important task. We don’t know anything with certainty, but we are \nrather sure that this task cannot be mastered without digital technology and methodology. \nThank you all for working diligently on this expedient challenge. \n\nJörg Rekittke, DLA Veteran \nNorwegian University of Life Sciences (NMBU) \n\nConcepts and Techniques for Large-Scale Mapping \nof Urban Vegetation Using Mobile Mapping Point \nClouds and Deep Learning \n\nAbstract: In urban environments, roadside vegetation provides important ecosystem services. Reliable \nand up-to-date  information  on  urban  vegetation  is therefore  needed  as  a  basis  for  sustainable urban design and regular tasks such as vegetation maintenance. Mobile laser scanning (MLS), i. e., the use of \nvehicle-mounted laser scanners, offers strong potential for capturing 3D point clouds of road environ-\nments on a large scale at a low cost. In this paper, the potential and challenges of using MLS for vegetation mapping are discussed. To lay a foundation for MLS-based inventories of roadside vegetation, a \nconcept for the automatic detection and analysis of vegetation in MLS point clouds using deep learning \nis presented. The proposed workflow covers vegetation detection and classification, delineation of individual trees, and estimation of tree attributes. In a case study, an initial implementation of the work-flow is tested using MLS datasets from two German cities and the results are evaluated through visual \ninspection. It is demonstrated that the proposed deep-learning approach is able to detect and classify \nvegetation in MLS point clouds of complex urban road scenes. When delineating individual trees, accurate results are obtained for solitary trees and trees with little canopy overlap, while the delineation \nof trees with strongly overlapping canopies needs further improvement in some cases. The results indicate that geometric tree attributes such as tree height and trunk diameter can be accurately estimated \nfrom MLS point clouds if the accuracy of the preceding processing steps is sufficiently high. \n\nIntroduction \n\nIn urban environments, roadside vegetation provides important ecosystem services, including \nsequestering carbon, mitigating air pollution, regulating microclimate, providing habitat, and \npromoting human well-being (SÄUMEL et al. 2016). Urban trees also help mitigate the effects \nof  climate  change  through  local  cooling  and  stormwater  absorption  (PATAKI  et  al.  2021). \nTherefore, maintaining and expanding roadside vegetation is essential for sustainable urban \ndevelopment. Reliable and up-to-date information on urban vegetation is needed to guide the \ndesign of urban green spaces toward the provision of ecosystem services (ELDERBROCK et al. \n2020)  and  to  develop  appropriate  green  space  management  programs  (SCHIPPERIJN  et  al. \n2005). Many municipalities, especially in North America and Europe, therefore, conduct inventories of public green spaces. These inventories often focus on surveying individual trees, \ni. e., mapping the location of individual trees, and collecting tree attributes such as tree species, height, and trunk diameter (MA et al. 2021). Since manual vegetation inventories are\ncostly and time-consuming, the use of LiDAR systems (Light Detection and Ranging) for\nautomated or semi-automated vegetation mapping has become an important research topic.\nThese systems capture the environment in the form of high-resolution 3D point clouds and\ncan be used with various acquisition platforms. The acquisition can be categorized as terrestrial laser scanning (TLS) with tripod-mounted laser scanners, personal laser scanning (PLS) \nwith handheld or backpack-mounted laser scanners, mobile laser scanning (MLS) with vehicle-mounted laser scanners, unmanned aerial vehicle-borne laser scanning (UAV-LS), and \nairborne laser scanning (ALS). Compared to TLS, PLS, and UAV-LS, the use of vehicle-mounted laser scanners significantly reduces the acquisition effort, while providing 3D point \nclouds with higher resolution and fewer occlusions than ALS. Because of these characteristics, MLS is a well-suited technology for the large-scale mapping of roadside vegetation and \nthus could become a complement or alternative to conventional vegetation surveys. Compared to conventional field surveys, MLS-based vegetation mapping would reduce labor and \ncost, while providing a richer, three-dimensional representation of vegetation. To realize the \npotential of MLS for vegetation mapping, an automated approach is needed to derive semantic information about vegetation from raw 3D point clouds. To lay a foundation for building \nsuch a system, this paper presents a general concept for the automatic detection and analysis \nof  vegetation  in  MLS  point  clouds.  In  contrast  to  previous  work,  the  proposed  workflow \nbuilds on a modern deep-learning approach for 3D point cloud segmentation. In a case study, \nan initial implementation of the proposed workflow is tested on MLS datasets from two cities \nand first results are provided. \n\nPotential of MLS-Based Vegetation Inventory \n\nCompared to conventional field surveys, MLS-based vegetation inventories would provide \nseveral advantages: First, the labor and cost of vegetation surveys would be reduced, allowing \nlarger areas to be mapped and vegetation inventories to be updated more frequently (e. g., \nquarterly to cover all seasons). Second, capturing vegetation in the form of 3D point clouds \nwould provide additional and more detailed data on urban vegetation. For example, shrubs \nand hedges could be mapped, which are not recorded in most conventional vegetation surveys \ndespite their ecological value and aesthetic impact. Furthermore, conventional tree invento-\nries usually only capture a limited number of tree attributes (ÖSTBERG et al. 2013). Using 3D \npoint clouds, additional geometric tree attributes such as trunk orientation or crown volume \ncould be captured (HERRERO-HUERTA et al. 2018). 3D point clouds could even be used to \nmodel the entire branching structure of trees (DU et al. 2019). Overall, the data collected in \nMLS-based  vegetation inventories could be used to build  comprehensive  tree information \nmodels, as proposed by SHU et al. (2022). Such information models would address the information needs of a wide range of stakeholders, including city officials, arborists, ecologists, \nand  landscape  architects.  For  landscape  architects,  information  derived  from  MLS-based \nvegetation inventories could be particularly useful for the following applications: (1) At the \nbeginning  of  the  design  process,  more  detailed  plant  models  could  be  created  to  enable  a \nmore accurate representation and analysis of existing vegetation. While generic plant models \nhave been commonly used to visualize vegetation (OEHLKE et al. 2015), plant models derived \nfrom  3D point  clouds  could  be  used  to  create  more  realistic  visualizations  of  vegetation. \nMoreover,  plant  models  derived  from  3D  point  clouds  could  also  be  used  to  estimate  the \necosystem services and disservices provided by existing vegetation. For example, the shading \nprovided by trees could be modeled, or the carbon storage and oxygen release potential of \nvegetation could be estimated (SCHOLZ et al. 2018). (2) Conducting MLS-based vegetation \nsurveys on a regular basis could also provide ground truth data for building and validating \nsimulation models of plant growth (WHITE et al. 2022). More accurate simulation of plant \ngrowth would support decisions between different planting regimes in the design of green \nspaces. (3) Once a certain planting regime has been established, MLS could be used to continuously monitor the green space (e. g., growth and condition). In this way, design decisions \ncould be evaluated, and vegetation maintenance measures could be planned and aligned with \nthe design goals. \n\nChallenges in MLS-Based Vegetation Inventory \n\nWhile MLS offers significant potential for the large-scale mapping of roadside vegetation, \nseveral challenging data characteristics must be considered when developing systems to automatically process MLS point clouds for vegetation mapping: \n\nLarge data volume: MLS produces large amounts of data with hundreds of points per square \nmeter. To be able to process MLS point clouds of large road segments or entire city districts, \nall processing steps must be automated and implemented efficiently. This requires algorithms \nthat allow parallel processing with modern multicore systems or graphics cards. \n\nVarying point density: The point density of MLS point clouds depends on the scanner type, \nthe acquisition speed, and the distance to the scanner trajectory. Systems for processing MLS \npoint clouds must therefore be robust to varying point densities. \n\nOcclusions: In MLS point clouds, vegetation  may be completely or partially occluded by \nother objects. The algorithms for detecting and analyzing vegetation in MLS point clouds \nmust therefore be able to cope with incomplete data, i. e., 3D point clouds that cover only a \npart of the surface.  \n\nLimited per-point attributes: Most LiDAR systems provide the 3D coordinates and reflection intensity for each scanned point. More advanced systems can capture additional attributes such as surface color (e. g., from panoramic images), temperature, or humidity. To support a wide range of scanner types, however, algorithms for vegetation detection and analysis should only rely on point coordinates and reflection intensity as input attributes. \n\nIntegration of  multi-temporal MLS data: Approaches for storing and processing  multi-temporal MLS data are needed to enable continuous vegetation monitoring. Since inaccuracies  can  occur  in  the  georeferencing  of  MLS  point  clouds,  techniques  for  co-registering \n3D point  clouds  from  different  acquisition  runs  are  needed.  In  addition,  approaches  are \nneeded to increase the coverage and merge redundant information from MLS point clouds \nacquired at different times and to identify areas that have changed between acquisition runs.  \n\nA Concept for the Detection and Analysis of Vegetation in \n\nMLS Point Clouds Using Deep Learning \n\nIn the following, a concept for the automatic detection and analysis of vegetation in MLS \npoint clouds is presented. The proposed workflow is divided into three steps: (1) In the first \nstep, deep-learning models are used to extract vegetation points from raw MLS point clouds \nand classify them into different vegetation types. (2) In the second step, the tree points detected  by  a  deep-learning  model  are  segmented  into  individual  trees.  (3)  Using  the  point \nclouds of individual trees, tree attributes such as tree height and trunk diameter are derived. \n\nDetection and Classification of Vegetation \n\nBesides vegetation, urban MLS point clouds contain a variety of other objects such as city \nfurniture, vehicles, and buildings. An automated approach is required to segment 3D point \nclouds of such complex scenes into vegetation points and non-vegetation points. In addition, \ndifferent vegetation types, such as low vegetation and trees, need to be distinguished. \n\nRelated Work \n\nWhile the present work aims to detect both low vegetation and trees, most previous work has \nfocused on tree detection in MLS point clouds. To segment urban MLS point clouds into tree \npoints and non-tree points, many works use either rule-based approaches (HAO et al. 2022, \nHUI et al. 2022) or statistical machine learning approaches (WEINMANN et al. 2017, CHEN et \nal. 2019). While rule-based approaches are usually not able to detect other vegetation types \nthan trees and are often very dataset-specific, statistical machine learning approaches often \nlack the capability to combine geometric features of different spatial scales. The recent work \nof CHEN et al. (2021) is among the first to use a deep-learning approach for vegetation detection in urban MLS point clouds. However, the PointNLM architecture proposed in their work \nis trained on hand-crafted geometric features of supervoxels and does not yet exploit the full \npotential of recent deep-learning architectures for 3D point cloud segmentation. \n\nMethodology \n\nIn general, deep-learning architectures for processing 3D point clouds can be divided into \narchitectures that operate on intermediate representations of point clouds such as 2D images \nor 3D voxel grids, and architectures that process point clouds directly (BELLO et al. 2020). \nOur workflow is built upon architectures that process 3D point clouds without intermediate \nrepresentations. These architectures usually are more efficient than architectures that use intermediate representations and are designed to self-learn geometric features at different spatial scales. Recent examples of such architectures include KP-FCNN (THOMAS et al. 2019), \na fully convolutional neural network (FCNN) based on a kernel-point (KP) convolution, and \nRandLA-Net (HU et al. 2020), “an efficient and lightweight neural architecture to directly \ninfer per-point semantics for large-scale point clouds” based on random sampling (Rand) and \nlocal feature aggregation (LA). In our implementation, the KP-FCNN Rigid architecture is \nused. Different variants of this architecture exist, targeting different processing tasks such as \nclassification  or  semantic  segmentation  of  3D  point  clouds.  In  this  work,  the  detection  of \nvegetation in MLS point clouds and its classification into different vegetation types are modeled as a single semantic segmentation task. To this end, models are trained to distinguish the \nfollowing classes: \n\nLow vegetation includes all types of low vegetation, e. g., shrubs, hedges, and potted plants. \n\nTree trunk includes tree trunks, defined as the segment ranging from the base of a trunk to \nthe first branching. \n\nTree branch includes the main branches of a tree that are not covered by foliage. \n\nTree crown includes tree foliage and the branches and twigs covered by it.  \n\nOther includes all non-vegetation points, e. g., ground, buildings, and city furniture. \n\nThis classification scheme is more fine-grained than the classification schemes used in previous studies. Segmenting trees into trunk, branch, and crown areas provides additional semantic information that can be used to delineate individual trees and estimate certain tree \nattributes. However, the proposed classification scheme also requires more detailed ground \ntruth annotations to train deep-learning models, which increases the annotation effort. \n\nSince large-scale MLS point clouds usually contain millions of points, they cannot be processed as a whole by deep-learning models. Therefore, our workflow includes two preprocessing steps to prepare raw MLS point clouds for processing by deep-learning models (Figure 1). First, the resolution of the large-scale point clouds is reduced by grid subsampling. \nSubsequently, small subsections of fixed size (4 m radius, 4096 points) are sampled from the \ndownsampled large-scale point clouds. These small-scale point clouds are processed by the \ndeep-learning model. The model predictions are mapped to the large-scale point clouds and \nare interpolated for points that were not covered by the small-scale point clouds. \n\nDelineation of Individual Trees \n\nThe deep-learning approach described in the previous section performs point-wise segmentation, where each point is assigned to a semantic class. However, for points that are classified \nas tree points, the deep-learning approach does not provide information about which individual tree a point belongs to. Therefore, an additional processing step is required to segment \nthe tree points identified by a deep-learning model into individual trees. Especially in areas \nwith high tree density and overlapping tree canopies, delineating individual trees can be a \nchallenging task. \n\nRelated Work \n\nIn  previous  work,  different  algorithms  have  been  proposed  to  delineate  neighboring  trees \nwith overlapping crowns, including graph-based approaches (ZHONG et al. 2017), clustering \napproaches (LI et al. 2021), and region growing approaches (LI et al. 2016). Some of these \napproaches rely on the correct detection of tree trunks and are therefore not robust to occlusions and misclassifications of tree trunks. Additionally, many algorithms for delineating individual trees are based on voxel representations of 3D point clouds, which limits their accuracy. \n\nMethodology \n\nTo improve robustness to incomplete data and achieve more accurate segmentation of overlapping tree canopies, we propose a multi-step approach to delineate individual trees. The \nproposed approach is inspired by several previous works (WU et al. 2013, ZHONG et al. 2017, \nXU et al. 2020, YANG et al. 2020) and consists of the following steps: \n\n1)  Identification of tree locations: In the first step, the locations of individual trees are \nidentified. To improve robustness against incomplete data, tree trunks, main branches, \nas well as treetops are considered for identifying tree locations. To identify tree locations \nbased on tree trunks and main branches, trunk and branch points identified by the deep-learning approach are clustered using the DBSCAN algorithm (ESTER et al. 1996). Adjacent clusters with similar growth direction are merged and the midpoints of the remaining clusters are used as approximate tree locations. To identify tree locations based on crown tops, a 2D canopy height model is constructed and searched for local maxima. \nThe positions of local maxima whose distance from the already found tree locations is \nabove a threshold are added to the set of tree locations. \n\n2)  Coarse delineation of individual trees: The tree locations obtained in the previous step \nare used to determine the coarse boundaries of the individual trees and to identify regions \nwith overlapping tree canopies. Different algorithms can be used for this purpose, e. g., \n2D Voronoi segmentation can be performed (ZHONG et al. 2017), or a canopy height \nmodel can be constructed and segmented using the 2D marker-controlled Watershed algorithm (KORNILOV & SAFONOV 2018). For the implementation in this work, a combination of both algorithms is used. \n\n3)  Refined delineation of overlapping tree canopies: If the coarse tree delineation indicates that two trees are close to each other, their canopies may overlap. In such cases, \nthe segmentation of the tree canopy is refined. Different approaches can be used to delineate  trees  with  overlapping  canopies,  including  graph-based  approaches,  clustering \napproaches,  or  region  growing  approaches.  Our  workflow  uses  a  region  growing  approach since it reflects the natural growth direction of trees and allows the delineation of \ntrees with different shapes. Specifically, we implement a custom, density-based region \ngrowing algorithm that is inspired by the DBSCAN algorithm (ESTER et al. 1996). In \nthis algorithm, for each tree to be processed, a set of seed points is selected (i. e., points \nthat belong to the tree with a high degree of certainty). In an iterative process, neighbor \npoints of the seed points are assigned to the respective tree, if they have not yet been \nassigned to another tree. Neighbor points that satisfy the core point criterion as defined \nin the DBSCAN algorithm (ESTER et al. 1996) become seed points themselves. To ensure  that  neighboring trees  grow  evenly,  points  are  sorted according  to  their  distance \nfrom the crown boundary determined during coarse tree delineation and processed in \nthat order. \n\n4)  Removal of implausible trees: In the final processing step, trees with implausible shape \nor size are discarded. Specifically, trees with few points and trees whose height is below \na threshold are filtered out. \n\nEstimation of Tree Attributes \n\nAfter obtaining point clouds representing individual trees, different tree attributes can be estimated. Most existing studies focus on the estimation of geometric tree attributes (HERRERO-HUERTA et al. 2018, WU et al. 2013, XU et al. 2020), while few authors also derive non-geometric attributes such as tree species or vitality (WU et al. 2018, CHEN et al. 2019). Since \n3D point clouds are particularly suitable for deriving geometric tree attributes, we also focus \non these attributes. However, algorithms for estimating non-geometric tree attributes such as \ntree species, carbon storage capacity, or oxygen release potential may be integrated into the \nworkflow in the future. For the estimation of the attributes tree location (WU et al. 2013), tree \nheight, trunk direction, crown width (HERRERO-HUERTA et al. 2018), trunk diameter at breast \nheight (CHEN et al. 2019), and crown volume (LI et al. 2020), we adopt the approaches used \nin previous work. Other tree attributes, namely under-branch height, and crown base height, \ncan  directly  be  derived  from  the  deep-learning-based  segmentation  of  trees  into  trunk, \nbranches, and crown. \n\nCase Study \n\nA test application was implemented to demonstrate the potential of the concept presented in \nthis paper. MLS point clouds collected in the cities of Essen, Germany, and Hamburg, Germany, were used to evaluate the test application. The point clouds were acquired using Trimble MX8 scanners in the leaf-on season. We manually annotated the point clouds and split \nthem into a training set, a validation set, and a test set. In the following, some preliminary \nresults for the test set are shown. \n\nFigure 2 shows exemplary results of the deep-learning-based vegetation detection and clas-\nsification.  As  can  be  seen  there,  large  portions  of  the  vegetation  are  segmented  correctly. \nHowever, several smaller segmentation errors can be identified: In multiple cases, low veg-\netation and tree crowns are confused. In addition, some pole-like objects are misclassified as \ntrees. There are also a few cases in which tree trunks are missed by the deep-learning model. \n\nResults of the delineation of individual trees are shown in Figure 3. While solitary trees and \nadjacent trees with little canopy overlap are correctly delineated in most cases, the results for \nthe delineation of trees with strongly overlapping canopies are mixed. Trees whose crown \nhas a large extent are over-segmented in several cases, and some parts of tree crowns with \nlow point density are missed by the region growing algorithm. \n\nFigure 4 shows some results of the estimation of tree attributes. As can be seen there, accurate \nestimates of geometric tree attributes are obtained if the accuracy of the preceding processing \nsteps is sufficiently high. When large parts of a tree are missed during tree segmentation, \nattributes such as tree height, crown width, and crown volume are often underestimated. In \ncases where multiple trees are recognized as a single tree, the crown width and crown volume \nare often overestimated. \n\nDiscussion and Conclusion  \n\nIn this work, a concept for the automatic detection and analysis of vegetation in MLS point \nclouds has been presented. The implementation of the concept produced promising results \nfor representative MLS point clouds from two cities. However, to approach the accuracy of \nmanual vegetation mapping, the method needs to be further improved. Since the accuracy of \nvegetation detection and classification affects the accuracy of the following processing steps, \nfurther improvement of the deep-learning approach for vegetation detection and classifica-\ntion would be of major benefit. Despite this need for improvement, the preliminary results of \nthis work suggest that the proposed deep-learning approach can detect and classify vegetation \nin complex street scenes that would be difficult to model using rule-based approaches. However, this comes at a price: The training of deep-learning models requires extensive annotated \ntraining data and high computing power of graphics hardware. To improve the practicality of \nthe approach, techniques to reduce the labeling effort (e. g., active learning or transfer learning) and improve model speed (e. g., model pruning) could be incorporated into the work-\nflow. \n\nWhile  the  test  application  presented  in  this  paper  was  limited  to  capturing  geometric  tree \nattributes,  it  would  be  desirable  to  derive  even  richer  tree  information  models  to  cover  a \nbroader range of use cases. For example, detailed models of tree branching structures could \nbe derived from 3D point clouds to enable estimation of aboveground biomass and carbon \nstorage capacity, as well as realistic vegetation visualization. Furthermore, it would be useful \nto integrate approaches for processing multi-temporal MLS data into the workflow. In this \nway, point clouds representing vegetation in leaf-on and leaf-off conditions could be combined. Capturing vegetation in leaf-off conditions would avoid the occlusion of woody components by foliage and thus facilitate the acquisition of woody biomass and the delineation \nof individual trees. In addition, approaches for predicting non-geometric tree attributes such \nas tree species and tree vitality could also be integrated into the workflow, e. g., by combining \n3D point clouds with spectral data from panoramic images or aerial photographs. \n\nSince MLS is a cost-effective method to survey very large areas, the present work focused \non vegetation mapping using MLS. However, MLS is only suitable for capturing vegetation \nin the proximity of drivable roads,  while PLS or UAV-LS  are  more suitable for  mapping \nvegetation in parks or private gardens. To provide a complete mapping of urban vegetation, \nthe concept presented in this work should be transferred to other LiDAR platforms. Since \nPLS point clouds have similar characteristics to MLS point clouds and a generic deep-learning approach is used in this work, transferring the approach to PLS point clouds should be \npossible with little effort. \n\nBuilding on the concept presented in this paper, a data processing tool could be developed \nfor large-scale and cost-effective urban vegetation mapping. Such a tool would enable continuous monitoring of urban vegetation and thus provide a basis for sustainable design and \nmaintenance of urban green spaces. In particular, it would enhance the study of ecosystem \nservices provided by urban vegetation and could thus help to guide the design of urban green \nspaces towards the provision of ecosystem services. \n\nEcological Robotics \n\nAbstract: This research presents a novel method for paste-based robotic planting. Our method for robotically extruding seeds in a paste of clay and planting media enables precise, algorithmic planting. \nThis additive manufacturing process builds microtopography, while planting seeds. With this 3D printing process designers can engage with the geomorphological and ecological processes that shape landscapes. Microtopography can be designed to direct flows of water, while planting can be designed to \nfoster biodiversity, form ecotones, and control erosion. As a proof of concept, we demonstrate how \nalgorithms can generate precise planting patterns  such as pseudorandom gradients. We envision  unmanned ground vehicles with seed printing systems planting entire landscapes with algorithmic designs. \n\nIntroduction \n\nResearch on autonomous construction in architecture has explored the novel creative, material, tectonic, performative, and aesthetic potential for the computational design of the built \nenvironment (GRAMAZIO & KOHLER 2014, MENGES 2015). Similarly, the autonomous construction and planting of landscape promises unique aesthetic opportunities and new ways of \nengaging with ecology and geomorphology. Designers have experimented with robotic processes for constructing landforms such as soil 3D printing (MITTERBERGER & DERME 2019, \n2020) and autonomous excavators (JUD ET AL. 2021, HURKXKENS ET AL. 2022). Robotic processes for planting have been developed such as vacuum seeding robots (GOLDBERG 1995, \nFARMBOT 2020, PRESTEN et al. 2021), autonomous seed drilling tractors (GROß 2013), and \nseed sowing with unmanned aerial systems (MOHAN et al. 2021). While sowing seeds is an \nimprecise process with low survival rates, seed drilling is more precise and has higher survival rates, but mechanically disturbs soil, increasing the risk of soil erosion. Our paste-based \nextrusion method for autonomous planting has millimeter precision, high survival rates, does \nnot disturb soil, and creates microtopography. Potential applications include landscape architecture, land art, ecological restoration, and precision agriculture. \n\nMethods \n\nIn our method for robotic planting, seeds are extruded in a paste of clay, planting media, and \nwater (Fig. 1). As an additive manufacturing process, paste-based extrusion of seeds builds \nlandforms layer by layer. The proportions of the paste are calibrated so that it can be extruded \nsmoothly, while supporting seed germination. Clay is used for plasticity for the sake of ex-\ntrusion. Planting media is used to provide nutrition for plants, retain water, and provide pore \nspace for root growth. Water is used to wet the clay and germinate the seeds. The paste is 3D \nprinted, i. e. extruded, directly onto soil. After printing, the seeds embedded in the paste have \nthe shelter, nutrients, and moisture they need to germinate. Once the seeds have germinated, \nthe roots of the seedlings grow into the soil below. \n\nAs a proof of concept, we developed a prototype with a linear actuator ram mounted on a 6-axis robotic arm. Industrial robots are reliable, versatile systems that can easily be adapted to \nnew tasks, making them well suited for creative experimentation with novel material processes  (GRAMAZIO  & KOHLER  2014,  16).  For  this  prototype,  we  used  a  UR10e  industrial robotic arm because its 12.5 kg payload was enough for a large extruder with 2000 ml of paste and its reach of 1300 mm allowed for a large build space. Grasshopper, a visual programming environment for computational design (MCNEEL 2021), was used to generate geometry for robot path planning. The Robots ex Machina framework (GARCÍA DEL CASTILLO Y LÓPEZ 2019) was used to control the robot and extruder.  \n\nTo test this method, a series of planting patterns were robotically printed in the lab. We tested \ndesigns such as space filling curves, landforms derived from trigonometric waves, landforms \nderived from cellular texturing, landforms derived from procedural noise (Fig. 2 & Fig. 3), \nand generative typography (Fig. 4). For ease of printing and cultivation in a laboratory setting, designs were printed in growing trays and stored on racks with grow lights. Each 250 \nby 250 mm tray was filled with planting media as a substrate for the print. We used plants \nsuch as perennial ryegrass (Lolium perenne), annual ryegrass (Lolium multiflorum), arugula \n(Eruca vesicaria), radish (Raphanus sativus), alfalfa (Medicago sativa), Siberian kale (Brassica napus) and broccoli (Brassica oleracea var. italica). For the landforms, the extruder was \nfilled with layers of different seeds to create an elevation gradient of species. Over the course \nof the study, the prints were photographed daily to record the growth of the plants. \n\nResults \n\nThe planting designs printed cleanly and precisely as the crisp letterforms in Figure 4 demonstrate. Plants grew most healthily and vigorously in prints that were 5 or 10 mm tall, composed of 1 or 2 layers, because the seedlings’ roots had easier access to the porous, nutrient rich substrate of planting  media below. Furthermore, plants grew  more vigorously in narrower forms with widths of 20-40 mm because this ensured that seedlings had less competition and more access to sunlight and substrate. While paste-based extrusion of seeds creates microtopography, the scale of appropriate landforms is highly constrained by growing conditions.  \n\nFuture Work \n\nTo further this research, we are investigating alternative media for the paste, testing different \ntypes of extruders, integrating sensors into the system, and integrating the system onto an \nunmanned ground vehicle for landscape-scale planting (Fig. 5). We are testing pastes composed of biochar that release nutrients slowly and biopolymers that biodegrade rapidly. We are integrating moisture sensors, depth sensing, lidar scanners, and multispectral imaging for adaptive planting and monitoring. Using these sensors, we plan to conduct experiments with controls, replicates, and quantitative measures to assess the efficacy of this method with different pastes. To plant at landscape-scale, we plan to integrate the robot arm, extruder, and sensors onto an unmanned ground vehicle with real-time kinematic positioning. We plan to \nuse lidar, positional data, and simultaneous localization and mapping algorithms for autonomous navigation and for positioning the extruder relative to the ground in real time. For field \ntrials, we will use lidar and multispectral imaging on unmanned ground and aerial vehicles \nto conduct repeated surveys at high spatial and temporal resolution to assess plant growth.  \n\nConclusion \n\nWith paste-based robotic planting, computational designs for planting patterns can be autonomously seeded with high precision. While this experiment was conducted in the lab, robotic \nplanting could be done at scale in the field with unmanned ground vehicles. With generative \ndesign enacted by field robots, landscape architects would be able to design dynamic landscapes as ongoing performances – as ecological processes guided by design interventions. \nUnmanned aerial systems could  collect imagery and elevation datasets at high spatial and \ntemporal resolution that could inform the ongoing design and management of landscapes. As \nunmanned aerial systems monitor how landscapes evolve, unmanned ground vehicles could \nadaptively plant and replant in response, catalyzing new assemblages of plants and wildlife. \nWe hypothesize that algorithmic planting based on ecological principles could foster spatial \nheterogeneity, complexity, and thus biodiversity. We envision field robotics giving rise to an \nalgorithmic aesthetic of ecology.  \n\nNew media scholar Laura Marks describes algorithmic aesthetics as a semiotic process of \nenfolding and unfolding, a process in which infinite possibility is transcribed into information \nand then image (MARKS 2010). This is a performative aesthetics of infinity and contingency \n– an aesthetics that explores what is revealed and what is hidden; an aesthetic in which creativity is a  means of discovering the infinite. Design projects like  GRAMAZIO KOHLER Research’s  Endless  Wall  (2011),  SNØHETTA’S  MAX  IV  Laboratory  Landscape  (2016),  and \nMAEID’S Magic Queen (2021) evoke such an algorithmic aesthetic. With systems for precise \nautonomous planting, landscape architects would have the means to express ecological complexity  and  contingency  with  a  visibly  algorithmic  logic.  Computational  design  processes \nsuch as procedural noise, cellular noise, and fractional Brownian motion (Figures 2, 3 & 6) \ncould be used to generate planting patterns  with high spatial heterogeneity and ecological \ngradients  between  drifts.  Such  computationally  designed  planting  would  simultaneously \nevoke the accidental and intentional, the actual and virtual. \n\nExpanding Digital Design Workflows with Geospatial \nAnalytics: Linking Grasshopper3D with Google \nEarth Engine \n\nAbstract:  The  following  body  of  work  introduces  a  plugin  that  links  the  visual  scripting  language \nGrasshopper3D (GH) to the Google Earth Engine (GEE) in order to easily fetch geospatial information \nrelative to various societal issues and for any geographical area under study, inside the Rhino modelling \nsoftware.  \nAiming  at  expanding the  field  of  Digital  Landscape  Architecture with  novel  content to  analyse  and \ndesign, it provides designers with more than thirty years of historical imagery and scientific datasets, \ncollected in GEE on a daily basis by several institutions around the world. Leveraging the intuitiveness \nof the visual scripting language, it computationally empowers designers with geospatial insights with-\nout the need for any GIS skills and has been proved a successful platform for teaching purposes. Encouraging learning through application, the paper discusses three teaching experiences, which adopted \nthe proposed tool to visualise river dynamics in time, resource-specific maps of land consumption for \ncities and street-sensitive accessibility maps through the additional integration of OpenStreetMap data. \n\nIntroduction \n\nDuring the last three decades, a constellation of computational applications has emerged that \nempowers architects and designers to respond to the challenges of the  AEC and planning \nsectors through highly technological and innovative means. Active since late 2007, the Rhinoceros’s visual programming language: Grasshopper3D (GH), has been proved to be among \nthe most successful examples of this kind. It has offered a visually-intuitive medium to teach \nand compute advanced computational pipeline without writing one line of code, and has become an asset for both the academic and the industrial realms (CASTELO-BRANCO & LEITÃO \n202). Additionally, whether to simulate microclimatic conditions (MACKEY et al.. 2017), calculate structural performances (PREISINGER & MORITZ 2014), or work with georeferenced \ndata (DOGAN et al. 2018) to name a few, over the years GH has collected an extensive amount \nof plugins, developed by an active community of computational designers, to expand its influence in many aspects of the design process and in relationship to the many actors involved. \nFinally, by reshaping the traditional drawing tools through mathematics and functions, it has \nprovided designers with novel ideas to design while deeply influencing all scales of the project, from Digital Fabrication to Digital Landscape Architecture. Placed within this line of \ninvestigation,  the  following  body  of  work  introduces  a  plugin  that  links  Grasshopper  to \nGoogle Earth Engine to instantly fetch selected geospatial layers for any geographical area \nof interest. In this sense, it enables designers to access spatial insights related to more than \nthirty  years  of  remote  sensing  data,  collected  by  a  plethora  of  satellites  and  processed  by \nresearch institutions from all over the world. Answering to the call for data democratization \nwhile rendering large-scale computing accessible to non-experts, the Google Earth Engine \n(GEE)  is  a  “cloud-based  platform  for  planetary-scale  geospatial  analysis  [that  seamlessly \ngives to] not only traditional remote sensing scientists, but also a much wider audience, [access to many] societal issues including deforestation, drought, disaster, disease, food security, \nwater management, climate monitoring and environmental protection” (GORELIK et al. 2017). \nFor this reason, GEE is built around a petabytes-large catalogue of georeferenced data and \nan Application Programming Interface (API) to access and process server-side the same layers; achieving in this manner high speed performances and becoming suitable not only for \nglobal-scale  calculation  processes,  but  also  for  more  explorative  and  experimental  approaches, common in design processes.  \n\nThe Toolkit \n\nAs an entry point for designers to explore geospatial analytics through Google Earth Engine, \nthe toolkit proposed consists mainly of five GH components to import, spatialize, process \nand calculate geospatial raster layers through the Earth Engine API Python library1 and via \nHops. Being a recent development in the Grasshopper3D suite, Hops is the first package to \nefficiently link the visual scripting tool to the real potentialities of the Python programming \nlanguage.  By  externally  running  CPython  code  via  a  Flask  application,  it  allows  Python \nscripts to be implemented in GH unconstrained by the limitations of predefined libraries and \nopen to the vastness of community-driven packages available online.  \n\nBeing one of these contributions, the Earth Engine API is the official Python client library to \ndynamically access GEE. Used within the tailored Flask application, it runs requests from \nthe inputs in GH to the online GEE server and consequently fetches the required information. \nMore precisely, the discussed custom components to connect GH to GEE are: \n\n1)  ee_image: it permits the download of images from GEE for any geographical area of \n\ninterest and functions as the primary component to explore GEE. \n\n2)  ee_imageColl: it enables to work with the more advanced imageCollection typology and, \ncompared to the ee_image, requires extra information in respect to the date, or permitted \ncloud coverage to consequently extract images. \n\n3)  ee_ND: it engages with GEE to create normalised difference indicators on the server side \nby providing multiple bands to work with, and functions as an entry point to the world \nof remote sensing indicators \n\n4)  ee_cumCost: it calculates cumulative cost analysis, which are commonly used to spatialize accessibility, provided a cost to travel over a territory and an initial set of origins \n\n5)  reproject_UTM: an utility component to manage coordinate reference systems and align data fetched from GEE with the outputs of other plugins for GIS operations \n\nThe requirements to use the aforementioned components are kept very concise and focus on \nproviding the maximum flexibility with the minimum amount of inputs, and always comprises: an area of interest to download the image from, a resolution -in metres- to balance the amount of information to be downloaded, and the layer, with respective bands, that we are interested in accessing. Additionally, more inputs can be requested to calibrate the functions of the specific components, like in the case of the ee_ND that requires more than one band to reciprocally subtract, or the ee_cumCost which requires locations of origin for the accessibility analysis to be calculated from. This being said, the toolkit automatizes a series of spatial operations common in Geographical Information Systems (GIS) to deal with raster layers, \nlike is the case of resampling operations to obtain custom resolutions, or mathematical operations to calculate remote sensing indicators. It is important to notice that it does so in the \nbackground, opening up possibilities for the users to interact with the tool only through specifically opinionated inputs in order to facilitate its generic usability and versatility. In this \nsense, the tool aims at providing a simplified pipeline for computational designers to investigate  the  immensity  of  the  Google  Earth  Engine  database  for  design  purposes  through  a \nscarce set of inputs, allowing them to obtain material for further analysis and manipulations \nwith conventional processes – through standard components in Grasshopper3D – in a fast, \nand interactive fashion and without the need to be GIS experts.  \n\nFinally, the open source nature of the tool – a Python Flask application – permits an in-depth \ncustomization of each component – if equipped with enough knowledge of the Python programming language – and it has been proved to be a fruitful case to learn and apply computational logics in a pedagogical sense. It balances levels of complexity  when approaching GIS  processes  through  visual  programming  while  maintaining  the  possibility  to  read  and study the back-end codes when necessary. \n\nLearning Through Application \n\nThrough  one  year  of  teaching  experience,  the  proposed  plugin  has  been  tested  on  several \noccasions and has been proved to be versatile enough for different case studies, enhancing in \na broad sense the toolset that designers possess when approaching a territorial project – for \nvisualisation or analytical purposes – and not focusing on highly specific outputs. In the following section, the paper discusses three such occasions where the methodology has been \nshared with students to analyse river patterns in time, resource-specific maps of land consumption for cities, and street-sensitive accessibility maps through the integration of Open-StreetMap data relative to high resolution street networks.  \n\nMore precisely, the case studies hereby collected are the results of the Geomining lecture for \nthe Master in Landscape Urbanism at the Architectural Association School of Architecture \nin London, the Earthy Indexes workshop at the CAADRIA conference 2022\/23, and the one-week Urban Analytics workshop for the IAAC Global Summer School 2022. \n\nAnalysing River Patterns in Time \n\nThe analysis of river patterns in time is an important tool for understanding the dynamics of \nriver systems and the impacts of natural and human-induced changes on these systems. Used \nto inform a wide range of decisions related to the management and protection of river systems \nand the resources they provide, such as flood risk assessment, water resource management, \nenvironmental impact assessment, and land use planning, it is a fundamental asset for Landscape Architecture, which usually requires tedious data research and modelling.  \n\nUnequipped with a specific plugin, these studies are commonly carried out in GH through \nad-hoc scripting via iterative logics, such as for river meandering and oxbow lake simulation2 \nor water runoff studies which can be used as support material. Despite being excellent case \nstudies to teach iterative logics and loops (i. e. using the Anemone plugin3), they often fail to \nreach a high level of  specificity and end  up in the realm of design exercises compared to \nterritorial studies: fruitful to inspire design processes but insufficient for serious analytical \npurposes.  \n\nOn the other hand, there are several methodologies that can be used to map river dynamics \nin time using GIS, including time-enabled data, dynamic modelling and finally time series \nanalysis. Despite being able to provide highly specific and precise assessment of river dynamics, studies via time-enabled data or computational models are generally expensive or \ndemanding to implement due to the requirements of on-site equipment or highly trained professionals to set up and run hydrologic models. On the contrary, remote sensing has been \nwidely used in the analysis of river patterns in time over the past few decades as it allows for \nthe collection of large amounts of data over a broad area in a relatively short period of time; \npermitting a wide range of spatial and temporal scales to be included in a interoperable medium for the experts of the field to disseminate the results of their research. \n\nIn this sense, the JRC Global Surface Water mapping layer4 offers an unprecedented synthetic image of more than 4 million scans from Landsat 5, 7, and 8 to describe in high-resolution  the long-term changes  happening in river  systems  from early 1984 until the end of \n2021. Hosted in GEE as a multi-band 30m resolution image, it can be easily queried via the \nproposed ee_image component to visualise for any area of interest the patterns of extension, \nseasonality and recurrence of water to name a few. These layers precisely have been class \nmaterial during the Geomining lecture at the Architectural Association School of Architecture where participants drew a synthetic line-map of temporal river dynamics (Figure 1) almost-instantly and without geographical restraints. Taking advantage of the extensive repre-\nsentational possibilities of GH and adopting colour, angle and length as parameters, the map \nreported not only where it is possible to find water resources, but also their permanent loss \nand yearly frequencies, thus providing a wider understanding of the ephemerality of water \ncompared to a standard layer by layer visualisation. Additionally, and only thanks to the implemented pipeline, no particular download was required to compute the analysis. Avoiding \nto redundantly download entire databases by running area-specific queries in GEE is far more \nthan secondary as it prevents common issues concerning not only memory availability but \nalso computational power and computing times on the designer’s machine. \n\nMaps of City Consumption \n\nThe majority of people in the world live in cities, which currently only take up 3% of the \nEarth's surface but have transformed 70% of the planet through human activities (CIESIN \n2016). In this sense, cities around the world are interconnected and constantly exchanging \nresources, but the traditional link between places of consumption and places of extraction \nthat was once vital for a city's prosperity has been disrupted. As geographical proximity became less important for urban success, the environmental impact of this shift was overlooked, \ncontributing to the unsustainable nature of modern society, particularly due to the physical \nseparation of consumption and resource extraction. \n\nAiming to shorten the awareness gap that current planetary urbanisation has produced, the \nEarthy Indexes workshop held by the author and Erzë Dinarama at the CAADRIA conference \n2022\/23 presented a computational methodology – strongly supported by the discussed pipeline – to engage with the concept of ecological footprint at the city scale. More specifically, \nit challenged participants to crossread resource-specific demands of agricultural, pasture or \nforest land with context-specific land availability and land accessibility; finally envisioning \nup to which extension a city would consume if operating only by proximity logics (Figure \n2).  \n\nIn line with another study on Spatialized Metropolitan Ecological Footprints (Neri 2021), \nthe analysis computes pro-city land consumption values to fulfil the annual demand of a selected resource for its entire population and consequently queries exact amounts of land, filtered and ranked by its infrastructural accessibility. It exploits mainly two data layers: the \nGlobCover 20095 for a 300 m resolution global land cover map, and the Oxford’s Global \nFriction Surface 20196 layer to feed a territorial road-sensitive cumulative cost analysis via \nthe ee_cumCost component. More specifically, the latter offers a map where every pixel is \ngiven a speed to travel based on the local road infrastructure at approximately 900 m scale \nand based on a combination of national and global (OSM) data. \n\nFig. 2:  Ecological footprint studies for coffee, beef and wood, for the city of Barcelona as \npart of the Earthy indexes workshop led by Erzë Dinarama and Iacopo Neri at the \nCAADRIA 2022 – Post Carbon conference  \n\nBridging statistical data (e. g., demography and land consumption values) with geographical \ndata (e. g., land use and accessibility maps), this approach offers a fruitful pedagogical platform to engage with territorial indexes, while discussing the role of critical cartography in \nsupport of sustainability-related studies.  \n\nUrban Accessibility Maps \n\nFinally, the proposed pipeline has been adopted to study micro-scale mobility patterns. Reflecting on the aforementioned Oxford Global Friction Surface layer, the ee_cumCost component offers the possibility to alternatively use an ad-hoc friction layer to run cumulative \ncost analysis, therefore, exploiting GEE only for computing purposes and not for data collection. Again, OSM data provides a valuable medium to fulfil this goal, and can be easily accessed in GH via many workflows (i. e. Urbano7, Gismo 8) and geographically aligned with \nthe proposed pipeline via the utility reproject_UTM component. Technically, the cumulative \ncost component welcomes any sort of curve-based geometry to paint an image on the GEE \nserver with custom values and for any provided resolution, permitting the modelling of district-scale isochrone studies unlimited by the coarser standard friction layers of GEE (Figure 3).  \n\nThis was the subject of the one-week Urban Analytics remote workshop for the IAAC 2022 \nsummer school led by the author together with Eugenio Bettucchim, where the international \naudience of participants mapped for their home-towns a series of accessibility maps to various amenities and public services, collectively discussing by comparison the manifold forms \nof the x-minutes city. \n\nOther scholars have been using OSM data to create intuitive pipelines for accessibility studies \nvia network graph (Geoff 2020). Despite being widely used in mobility studies as an excellent \nmedium to represent complex relationships between the different elements of a street network \n(i. e. intersections, roads, and traffic flow), graph modelling requires extensive cleaning operations in its set up phase, which – for a crowd-sourced and in-development database such as OpenStreetMap – may disincentive non-expert users in comfortably interact with the algorithm. Trading specificity over usability, the proposed pipeline suggests a raster based approach  to  model  street-sensitive  accessibility  maps,  solving  the  incongruencies  within  the \nOSM network with a choice of pixel-resolution. \n\nConclusion and Outlook \n\nIn conclusion, the Grasshopper3D addon discussed in this text allows designers to access and \nutilise geospatial data from the Google Earth Engine platform in their design process. The \nplugin consists of five components that import and process geospatial data through the Earth \nEngine  API  Python  library  and  Hops.  The  Earth  Engine  API  is  the  official  Python  client \nlibrary for accessing GEE and is used within a tailored Flask application to fetch the required \ninformation in response to inputs from the GH components. These components allow designers to explore and use GEE data, specifically imagerial data, for various purposes and scales: \nfrom digital fabrication to digital Landscape Architecture, and integrating it with more traditional computational pipelines. \n\nAs proved through one year of teaching experience, this plugin represents a valuable tool for \ndesigners seeking to use geospatial data in their work and expands the capabilities of GH by \nlinking it to GEE's extensive data catalogue and powerful processing capabilities. \n\nFurther steps can be taken to extend the plugin with GEE’s Machine Learning algorithms \nlike the ones used for classification, clustering, regression or feature extraction, to name a \nfew. Related to a higher level of expertise, these algorithms allow to reproduce at will many of the pre-processed layers of GEE, which might be used to accomplish adhoc or higher resolution maps, similarly to the example of the district-scale isochrone studies via externally \nfetched OSM data, as well as to include design inputs in the forecast of their impacts. \n\nLiDAR-Based Digital Modeling and Comparative \nAnalysis of Urban Street Tree Form and Dimensions \n\nAbstract:  Numerous  workflows  exist  to  computationally  generate  three-dimensional  tree  models \nwhich effectively simulate their real-world counterparts. This research hybridizes several existing and \nnew approaches to tree modeling to improve growth models based on point cloud data. The digital tree \nmodels are created in Blender using an add-on called The Grove, enabling digital trees to grow according to light availability, with full control over their branching structure and form. These three-dimensional tree models are then measured and their dimensions compared to the point cloud counterparts, \nwith average values indicating that the digitally-grown trees are relatively similar to the point cloud \ntrees though smaller in most dimensions. The results demonstrate that point-cloud models of trees can \nbe used to improve computational tree growth models leading to improved tree visualization. \n\nIntroduction \n\nOur objective is to create a hybrid workflow to model context-specific digital tree models \nbased on LiDAR data of existing trees. We also aim to visualize the tree models by placing \nthem within a rendered virtual environment. Our hypothesis is that point clouds of street trees \ncan be used to improve computational tree growth models, leading to improved visualizations \nof trees. Visual realism is a critical part of this research, since capturing the materiality, light, \nand atmosphere of the landscape can resonate with audiences. Our motivation for this project \nis to improve upon our recent research in computational tree modeling which generated three-dimensional tree models based on scientific data without sacrificing visual realism, yet which lacked  any  methods  for  comparing  the  modeled  trees  with  real-world  tree  information (ACKERMAN et al. 2022).  \n\nLandscape architects model sites of significant physical size, places which are naturally dynamic and which can take decades to fully develop according to the designer’s vision. Thus, \nit is logical that most 3D modeling software is not currently suited to simulating landscape \ncharacteristics. This territory is often taken up through adapting software intended for modeling trees and terrain for games and film, tools such as SpeedTree, a standard industry tool \nfor creating realistic trees and plants, and Terragen, software used to create large-scale photorealistic natural environments. In recent years, many landscape architects have begun using \nLumion, a real-time renderer which integrates with most 3D modeling software and has a \nlarge and accessible library of trees and other vegetation. \n\nConstantly improving imaging technology has allowed us to digitally model landscapes for \nseveral decades (LEWIS 2012). Yet distinct challenges exist in modeling natural elements of \nthe landscape. In contrast to the well-defined geometry of architectural and industrial objects, \nthe organic variation of natural elements and the multi-part composition of vegetation presents unique difficulties. For example, trees are comprised of a trunk, branches, twigs, and \nleaves, each following a similar pattern but with unique formation. Where a single model of \nan architectural element such as a window can be used repeatedly in a scene without creating visual dissonance, a single model of a tree cannot be multiplied without looking artificial. In order to overcome this artificiality, digital tree simulations must integrate architectural and self-organizing  components  of  tree  growth  to  create  scientifically-informed  tree  models \n(PALUBICKI et al. 2009). \n\nSeveral models have been created to computationally generate unique three-dimensional tree \nmodels. The Algorithmic Beauty of Plants describes the application of L-systems to generate \na variety of tree branching structures which build upon earlier work of others’ to computationally simulate branching patterns (PRUSINKIEWICZ et al. 1996). Weber and Penn developed \ndigital tree models which focused more on visual realism than strict adherence to botanical \nprinciples. Their model integrates branching, pruning, leaf orientation, stem bending from \nwind, and vertical attraction, and realistic materials (WEBER & PENN 1995). De Reffye et al. \nused characteristics of tree mortality and regeneration to generate digital models of tree species growth over time, a data-informed method to create vegetation that strictly adheres to botanical  structure  and  development.  While  effective,  this  method  requires  knowledge  of botany as well as their specific computational methods (DE REFFYE et al. 1988).  \n\nMethods for creating scientifically accurate, realistically-rendered digital trees has improved \nsignificantly in recent years; such as digitally modeling an endangered eucalyptus woodland \n(CHANDLER et al. 2021), and digitally modeling and visualizing fifty years of growth in a \nWisconsin forest (HUANG et al. 2021). This use of field specimens for material texturing is \nan emerging tree visualization practice that help capture the realism of the landscape being \ndepicted (DEMETRESCUE et al. 2020). Yet many of these techniques have been limited by the \nhigh  level  of  programming  skill  required  to  apply  these  techniques  in  a  meaningful  way, \nrunning the risk of stalling the use of landscape visualization in scientific communication \n(BELL 2001). \n\nHigh levels of  graphic realism in landscape  visualization  are valuable in part due to  their \nability to reliably replicate similar levels of human cognition that occur when viewing a physical landscape site (SHI 2020). Yet realism in digital landscape visualization is often challenging given the number of trees and the amount of detail required in tree geometry (BAO et al. 2011, COLDITZ et al. 2005). These digital tree models are burdened with simulating \ninteraction and competition between trees, responding to sun and shade, compete for light \nwith their neighbors, lose branches over time, and simulate a range of other tree growth factors which have long been understood as critical components of the development of a tree’s \nphysical form (BELLA 1971). However, it stands to reason that with a greater number of interrelated  factors  being  used  to  model  a  tree,  the  more  closely  we  must  understand  the \ncause\/effect relationship of the parameters being used. This understanding is especially critical when tree growth models also include context such as nearby architecture and neighboring trees. \n\nMethods  \n\nPoint Cloud Capture and Conversion \n\nA comprehensive model of urban street trees was developed using vehicular ground-based \nLiDAR to capture several sets of urban street trees in Zhengzhou, China. The capture was \nperformed by driving down several urban street corridors with LiDAR equipment on the roof \nof the vehicle. The goal of this LiDAR capture effort was to create several point cloud models \nshowing variation in tree maturity. Three different sets of tree maturities were captured: 5-6 \nyears, 8-13 years, and 13-18 years. We were able to capture different maturity levels because \nmultiple  tree  planting  efforts  had  occurred  in  the  area  over  several  years,  producing \nheterogeneous groupings of trees spanning over a decade of growth. All trees were planted \nin identical linear plans along urban streets with high traffic volumes. All trees were of the \nsame species, a large deciduous tree with the botanical name Platanus x acerifolia, commonly \nknown as the London Plane Tree. This species was ideal for our research as it is one of the \nmost common street trees throughout China and North America, making the project broadly \napplicable to several urban contexts (LI et al 2011, LU et al 2010).  \n\nOnce captured, the point cloud model was processed in Lidar360 software in order to classify \nthe  point  cloud  into  tree  canopy  and  ground  elements.  The  canopy  point  cloud  was  then \nseparated into individual tree point clouds for analysis. This separation was done in Lidar360 \nusing an algorithm based on the shortest-path metabolic ecological theory, which uses the \nfact that vascular plants optimize the shortest possible distance from leaf to root to determine \nevery  point’s  belonging  to  a  particular  trunk  (TAO  et  al.  2015).  Each  point  cloud  was \nclassified and colorized before exporting to an LAS dataset (Fig. 1).  \n\nThe LAS dataset then needed to be converted to physical geometry for visualization. This \nwas  done  by  using  the  three-dimensional  modeling  software  Rhino  and  its  parametric \nmodeling tool, Grasshopper. In Grasshopper, we used the Volvox component to load the LAS \ndataset, create a voxel for every point, and export to a mesh. We then used the Weaverbird \ncomponent to subdivide and smooth the mesh. The resulting geometry provided a reasonably \nlegible approximation of a three-dimensional tree model which delineated each tree’s trunk, \nbranching structure, and canopy fullness (Fig. 2). \n\nTree Growth Modeling \n\nWe selected the intermediate-aged group of 8-13 years for use in tree growth modeling, as it \nincluded enough branching and canopy detail for comparison, while also being small enough \nto minimize the computational load in iterative development of a growth model. The 8-13-\nyear  model  was  exported  from  Rhino  as  an  FBX  file  and  imported  into  Blender,  another \nthree-dimensional modeling program. Blender allows intuitive yet sophisticated tree growth \nsimulation  through  an  add-on  called The  Grove,  which  provides  an  interface  for  growing \ngroups of trees with precise control of growth characteristics, species, and age. The Grove \nalso enables tree growth in response to light and shade, competing with neighboring trees for \nlight and responding to shade from nearby objects. \n\nTo begin the growing process, we selected the Platanus x acerifolia from the preset list of \navailable species in The Grove. These presets, which included many common trees, provided \na starting point with settings for the unique growth characteristics for the selected species. \nWe then placed a seedling tree at spacing intervals identical to the point cloud trees and grew \nthe seedling trees to 10 years of age. Through a trial-and error process of visual comparison \nbetween the 8-13-year point cloud mesh and the 10-year Grove model, we adjusted specific \ngrowth characteristics and re-grew the seedling trees again to 10 years of age. With each step \nwe noted the adjustment and captured an image of the tree group (Tab. 1). \n\nThrough iterative adjustment and re-growth, we gradually improved the growth model. After \nnine iterations, the tree growth model bore enough resemblance to the LiDAR model with \nregard to branching, structure, and canopy that we were satisfied with the settings. A visual \ncomparison of the final growth model and the LiDAR model demonstrates the results (Fig. 3). \n\nResults and Discussion \n\nWe hypothesized that point cloud models of trees could be used to improve computational \ntree growth models. Referring back to Table 1, the change in form and structure from the first \niteration to the ninth is striking. It is possible that this process could be seen as a form of \nmodel validation against physical counterparts, forming the basis for accepting the landscape \ncognition  that  occurs  when  viewing  images  that  include  these  digital  tree  models.  This \npresents implications for use of digital tree models in performance calculations. Lidar360 has \nthe ability to generate a report showing dimensions for each tree within the point cloud model. \nThese values can be used in climate-based calculations such as the U.S. Forest Service Tree \nCarbon Calculator (USDA 2022). This and other tools allow calculation of carbon dioxide \nsequestration  and  aboveground  biomass,  critical  factors  in  mitigating  climate  change.  We \nperformed a comparative study of the dimensions of trees from Lidar360 and dimensions of \ntrees generated in this iterative study using the Grove. Trunk diameter of trees from the Grove \nwere taken by importing the tree meshes into Rhino and creating a clipping plane at 1.37 \nmeters from the ground, the approximate level at which DBH (diameter at breast height) is \ntaken. The diameter of each trunk was measured (Fig. 4). \n\nTo calculate tree canopy volume, we developed a crown envelope which essentially wrapped \nthe tree canopy in an enclosed volume. This builds on recent work in transforming urban tree \npoint clouds into three-dimensional crown models (GUO et al. 2021, MÜNZINGER et al. 2022). \nBecause we imported leafless trees into Rhino to reduce computing load, we added a small \nbuffer at the ends of branches to account for the larger volume when leaves are present (Fig. \n5). \n\nOverall, the Grove tree models average height was slightly higher than Lidar360 – an average \nof 10.173 meters vs. 9.910 meters. However, in every other measurement the Grove trees \naverage  values  were  somewhat  lower  than  those  in  Lidar360.  The  differences  are  small \nenough that we feel that we are close to a digital growth model that can produce trees for use \nin analysis and simulation. Our aim is to be as close as possible to approximating real-world \nvalues, and we will continue to iteratively adjust the Grove trees and analyze their dimensions \nuntil they more closely matched Lidar360. Narrowing the gap between digitally-grown trees \nand real-world counterparts will be critical if we wish to use the dimensions of trees grown \nwith The Grove and Blender to perform similar carbon calculations. This would provide a \nvaluable tool for responsibly determining future performance of urban street trees. \n\nConclusion and Outlook \n\nFuture directions of this work will aim to expand the workflow to include additional common \ntree  species  using  a  similar  workflow  of  point  cloud-based  iterative  growth  modeling.  As \npreviously mentioned, we also aim to quantify the digital models created with The Grove and \nBlender in order to perform predictive calculations for carbon sequestration in urban settings. \nCombining these calculations with visualizations of mature urban street trees may well be a \npowerful  advocacy  tool  for  promoting  increased  tree  planting  in  urban  areas  while \nresponsibly depicting the likely visual character of such plantings.  \n\nDespite these successes, there are several components of this research that are problematic. \nA primary issue is the number of software programs and skillsets required to move through \nthe phases of these workflows. Unless we are able to streamline the workflow significantly, \nthis  level  of  landscape  modeling  and  visualization  will,  as  Bell  (2001)  stated,  remain  an \nunderutilized tool in scientific communication. \n\nAn additional problem is the significant computational power needed to run the tree growth \nsimulations and Unity visualizations. Even with the high-end computer used to generate the \nmodels and visualizations, 10-20 minutes was needed to generate a group of 20 trees grown \nto 35 years of maturity – approaching an apparent upper limit on the amount of trees that can \nbe  modeled.  These  trees  also  experienced  some  lag  time  in  Unity  that  resulted  in  a  less \nresponsive experience using the software. This is a long-standing issue with rendering 3D \nvegetation using current high-end computing power, mentioned by Weber & Penn (1995), \nColditz et al. (2005), Bao et al. (2011), and others. This suggests that issues with realism and \nlimitations of computing power will persist and should be anticipated as a regular part of this \nwork. \n\nThis  research  has  overcome  some  of  the  primary  challenges  that  have  long  existed  in \nmodeling the natural landscape, primarily the difficulty in capturing the organic variation of \nnatural  elements.  It  has  added  new  knowledge  of  modeling  a  tree’s  physical  form  and  its \nbehavior among other trees, building upon decades of work to devise L-systems, botanically-based models, visual models, and others. Ongoing development of this research can further improve  the  ways  that  we  model,  analyze,  and  apply  computationally-grown  trees  to contemporary challenges. \n\nNeural Radiance Fields for Landscape Architecture \n\nAbstract: In this paper, we examine potential applications of Neural Radiance Fields (NeRF) in the \nfield of landscape architecture. NeRF is a state-of-the-art method for novel view synthesis and volumetric scene reconstruction based on real-world training data. Our paper addresses NeRF and its derived models with a focus on the use and application of Instant-NGP, a method developed by researchers from the technology company NVIDIA. We discuss experimental applications of NeRF based on the case study of the post-disaster landscape of Ahr Valley, Germany, affected by a 100-year flood in \n2021. In particular, we are interested in the benefits of NeRF in comparison to other landscape modeling \nmethods, such as Structure-from-Motion (SfM) or Multi-View-Stereo (MVS), which use similar data \nas input.  \n\nThis study shows that the application of NeRF technology can be a promising alternative for capturing \nand visualizing landscape scenes. The study focuses especially on tasks and situations where the larger \nspatial context – the landscape – is of interest and importance. The technological aspects of how NeRF \nmodels work are relevant, but our main focus is on their potential implications for the field of landscape \narchitecture. Technical development and research in the scientific field of computer vision are accelerating rapidly. As users, rather than developers, of digital tools, we believe that NeRF technology re-\nquires professional validation through real-world landscape projects. \n\nIntroduction \n\nUpon reviewing a corresponding article on computer science, we developed a more comprehensive understanding of what can be generated with a Neural Radiance Field (NeRF) and, \nconsequently, the relevance and potentials of this technology and method in future developments of spatial design in general and more specifically, in landscape architecture. The NeRF \napproach comes from the computer science field of self-learning systems – as “neural” refers \nto “self-learning” – and we recognize the task of introducing this method to digital landscape \narchitecture as an urgency, which our contribution is centrally dedicated to. In this context, \nwe set out to generate on-site images – starting with the university campus and ending with \na significant flooded area after a disaster – that we could use for our related experiments with \nNeRF technology.  \n\nNeRF – Neural Radiance Fields \n\nNeural Radiance Fields (NeRF) is a method for novel view synthesis and volumetric scene \nreconstruction based on real-world training data. NeRF was introduced by (MILDENHALL et \nal. 2020) and, since then, has gained traction in computer vision and related fields (GAO et \nal. 2022, TEWARI et al. 2022). “In its basic form, a NeRF model represents three-dimensional \nscenes as a radiance field approximated by a neural network. The radiance field describes \ncolor and volume density for every point and for every viewing direction in the scene” (GAO \net al. 2022). The original approach by Mildenhall et al. “represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location (x; y; z) and viewing direction (\n)) and whose output is the volume density and view-dependent emitted radiance at that spatial location” (MILDENHALL et al. \n2020). The NeRF model uses a set of two-dimensional RGB images, and their camera poses \nto create synthetic three-dimensional scenes. These scenes can be rendered into new images \nor video animations of photo-realistic quality (GAO et al. 2022). NeRF models can also be \nexported as simple mesh models. Emerging from the field of computer vision, the primary \nfocus of the NeRF method is to produce visual representations of a scene, surface, or object. \nUnlike other methods and sensors in remote sensing and environmental modeling, NeRF does \nnot originate from a surveying or measurement context. NeRF uses internal coordinate sys-\ntems instead of geographic reference systems, which were not a priority in its development. \nIn the field of landscape architecture, the fact that the NeRF model is not connected to a real-world coordinate system that potentially links data to a ground-truth reference might be un-\nusual at first. The rooting in scanning and surveying that led to the rise of lidar point cloud \nmodels  in  the  field  is  being  replaced  with  a  kind  of  ground  truth  of  images.  The  article \n“Ground truth to fake geographies: machine vision and learning in visual practices” by GIL-FOURNIER & PARIKKA (2021) is of importance to this discussion and, particularly where the \nauthors argue that “ground truth has shifted from a reference to the physical, geographical \nground to the surface of the images.” \n\nA NeRF model is not limited to generating a radiation field but can also be used to generate \npoint-based radiation fields (XU et al. 2022) or voxel-based models (YU et al. 2021). Since \nits publication in 2020, the paper ‘NeRF: Representing Scenes as Neural Radiance Fields for \nView  Synthesis’  by  MILDENHALL et  al.  (2020)  has  inspired  many  researchers  to  advance, \nadjust, and refine their methods (GAO et al. 2022, TEWARI et al. 2022). Especially the processing speed metric has been a major threshold in making the method available to a wider \narray of users, as it is directly connected to the complexity of scenes and the hardware necessary for their generation. Comparing the element of speed between the newer and older \nmodels, we can observe that the former outperforms the latter by several orders of magnitude. \nWhile processing a specific scene takes twelve hours in 2020 (MILDENHALL et al. 2020), the \nsame scene takes only about five seconds in the middle of 2022 (MÜLLER et al. 2022).  \n\nGAO et al. (2022) provide an overview of existing literature grouped based on their focus on \napplications such as three-dimensional reconstruction, image processing, or urban applications. Especially interesting is a model for large-scale scene reconstruction (TANCIK et al. \n2022) that lets us envision potentially global scale models. Significant improvements have \nbeen made to NeRF models, creating a wide range of applications, including “urban mapping \n\/ modelling \/ photogrammetry, image editing \/ labelling, image processing, and 3D reconstruction and view synthesis of human avatars and urban environments” (GAO et al. 2022). \nRecent advances in NeRF model performance have also made this technology more accessible to professionals in related fields outside of computer vision. More specifically, professionals from fields involved in digital visualization and aesthetics, such as landscape architecture, will be encouraged to test and develop their own models in relation to their specific \ntasks and topics. \n\nNeRF Aesthetics \n\nCustomary techniques for reconstructing three-dimensional landscape scenes, such as point \nclouds or vectors derived from photogrammetry, result in models whose aesthetics are detached from their physical context – the surrounding landscape. Where the lidar scanner rays \nend for a point cloud model, a black hole opens as the model background. Such models represent their own digital aesthetics and stand in stark contrast to the realism of photography \nand film. From an aesthetic point of view, there was always a significant difference between \nthe navigable three-dimensional model and the modeled real scene. Lidar scans, or photo-\ngrammetric scene reconstructions, seem to be functionally limited by their rootedness in tech-\nnical correctness and dimensional accuracy. It is difficult to implement diverse, complex, and \nassociative topical links in these models. In contrast, NeRF technology translates the ability \nof photography or film to capture the full context of a scene, including the background, into \na complex three-dimensional model with an identifiable background (Fig. 1 and 2). A NeRF \nmodel generates a detailed reconstruction of variables, which are key in registering a scene. \nIn addition to position and color, other variables transferred to the model include light intensity, darkness, and transparency. The ability to incorporate these elements presents an unprecedented three-dimensional realism (Fig. 3). Point cloud models, with high point densities and an even distribution of points, appear sparse up close and denser from a distance, where \nthis  higher  density  does  not  correspond  to  increased  information.  Combining  point  cloud \nmodels with different resolutions or resampled data can thus be useful for creating large models. Christophe Girot describes such combined models through the term he coined as cloud-ism (GIROT 2020). As we have established the possibilities of the NeRF method, we propose to counteract the newfangled term cloudism, again with a classic term – realism. Landscape \nin the form of a model is still most accurately understood – by laypersons and experts alike \n– when it corresponds to the common appearance of the surrounding landscape. \n\nInstant-NGP \n\nFor the generation of our experimental NeRF outcomes, we used Instant-NGP (Instant Neural \nGraphics Primitives), an open-source software framework developed by NVIDIA. The software framework processes Neural Graphics Primitives that, in addition to NeRF, can also be used for Gigapixel images, neural Signed Distance Functions (SDF), and Neural Radiance Caching (NRC). Our paper is limited in scope to NeRF models. Instant-NGP is proving to be \none of the most popular and regularly updated NeRF generation solutions. It trains a NeRF \nin seconds using multi-resolution hash encoding. The coordinates are hashed and used as an \nindex into a stack of multi-resolution data arrays, drastically reducing the number of parameters per model. The NeRF model is constrained by a unit cube bounding box set at a coordinate space of [0,1]³. The model has the highest resolution around a central point positioned \nat the center of the unit cube, at [0.5, 0.5, 0.5]. \n\nCase Study Ahr River Valley \n\nFor our initial experimentation with the application of NeRF technology, we focused on the \ncase of the Ahr Valley in Germany in the aftermath of the 2021 flood disaster. We obtained \nthe related fieldwork data through camera tours and UAV flights on-site. In the summer of \n2021, between July 12th and July 15th, the Ahr River Valley experienced a 100-year flood as \na result of pronounced heavy regional rainfall events in connection with a low-pressure system. In addition, the soils in the affected regions of Rhineland-Palatinate and South West-phalia could hardly absorb any additional water (GERMAN WEATHER SERVICE 2021). After the flood,  which took the lives of  many people and caused extreme destruction, the  hasty \nreconstruction activity did not necessarily lead to sustainable design and building. \n\n“The moment after a natural disaster is a window of time that can be used to adapt-to-climate \n(change), but this opportunity is in many cases demonstrably wasted. […] After a disaster, \namnesia leads people to forget about what primarily should be designed and built” (REKITTKE \n& NINSALAM 2022). Without a thorough analysis of a disaster, economically and ecologically \nsensible decisions become unlikely. There is a danger in conducting post-disaster analysis \nand the subsequent planning and design relying solely on documents like maps or legal texts, \nwhich operate on a high level of abstraction. It is imperative to incorporate what the people \nthemselves have seen (REKITTKE & NINSALAM 2022). We are interested in NeRF technology \nfor this particular reason, as it opens up new possibilities for visual realism and the ability to \nintegrate different temporal layers into a single landscape model. Disasters reveal snapshots \nof many aspects that should have been taken into account during planning phases and are \novershadowed once the developments are carried through a short time later. In this pursuit, \nwe  aspire  to  preserve  the  memories  of  a  flood  disaster  by  creating  appropriate  landscape models. Like in an autopsy, the aim is to fill the common gap between reality, recollection, and  forward  planning  with  evidence  that  is  supposed  to  trigger  cogitation (REKITTKE  & NINSALAM 2022). \n\nData Collection and Processing \n\nFor testing NeRF models in the context of post-flood Ahr River landscapes, we created an \nextensive dataset consisting of 106 video and image samples using UAV-mounted cameras \n(Fig. 4) and ground-based handheld smartphone devices. Our data were collected in two separate sessions. The first was during the flood event in July 2021– sporadic and ad hoc. The \nsecond was in September 2022, in the course of systematic fieldwork. Our aim was to create \ncases using one of the most common NeRF methods available. All NeRF models were trained \nlocally using Instant-NGP. The GitHub repository (GITHUB \/ instant-ngp 2022) provides documentation  on  software  and  hardware  requirements,  installation,  pre-processing,  training, \nand rendering NeRF, as well as exporting. Another document on GitHub provides additional \nadvice on the process (GITHUB \/ nerf_dataset_tips 2022). We created a separate NeRF model \nfor each set of input data, following a list of six sequential processing steps: 1) data acquisition, 2) data pre-processing and frame extraction, 3) pose estimation, 4) NeRF model training, \n5) video export, and 6) post-processing. \n\n1) Data acquisition for each site was carried out using lightweight, field study-ready collection devices: a DJI Mini drone and an iPhone 11 Pro. For all data acquisition, we used the \nhighest  possible  resolution  of  the  devices.  The  drone  videos  were  shot  at  2.7K  resolution \n(2720x1530), 23,97 fps, in MPEG-4 format. With the smartphone camera, we shot videos at \nFull HD resolution (1920x1080), 59,94 fps, in MPEG-4 format, and pictures at 12MP resolution (4032x3024), in JPEG format. Shots in the  wide-angle camera  mode (0.5x, 13 mm \nequivalent focal length, 120° field of view) were particularly effective. In total, we collected \n96 videos and 10 image sequences, a raw data package of 35 Gigabytes. \n\n2) For the video shots from the field, we extracted a set of sequential frames ranging from 50 \nto over 400 images. The image sequences were filtered to the same amount. NeRF models \nbased on the method of Müller et al. (2022) do not infinitely increase resolution or quality \nwith a more extensive set of input images. Mildenhall et al. (2020) and Müller et al. (2022) \nuse tens to hundreds of images to train NeRF models. We followed the recommendations \npresented on the GitHub forum (GITHUB \/ nerf_dataset_tips 2022). Furthermore, we tested \nthe application of digital image enhancement techniques such as sharpening, noise reduction, \nand super-resolution to improve matching image detection. \n\n3) We used the COLMAP pipeline that was part of the Instant-NGP codebase to process an \nestimate of the camera poses for each image set. The resulting JSON file containing the camera parameters for each image was saved in a folder along with the original images in the \nformat TRANSFORMS.JSON. \n\n4) We trained our NeRF models using the interactive GUI (Graphical User Interface) that \nwas included in the codebase. The GUI offers a variety of different tools for training, visualization, and export, as well as allowing the user to interactively move through a scene while \nthe  model  is  being  rendered  in  real  time.  Training  begins  by  launching  the  GUI  from  an \nAnaconda prompt, and within seconds, the model evolves from blurry noise to a clear representation of a scene. Once the training reaches a satisfactory level, the training progress can \nbe saved as a JSON file – called snapshot – which can be used to reload the NeRF model or \nto create an animation. The GUI facilitates interactive creation and saves a camera path along \na set of key frames that can be used to export a video animation. \n\n5) The codebase allows exporting of flythrough video animations of the NeRF model using \nthe previously generated training progress and camera path. The export is handled outside \nthe GUI in an Anaconda code prompt using Python bindings. We exported a range of video \nanimations up to 4K resolution at 30 fps. \n\n6) The exported videos can be easily edited using common video and image editing tools. \nSince both the input and output of the NeRF model are image-based, digital editing and processing  pipelines  such  as  image  sharpening,  noise  removal,  or  frame  interpolation  can  be \napplied before and after NeRF modeling. The user has full control over both pre- and post-NeRF model media, as would be the case with photography, photogrammetry, or map-making. \n\nNeRF for Landscape Architecture \n\nAlthough we have been working with NeRF technology for a limited time and therefore did \nnot  yet utilize its full potential,  we can already identify and highlight some of its specific \nstrengths.  We  offer  a  selection  of  tested  applications  for  NeRF  technology,  generally  for landscape architecture and, more specifically, in the context of our case study. In addition to \nthe enormous technological advances that have determined the rise of NeRF technologies in \nrecent years, the method has to be tested in relation to issues concerning landscape architecture. \n\nMulti-Resolution Models \n\nFor NeRF models, it applies that their resolution is not developed in relation to the model but \nto the depth of information captured from the input images. “The multiresolution aspect of \nthe hash encoding covers the full range from a coarse resolution \nmin that is guaranteed to \nbe collision-free to the finest resolution \nmax that the task requires. Thereby, it guarantees \nthat all scales at which meaningful learning could take place are included, regardless of sparsity” (MÜLLER et al. 2022). In the context of the Ahr Valley after the flood, we are able to \ncreate a lightweight but complex three-dimensional model that enables capturing environ-\nments at multiple scales: from the rocks in the Ahr riverbed to the flowing water, from the \nriverbanks and adjacent vegetation to patterns of the urban fabric, and from the mountains in \nthe background to the clouds in the sky above the valley. The main benefit we see in our \ncase-based NeRF models is that they feature a high spatial depth, capturing the sky, clouds, \nand even distant landscape features such as mountains, valleys, and urban areas. In the case \nof the Ahr Valley, the NeRF model consolidates all flood-relevant factors to be discussed \nsimultaneously in one model: the change in sediment flows in the river, the altered course of \nthe river, the destruction of urban settlements and agriculture in the Ahr valley near the floodplain,  the  topography  of  the  valley  where  water  has  accumulated  downstream.  More  advanced NeRF models can present the rich contextual depth of the mapping in the form of a \nnavigable three-dimensional model. Xiangli et al. (2022) outline the nature of such prospective models by expanding the notion of rendering scenes at multiple resolutions by “modeling \ndifferent scenes at multiple scales with drastically varying views on multiple data sources” \n(XIANGLI et al. 2022). \n\nObject Focus versus Open World Scene? \n\nBased on our current research and studies, we observe a certain level of contradiction regarding the  great landscape potential of NeRF  models and their technical  nature. NeRF is designed to feature a central point in the model, from which the resolution gradually decreases towards the edges of the bounding cube. This raises the question of whether NeRF models \nare inherently object-oriented (single object) and how this might impact the modeling of non-point-centric open-world scenes, such as landscapes. Is our positive assessment of the NeRF \nlandscape model accurate, or will the triumph of the NeRF models primarily extend to object \nmodels, for example, in the context of architectural projects? Instant-NGP NeRF models are \nconstrained by a maximum resolution bounding box at its center. But in our case study, we \nfed this “machine” exclusively with data from landscape photography and landscape videos, \nthereby obtaining effective landscape models. We suggest that future explorations are “to be \ncontinued.” \n\nComparison to Photogrammetry and Point Cloud Models \n\nThere are partial overlaps in data collection and processing methods between NeRF models \nand photogrammetric processing. Both methods use two-dimensional raster images as input \ndata and share further similarities in the initial processing of this input data. A wide range of \nNeRF methods, including the one of Müller et al. (2022), use COLMAP, a package for SfM, \nto extract camera poses. Models derived from lidar scanning or photogrammetric modeling \nstill offer higher geometric accuracy than NeRF models (LEHTOLA et al. 2022). For our own \ncomparison of the different methods, we created a set of 406 frames from a selected drone \nflight, which we used as input for corresponding NeRF and photogrammetric models. The \nNeRF model was generated with Instant-NGP, and the photogrammetry model was processed \nas a dense point cloud in Agisoft Metashape. The point cloud was exported as a file in LAS \nformat with 12 million points and a file size of 326 MB. \n\nThe output quality of a photogrammetry process is assessed based on the accuracy of where \nthe resulting points are positioned with respect to a ground truth reality. Passive sensing data, \nsuch as intensity return data or true color imagery captured by other sensors, may only suport subsequent analysis or enhance visualization. In many ways, the NeRF model sits somewhere between the perception of space and the perception of textures, materials, light, and color. There are various metrics can be used to assess the quality of a NeRF model. Many \nfundamental advantages of photogrammetry, such as a relation to a “real world” Coordinate \nReference System (CRS) and transformations of the model with respect to this CRS, are not \nyet realized in the NeRF system we used. Nonetheless, this does not preclude the possibility \nof implementing them in future applications. \n\nA NeRF differs from all the traditional three-dimensional scene formats commonly used in \nthe field, some of which include vectors or meshes, grids, and point clouds. Each format can \nhave distinct ways of formulating a representation, which can yield a unique set of advantages \nand disadvantages depending on the format used. It can therefore be difficult to judge a NeRF \nin relation to the qualities of these formats. Some of these metrics may be embedded in the \nprocess or acquisition technology used for data generation to determine the potential for accurately representing a scene from the start. Different metrics apply to data obtained from \nphotogrammetry or lidar scanning. Such comparisons exist in various areas that are tangentially linked to landscape architecture, for example, in heritage preservation. Data obtained \nthrough lidar scanning is among the most accurate geometric data available in modern scanning techniques but lacks the ability to accurately capture the texture and diagnostic color \ninformation  (DOSTAL  &  YAMAFUNE  2018).  Perhaps  the  most  fascinating  outcome  of  the \nmethod is not the NeRF model itself but the images and videos that are generated from the \nmodel (Fig. 5 and 6). MILDENHALL et al. (2020) state that the results of view synthesis are \nbest viewed as videos. \n\nMaterial Noise \n\nMetrics such as reflection or change in transparency and color as a function of position are \nnot considered part of the physical enterprise of the object or scene in the current literature \non photogrammetrically derived models. Rather, they are viewed as  factors that distort or \ncorrupt the signal in ways that may need to be eliminated in order to derive a high-quality \nmodel.  In  scenes  produced  by  photogrammetry,  removing  water-surface  reflection  effects \npresents a challenge (PARTAMA et al. 2018). Materials featuring difficult optical properties –including but not limited to absorptivity, reflectivity, scattering, challenging texture and complex shape or geometry – still pose challenges in photogrammetry (NICOLAE et al. 2014). The \ndistinction between signal and noise is pronounced in the literature on photogrammetry and, \nmore generally, in remote sensing and earth observation. The NeRF model, on the other hand, \nallows data otherwise defined as noise to be used to visualize unstable materialities, surfaces, \nand objects. In our case study, for example, we had the means to illustrate the unstable nature \nof the Ahr River – with its changing water levels up to extreme flooding conditions. \n\nMulti-Source NeRF \n\nA multi-source model is based on input data generated through multiple acquisitions for the \nsame or a similar area. This method can be used in situations where only a sparse set of input \ndata is available to increase the resolution of the NeRF model by adding additional input data \nfor angles or features not previously captured. For our case study, we trained a NeRF model \nof the Kalvarienberg Monastery and the surrounding area in the town of Ahrweiler with sev-\neral of our drone acquisitions and eventually improved the model’s resolution. In addition, \nour model captures the changing light conditions between diffused and direct sunlight caused \nby different cloud conditions during the recording period. The various parameters – geometry, color, lighting, texture, and translucency – captured by a NeRF model may be acquired \nindependently. Each parameter can be derived from a separate set of input data. The final \nNeRF synthesis model allows navigating between these parameters in relation to the position \nand direction of a particular view. In working with a 3D landscape model, this synthesis is a \nnovelty that opens up considerable potential. \n\nMulti-Temporal NeRF \n\nIt sounds almost unattainable within the limitations and resources of our current time, but a \nsimultaneous coupling of movement through time, and movement through space, is fundamentally possible with NeRF technology. This option is yet to be defined and therefore, we \npropose to use “Multi-temporal NeRF models” when referring to the visualization of changing layers of time in the course of changing positions. Multi-temporal NeRF models use mul-\ntiple sets of images captured at different times and utilize them as the input to produce novel \nviews that interpolate between the images. The model synthesizes the input data and allows \nit to move through time while moving through space. A Multi-temporal NeRF model makes \nit possible to capture movements, visualize ongoing processes, and depict all kinds of patterns \nof change. For example, the growth or the changing state of the health of vegetation can be \ndocumented in this way. The intensity of the changes captured by the model can be related \nto the temporal extent of the capture and the intensity of the change in the underlying object \nor  study  surface.  Multi-temporality  is  a  common  concept  and  method  in  geosciences,  in \nwhich remote sensing  observations collected at different times are combined into a single \nmulti-temporal image or model. Multi-temporal analyses enable the detection and visualiza-\ntion of changes in  spatial patterns over  time. The concept  has  taken root in areas  such  as \narchitecture and landscape architecture to understand changes in the built environment. The \nlandscape architect, in particular, can think of numerous possible uses. The depiction of seasonal changes in the city, landscape, and vegetation are only a few of them. We find this \nmethod to be the most effective to this date for purposes of representing the “before” and \n“after” conditions of a site. \n\nIn 2021, it was already demonstrated that NeRF models could be trained with unstructured \ncollections of photographs taken at different times, from different angles, and under different \nlighting conditions. The model registers the static geometries of the scene but interpolates \nbetween color and illumination in dependence on the view position (MARTIN-BRUALLA et al. \n2021). It is possible for a NeRF to process a sequential set of images of the same scene at \ndifferent  times  of  the  day,  times  of  the  year,  and  so  on.  The  associated  different lighting \nconditions of these different images, which show a time difference, allow the generation of \nan outstanding level of multi-temporality in a single NeRF result. The resulting model allows \nthe user to literally move through time as they move through space – made possible by adjusting the different radiation fields between the time-shifted images. \n\nIn our case study, the Multi-temporal NeRF shifts the digital model from a state of representation to a state of simulation of the underlying flood event. Our NeRF model captures and \ninterpolates  situations  found  in  two  self-contained  trajectories.  The  model  combines  two \ndrone flights – one in 2019 and the other in 2022 – over the Ahr Valley municipality of Rech, \nGermany. The acquisition from 2019 shows a historic bridge over the Ahr River, connecting \nthe two halves of the village. The second acquisition captures the same location in the autumn \nof 2022, after the flood event destroyed parts of the bridge, swept away several buildings \nsouth of the bridge, and visibly changed the course of the river (Fig. 7). Both drone flights \nhave different trajectories and viewpoints, allowing us to create a model relating one set of \nviews to the 2019 acquisition and the other set of views to the 2022 acquisition. In the resulting NeRF model, we can navigate through the internal digital coordinate system and observe \nthe changing states in quasi-real-time. \n\nFlooding as a Multi-Temporal NeRF Application \n\nDue to the presence of temporal components – such as large amounts of water that flows in \nand out of a particular site – flood zones are generally considered to be suitable for the application of multi-temporal NeRF. Instant-NGP’s interactive GUI also provides a set of visual \ndebugging tools that can be used to uncover the internal structure of input and output neurons. \nThe parameters of these tools are recorded as part of a keyframe animation. For our case \nstudy dealing with speculative scenarios of a flood-ravaged valley, we used the partial acti-\nvation of neurons as a rising green light field to simulate the rising waters of the flood through \nvisuals (Fig. 8). Through this experimentation, we found a simple yet very powerful tool for \ndigital flood simulation with full visibility of all model elements. Supporting this hypothesis \n(LI et al. 2022) have shown that NeRF models can be used to simulate ultra-complex climate \nevents. \n\nConclusion \n\nThis paper presents a baseline study on  various approaches and  methods of  working  with \nNeRF models in landscape architecture. The aim is to inspire and encourage researchers in \nrelated fields to develop in-depth studies on the applications of NeRF. Our interest in NeRF \nis fundamentally rooted in the idea that landscape is anything but static, which is, at the same \ntime, where we find significant potential in this approach. NeRF models can be useful for \n“wandering” through changing light conditions or addressing moving objects, such as water, \nclouds,  birds,  cars,  trains,  and  others.  Different  materials  can  be  evaluated  through  direct \ncomparison.  Reflections  and  light,  as  well  as  structure,  can  be  included  in  their  changing \nappearance. Changed terrain, for example, differing terrain heights in the course of a construction project, can be evaluated. In addition, the same scenes and objects could be recorded \nunder different lighting conditions in order to enable a critical evaluation. For example, early \nin the morning, at noon, in the evening, or in cloudy weather. The NeRF interpolates between \nthe input images, allowing for seamless switching between different states within the result-\ning model. It is an important task to think of a landscape model not as a static set of coordi-\nnates, i. e. point clouds, raster, or vector data, but as a set of parameters that are constantly \nchanging. As in a landscape as such, the model changes depending on the viewer’s position \n– an unstable model. The fact that NeRF crosses the border between modeling and simulation \nsuits the instability and openness of the landscape subject. We are dealing with a technology \nthat is still very new and largely untested but whose potential seems enormous. Most com-\nputer graphics algorithms and techniques developed over more than half a century assume \nmeshes or point clouds as three-dimensional scene representations for rendering and editing. \nNeural rendering, on the other hand, is such a recent field that the term was first used in 2018. \nFor this reason, there is an inevitable gap between the available methods that can work with \nclassic three-dimensional representations and those that can be applied to neural representa-\ntions (TEWARI et al. 2022). This is definitely true for the field of landscape architecture, and \nwe look  forward to the developments and publications that  will qualify NeRF  models for \nlandscape architecture in the years to come. \n\nIn 2019, Christophe Girot described how the point cloud model overcomes the separation \nbetween model, architectural drawing, renderings, or other visualizations. “In the “cloudist” \napproach, there exists no separation between a model, a section and a plan: they all stem from \nthe same cloud of design information. Separate renderings or visualizations become quite \nunnecessary, since the views generated are directly derived from the model, with their own \nsingular  aesthetic”  (GIROT  2019).  NeRF  models  remove  the  threshold  between  different \nforms of representation (Fig. 9). The NeRF method offers qualities similar to point clouds \nbut significantly reduces the separation or the visual contrast between the model and reality.\n\nThe Influence of Perceived Landscape Qualities on \nEconomic Vitality: A Case Study of a Retail Coffee \nChain \n\nAbstract: As a crucial aspect of vitality, the economic facets of vitality at the store level have yet to be \ninvestigated in greater detail, and its relationship with micro-level perceived landscape qualities in the \npublic realm requires further examination. The recent advancements in big data and Machine Learning \n(ML) have presented an exceptional opportunity to empirically investigate vitality and its association\nwith the urban built environment. This research aims to comprehensively gather various dimensions of\neconomic vitality for retail coffee chain, using Starbucks stores in Hong Kong as a case study. The\nstudy incorporates the previously under-researched dimension of customer sentiment, which is interpreted through the Natural Language Processing (NLP) model. Additionally, the study collects both\nsubjectively measured landscape perceptions and objectively extracted visual features from street view\nimagery (SVI) using ML algorithms and crowdsourced surveys. Results indicate that micro-level perceived landscape qualities, such as scale and signage, have a greater impact on economic vitality than\nconventional macro-level planning characteristics. The findings of this research have the potential to\ninform and support a successful and economically dynamic retail model at the neighbourhood scale,\nfurther emphasizing the economic significance of human-scale landscape design in the public realm.\n\nIntroduction \n\nUrban vitality has long been considered a critical aspect of successful cities in place making, \ncontributing to resilience, creativity, and innovation for sustainable development (CHEN et \nal. 2022, MONTGOMERY 1998). First introduced in JACOBS (1961)’ seminal book, and initially defined as the presence of active street life, the concept of vitality has evolved into a \nmulti-faceted connotation that encompasses various dimensions, with economic vitality being regarded as a critical component (HUANG et al. 2020). \n\nQuantifying vitality remains a challenge due to its complex nature, encompassing both social \nand economic aspects. Previous studies have used macro-scale indicators, such as the number \nof entertainment facilities within a city, to measure vitality. However, with the rise of big \ndata,  new  opportunities  have  emerged  to  quantify  vitality.  Despite  this,  researchers  have \npointed out that some big data sources, such as cell phone records, have relatively low data \nquality. Therefore, researchers have shifted to using the intensity of geo-tagged catering businesses from POIs to measure economic aspects of vitality (XIA et al. 2020, YE et al. 2018). \nAlternatively, LONG & HUANG (2019) compared economic vitality across hundreds of cities \nin China using crawled numbers of reviews from popular social media websites that collects \nratings for restaurants. More recently, researchers have proposed more complex frameworks \nthat utilize information available from online service evaluation platforms, such as incorpo-\nrating service quality and scale in addition to popularity (LI et al. 2022). In conclusion, the \nspatial organization of small food establishments plays a significant role in reflecting human \nactivity patterns. Utilizing customer reviews to gather information about economic vitality \nhas also proven to be a valuable approach. However, these methods fail to consider the emotions  and  sentiments  of  user  groups,  which  play  a  crucial  role  in  the  human-environment \ninteraction and contribute to the economic and social aspects of individual businesses at a \nmicro-level (LIU et al. 2020). Additionally, calculating an overall vitality index using certain \nweighting methods for each dimension may be inexorably subject to bias, as different businesses may provide different types of services and target distinct demographic groups with \nvarying economic statuses. \n\nIn view of these factors, exploring the economic vitality of chained catering services, specifically  coffee  retail,  can  provide  an  innovative  approach  for  comparison  across  different \nstores. Coffee retail is often considered a crucial type of \"third place,\" where people gather \nfor socializing without an obligation to stay. It creates a sense of place, a key aspect of promoting  vitality  (OLDENBURG  1989).  The  success  of  coffee  retail  is  influenced  by  various \nfactors such as the environment, service quality, context, and food and beverage offerings. \nHowever, literature in the hospitality industry suggests that chained coffee shops often use \nstandardization and intra-regional diversification strategies based on ‘portfolio theory’ to reduce costs, providing a tactical advantage and greater survival rates over single-location franchises (PARK & JANG 2022). As a result, the differences in services and food offerings between stores within the same chained business can be largely ignored when comparing their \neconomic vitality, offering a solution to the limitations of previous methods. \n\nOn the other hand, previous research has shown that the design of the built environment can \naffect vitality. For instance, building morphology, density, typology, and land use mix have \nall been linked to vitality (HUANG et al. 2020, LONG & HUANG 2019, XIA et al. 2020, YE et \nal. 2018). However, these studies focused merely on objective environment factors at a macro \nand planning scale, but  neglected the nuances of daily life experience and the micro-level \nperceived landscape qualities which can be critical in promoting vitality. \n\nPerceived landscape qualities can be measured objectively, subjectively, or through a combination of the two measures. Advancements in Computer Vision (CV) technology have allowed for more efficient and high-throughput methods like using emerging urban data such \nas SVI to measure perceived qualities (DUBEY et al. 2016, ITO & BILJECKI 2021, ZHANG et \nal. 2018). In a nutshell, the perceived landscape qualities can be largely categorized into subjectively measured design perceptions and objectively measured visual elements (QIU et al. \n2022). These human-centric perceived qualities, which can proxy how people perceive the \nenvironment when walking down the street, have been used to examine the impact of microlevel  perceived  landscape  qualities  on  walking  behaviour  or  housing  prices  (BASU  & SEVTSUK 2022, SONG et al. 2023, SONG et al. 2022).  \n\nThough several recent studies have sought to reveal the correlation between perceived land-\nscape qualities and street vitality (CHEN et al. 2022, JIANG et al. 2022), they mainly focused \non pedestrian volume as a representation of vitality and only  studied a limited number  of \nperceived landscape qualities. Further research is needed to investigate how perceived environment qualities contribute to the economic vitality of coffee retail at a micro-scale. Additionally, due to differences in measurement methods, subjectively measured perceptions have \nbeen shown to exhibit different spatial heterogeneity patterns in comparison with their objective counterparts (SONG et al. 2022). Thus, their separate impacts on economic  vitality \nwarrant further understanding. \n\nIn conclusion, our research endeavours to address the existing knowledge gaps by integrating \nthe human-environment interaction into the measurement of economic vitality across chained \ncoffee stores, and examining how economic vitality is influenced by quantifiable micro-level \nperceived landscape qualities measured through both subjective and objective methods. Our \nresearch offers new insights in the following aspects: \n1) It sheds light on the multiple dimensions of economic vitality of chained coffee shops at \nthe store level and incorporates customer sentiment using advanced Natural Language \nProcessing (NLP) techniques. \n\n2)  The study measures both subjectively measured perceptions and objectively measured visual elements from SVI with ML tools.  \n\n3)  The relationship is disclosed between the perceived landscape qualities within the walking  radius  around  each  store  and  the  various  dimensions  of  economic  vitality,  by  the \ncomparison of the perceived landscape qualities with macro-level factors in relation to \neconomic vitality. \n\nData and Methods \n\nStudy Area and Data Source of Economic Vitality \n\nThe study area is Hong Kong, a high-density city that is one of the world's largest financial \ncentres with over 7 million residents. To control for factors that could impact the economic \nvitality of different services, chained coffee stores were selected for our investigation using \nbig data. By choosing stores from a single brand, the research can mitigate the influence of \nfood quality, service, and interior design and focus instead on other key factors such as the \nquality of the outdoor street environment and macro-level spatial qualities such as accessi-\nbility to transportation and points of interest (POI). This approach offers a straightforward \nresearch  design,  which  provides  a  clearer  understanding  of  the  economic  vitality  of  these \nstores compared to previous studies that have utilised a more broad-brush approach, observing citywide vitality in a coarser grid. Specifically, Starbucks coffee is chosen, a global market leader with over 150 stores in our study area. The analytical framework of this study can \nbe seen in Fig. 1. \n\nThe search results were finalised using the Google Map API, which returned information for \n158 Starbucks stores (Fig. 2) located throughout Hong Kong after initial data cleansing. It is \nworth mentioning although data was also obtained from the local restaurant evaluation platform 'Open Rice', the number of reviews for Starbucks Coffee on this platform was insufficient, so this data was not included in the study. Information gathered from the web crawl for each store comprised its geographic coordinates, address, and, most importantly, information on reviews, including the number of reviews, the number of review images, overall review score, review score distribution, and detailed review text (the 20 most recent reviews after January 2017).  \n\nNLP  is  a  field  of  Artificial  Intelligence  and  computational  linguistics  concerned  with  the \ninteractions between computers and human (natural) languages. It enables the interpretation \nof the human language in a meaningful way, for instance, to understand the emotions. Senti-\nment scores were calculated for each store based on its review texts using the state-of-the-art \nBidirectional Encoder Representations from Transformers (BERT) model, an NLP technique \nthat  uses  a  self-attention  mechanism  and  eliminates  biases  from  left-to-right  momentum \nwhich was used in previous models. The use of BERT has been increasing in recent studies \n(ALAPARTHI & MISHRA 2021). The  model  was pre-trained on a review dataset containing \n150k reviews and reported to achieve an exact prediction accuracy of 67% and an off-by-1 \nscore prediction accuracy of 95% for reviews in English. The sentiment score for each store \nwas calculated as the average of the sentiment scores interpreted from its crawled reviews, \nwith a score between 1 and 5, where 3 represents a neutral sentiment, 5 represents the most \npositive sentiment, and 1 represents the most negative sentiment. \n\nMeasuring Micro-level Perceived Landscape Qualities  \n\nThe street network for this  study  was obtained from  OpenStreetMap and points along the \nHong Kong road network were sampled every 50m using the QGIS platform (ZHANG et al. \n2018). To examine the correlation between perceived landscape qualities and economic vitality, points were selected within the 250m walking radius around each of the chained coffee \nstores located on the ground floor. Points located on highways were excluded as they do not \nreflect the pedestrian experience. The coordinates of points were fed into the Google Street \nView Static API and street view images (SVI) were obtained (heading = 0, field of view = \n90, image size = 800 x 400 pixels). After discarding grey or indoor images, 2,110 SVIs were \nleft and used for further analysis. \n\nTo extract objectively measured visual features from SVIs, the widely used ML algorithm \nPSPNet pre-trained on the ADE20K cityscape dataset was adopted. Around 20 streetscape \nelements, such as sky, sidewalk, trees, buildings, etc., were successfully extracted from each \nSVI. The view index of each visual feature (i. e., the percentage of an element  within the \nentire image) was calculated and the average value of each element within the walking radius \nwas used as the perceived objective feature quality for each store. A randomly sampled SVI \nand its semantic segmentation result using the PSPNet algorithm are shown in Fig. 3. \n\nMeanwhile,  in  accordance  with  previous  studies,  we  aimed  to  quantify  eight  subjectively \nmeasured design perceptions: typology, order, ecology, enclosure, aesthetics, accessibility, \nrichness and scale (EWING et al. 2006, SONG et al. 2022; TIAN et al. 2021). To achieve this, \nwe utilised perceived quality scores obtained from 300 SVIs, with 80% used for training and \n20% for testing, gathered from crowdsourcing surveys in a previous study (TIAN et al. 2021). \nThese scores served as the dependent variables, while the view indices of key street elements \nserved as the independent variables for the prediction task. \n\nEight ML algorithms were used and compared for prediction performance: K-Nearest Neighbours (KNN), Support Vector Machines (SVM), Random Forest (RF), Decision Tree (DT), \nGaussian Process (GP), Voting Selection (VS), ADA Boost (ADAB) and Bagging Regression  (BR).  The  ML  models  were  evaluated  by  using  R-squared  (R2)  and  Mean  Absolute \nError (MAE). The best-performing model for each subjectively measured landscape quality \nwas then selected to predict the scores for the entire SVI dataset in Hong Kong. \n\nMacro-level Conventional Planning Qualities and Correlation Analysis \n\nIn  addition  to  the  micro-level  perceived  landscape  qualities,  macro-level  planning  factors \nwere also computed to evaluate their impact on vitality. A 1.5 km buffer was created around \nthe centre of each store location, and the relevant  variables  were obtained from the Hong \nKong Geodata Store (https:\/\/geodata.gov.hk\/gs\/) and processed in QGIS. The variables included ‘number of POIs’, ‘number of hotels’, ‘number of Airbnb’, ‘number of elderly facilities’, ‘number of bus stops’, ‘distance to metro station’, and 'size of park area', which have \nbeen reported to contribute to street vitality. For example, accessibility to transportation facilities such as the distance to metro stations and the  number of bus stops can impact the \npotential crowds around the station. The accumulation of destinations (number of POIs) can \nattract people and promote vitality. Meanwhile, park size represents the neighbourhood-scale \nenvironmental quality, which contributes to subjective well-being and often attracts people. \nAdditionally, Airbnb can attract tourists and is essential to vitality. \n\nThe  study  conducted  further  statistical  analysis  to  determine  the  correlations  between  the \ndifferent dimensions of economic vitality of ground-floor stores and various groups of built \nenvironment qualities. Pearson correlation analysis was applied to provide a comprehensive \ncomparison between macro and micro-level factors and their relationship with economic vitality.  \n\nResults \n\nComparison of Economic Vitality \n\nThe 158 Starbucks Coffee outlets in Hong Kong are dispersed throughout various regions of \nthe city. Among these outlets, about 13 stores are located in the ‘Central’, which is its most \nconcentrated area, 91 stores of them on the ground floor and 67 stores on other floors ranging \nfrom -1st to 9th level. Because the intent of this research is to assess the economic vitality \nand its relationship with the surrounding context and integrates the Sentiment analysis based \non reviews, those review numbers were excluded if they were less than 30 times, and 127 \nstores were left. And because the stores located on the ground level have more direct interactions with the built environment, the stores on other levels were further removed, and 79 \nstores located on the ground level left. The detailed statistics are demonstrated in Table 1. \n\nAlthough only ground-floor stores were utilized for further analysis, a preliminary comparison was performed with stores located on other floors to identify potential biases. And the \nstatistics revealed similar results. In summary, ground-floor stores make up approximately \n60% of the total stores analysed. The average rating for these stores is slightly higher compared to those on other floors. The image count suggests that customers are more likely to \ntake and post photos in stores located on the ground floor, which may be due to the surrounding built environment. With regards to sentiment scores, it can be concluded that stores received overall positive sentiment scores, as a neutral emotion is rated as 3.0 on the scale used. \n\nML Model Performances \n\nMultiple  ML  algorithms  were  used  to  determine  the  most  effective  models  for  predicting \nsubjectively measured perceptions. As shown in Table 2, while four out of eight variables \n(Typology, Order, Aesthetics and Richness) had low  R-squared (R2) values and  were ex-\ncluded from further analysis, the qualities of Access, Ecology, Enclosure, and Scale achieved \nR2  values  ranging  from  0.40  to  0.53.  These  prediction  accuracies  are  deemed  acceptable \ngiven the size of the training sample, and they partially outperformed results from previous \nstudies  (DUBEY  et  al.  2016,  ITO & BILJECKI  2021,  SONG et  al.  2022).  Therefore,  the  four \nselected perceived landscape qualities were predicted for all SVIs using the best-performing \nmodels (i. e., Gaussian Process, Voting Selection, and Bagging Regression). After determining the qualities of each street view, we linked them to the corresponding Starbucks store \nlocations  and  obtained  the  mean  value  for  each  store  as  the  neighbourhood's  subjectively \nmeasured perceptions. \n\nCorrelation Analysis and Discussion \n\nThe Pearson Correlation analysis was conducted to investigate the correlation between the \nfour dimensions of economic vitality and selected macro-level spatial attributes (Fig. 4). The \nresults indicate that many macro-level factors had a moderate to weak positive correlation \nwith the review count. For instance, besides the most prominent impact of Airbnb (0.3), bus \nstops, POIs, and hotels also showed a similar positive association with the review count (0.26 \nto 0.27). The image count showed a weak positive relationship with bus stops (0.21). However, the correlations between the overall score and sentiment score and macro-level planning \nfactors were negligible. Despite this, POIs (-0.16) and hotels (-0.16) had the highest strengths \nin correlation coefficients with the sentiment score, suggesting that they may have a poten-\ntially negative impact on visitors' emotions, which in turn may negatively affect the economic \nvitality of the stores. \n\nWe conducted a separate analysis for the micro-level perceived landscape qualities (Fig. 5). \nOn the one hand, out of the four subjective perceptions, the quality of Scale, showed a mod-\nerate positive correlation with the review count (0.35), while its correlation with the image \ncount was weaker (0.23). Additionally, the review count demonstrated a weak positive correlation  with  Enclosure  (0.27)  and  a  weak  negative  correlation  with  Ecology  (-0.27). The \noverall review score showed a positive correlation with Ecology (0.2). Similar to the macrolevel spatial qualities, the correlations between sentiment and subjective landscape qualities \nwere statistically negligible. However, Ecology reported the highest positive impact (0.15) \non sentiment. \n\nOn  the  other  hand,  the  correlations  between  the  objectively  measured  visual  features  and \neconomic vitality dimensions were similar in strength to the subjectively measured percep-\ntions. The review count demonstrated a strong positive correlation with signboard (0.42). \n\nAdditionally, the review count showed comparable weak positive correlations with several \nother visual elements, including sky (-0.24), tree (-0.25), road (-0.26), streetlight (-0.26), and \nrailing (-0.26). It also reported a weak positive correlation with building (0.23). The image \ncount exhibited a moderate positive association with signboards (0.3) and weak negative re-\nlationships with the sky (-0.21) and road (-0.22). The sentiment demonstrated a positive cor-\nrelation with trees, showing its consistency of correlation with the Ecology perception (0.15), \nthough the correlation strength is statistically insignificant. \n\nOur study provides a brand-new insight into the hitherto poorly understood relationship between store-level economic vitality and built environment factors. Most importantly, it was \nobserved that compared to macro-level variables, micro-level perceived landscape qualities \nexhibit  stronger  correlations  with  economic  vitality  dimensions.  Additionally,  objectively \nperceived visual features were found to complement subjectively measured perceptions. For \nexample,  signboard  was  found  to  have  the  highest  impact  among  all  perceived  landscape \nqualities, offering meaningful design suggestions for enhancing future economic vitality. It \nproves that the wayfinding system is essential in the urban built environment. Conversely, \nsky, railing, and a few other visual elements had a negative impact, whereas building was \nfound to have a positive impact, potentially reflecting a different interpretation of enclosure \nquality, which supports walkability for pedestrians on the streets. This result is inconsistent \nwith the results of previous research that found sky and sidewalk to be positively related to \nvitality  using  SVI  (LI  et  al.  2022),  which  could  be  caused  by  differences  in  geographical \ncontext. It was also found that review count was negatively correlated with Ecology, which \nmight stem from a lack of available space in the public realm for street planting. This result \ncontradicts prior research, which suggests that street greenery has a positive impact on walking behaviours in Hong Kong (LU 2019) and that vegetation enhances street vitality (JIANG \net al. 2022). However, it did provide similar result which aligns with the findings of Y. LI et \nal. (2022), who found the greenery seem to show a degree of negative correlation when focusing  on  a  commercial  complex  site  in  Japan.  This  may  suggest  that  poorly  positioned \ngreenery may obstruct key commercial areas, potentially negatively affecting the economic \nvitality of stores. Future research should aim to conduct a more comprehensive analysis of \nthe relationship between street greenery and store-level economic vitality in Hong Kong. \n\nThe quality of Scale, Enclosure, and Access was all found to be positively related to review \nintensity, highlighting the importance of human-scale design quality in enhancing pedestrians’ experience and street vitality and supporting the benefits of appropriate street planning \nand design. Lastly, sentiment score was found to have a positive relationship with both greenery and ecology perception, albeit with relatively low strengths. This is in line with previous \nresearch that greenery can provide psychological benefits. Nevertheless, no statistically significant correlations  were established with other variables, suggesting the need for further \nresearch. The sentiments reported in reviews can be complex and might yield mixed results \ncompared to review intensity. \n\nRegarding macro-level factors, access to transportation was found to have a positive impact \non the dimensions of economic vibrancy, which is in line with previous research that suggests \npublic transportation facilities improve accessibility for non-local communities (HUANG et \nal. 2020). Additionally, the presence of visitor-oriented urban functions, such as hotels and \nAirbnb, were positively associated with economic vibrancy at the store level. The number of \nPoints of Interest (POIs) was found to have a relatively high impact among the macro-level \nvariables, which is consistent with earlier findings that land use density and functional mix \naffect economic vitality (LONG & HUANG 2019, XIA et al. 2020). However, our study sur-\nprisingly did not find significant correlation between park size and economic vitality, probably because park accessibility does not necessarily equate to increased economic activity in \nretail  or  commercial  stores.  Although  increasing  pedestrian  volume  can  increase  vitality, \nother driving forces, like perceived landscape qualities or urban micro-level amenities, are \nnecessary for attracting people to stay and linger so as to promote urban economic vitality. \n\nConclusion \n\nThis study offers several important contributions to the existing literature. Firstly, it provides \na unique perspective on quantifying  the dimensions of economic  vitality at the individual \nstore level, using a case study of chained coffee shops in Hong Kong. The study employs \ndata mining and NLP techniques to measure users’ sentiment scores from reviews, offering \na novel approach to this area of research. Secondly, the dimensions of economic vitality are \nstatistically evaluated in relation to both macro-level planning variables and micro-level perceived  landscape  qualities,  including  subjectively  measured  perceptions  and  objectively \nmeasured visual elements based on SVI dataset. This can help derivation of quantifiable design strategies and implementable guidelines to enhance the economic vitality of neighbour-\nhoods. Our preliminary data analysis suggests that compared to macro-level characteristics, \nsubjectively measured perceptions such as Scale, and objective visual elements, such as signboards, can have a significant impact on economic vitality. The objective visual elements in \nthe  streetscape  can  complement  the  subjectively  measured  perceptions  and  vice  versa. \nThirdly, although no statistically strong associations were found between sentiment scores \nand built environment factors, the study suggests that visual greenery and Ecology perception \ncould  play  a  positive  role  in  affecting  sentiment  scores,  which  is  beneficial  in  promoting \neconomic vitality. Lastly, this research adds to our knowledge of future recommendations for \nretail store location selection, and provides actionable insights for landscape architects on the \ndesign of streetscapes, with the goal of creating economically vibrant cities through meaningful placemaking. \n\nNevertheless, this research has several limitations. Firstly, the dataset could be enhanced by \nincluding comparison with other brands, such as Pacific Coffee, which holds a similar market \nshare  to  Starbucks  in  terms  of  coffee  outlets  in  Hong  Kong.  This  would  help  reduce  any \nbiases in the conclusion. Secondly, recent studies have shown that people's walking behaviour has a non-linear relationship with the built environment, and therefore, the vitality of an \narea may be influenced in a similar way. In future research, multiple walking radii could be \nemployed to gain deeper insights into this phenomenon. Thirdly, Thirdly, the accuracy  of \npredictions of subjectively measured landscape perceptions could be improved by either increasing the size of the training set or by employing more advanced machine learning algorithms such as Convolutional Neural Networks. Lastly, it would be beneficial to further explore other perceived landscape qualities or psychological perceptions, such as safety, in future studies. \n

Introduction \n\nThe cover of the eighth issue of the Journal of Digital Landscape Architecture JoDLA 8-2023 \nshows imagery, captured using a drone, of the city of Bad Neuenahr-Ahrweiler in Germany, \na region which was severely impacted by a flood disaster in 2021. Showing damage caused \nby severe floods or extreme fires is one of the many ways digital landscape architecture can \ncontribute to Hazard Management, one of the issues of resilient landscape architecture. However, our profession would much prefer to use landscape modelling to prevent some of these \ndisasters. This issue of JoDLA presents the current capacity our profession has for doing so. \n\nAfter being listed in Scopus, the journal is now also listed in DOAJ (Directory of Open Access Journals). Wichmann publisher has made accessible the JoDLA, and its forerunner publication Digital Landscape Architecture, as open access papers since 2013 and therefore provides ten years documentation of research in the area of Digital Landscape Architecture. \n\nThe  DLA  2023  is  organized  by  the  next  generation  of  professors  at  Anhalt  University  in \nDessau, Germany, where the Digital Landscape Architecture – Con was founded.  \n\nProf.  Dr.  Matthias  Pietsch,  the  local  chair  of  the  2023  DLA,  suggested,  after  the  COVID \npandemic, to focus on the issues of our endangered landscape by calling the main theme for \nthis year’s conference and of the JoDLA 2023 Future Resilient Landscapes. \n\nIn addition to the main theme, we have provided a number of other possible areas for submitting papers on current research or outstanding practice in digital landscape architecture. \nWe received 98 extended abstracts and can now present the result of a rigid two-phase double-blind review process. \n\nThe eighth issue of the Journal of Digital Landscape Architecture 8-2023 covers 66 contributions on the following seven current areas of research and prototype applications in digital \nlandscape architecture: \n•  Resilient Landscape, Global Change and Hazard Response  \n•  Landscape and Building Information Modeling (LIM + BIM) and other Standardizations in Digital Landscape Architecture  \n•  Algorithmic Design and Analysis Landscapes  \n•  Geodesign Approaches, Technologies, and Case Studies  \n•  UAV Imagery and Remote Sensing and Digital Fabrication in Landscape Architecture  \n•  Visualization, Animation and Mixed Reality Landscapes (VR, AR)  \n•  Teaching and Hybridization in Digital Landscape Architecture \n\nWe are very pleased that the worldwide academic community continues to grow in spite of \ncontinuing crises. The accepted abstracts come from seventeen countries:  \n\ntwenty-eight entries from the United States, fourteen from Germany, ten from China, five \nentries each from Turkey, four from Canada, three each from Hungary, Italy and Switzerland, \nand two each from Australia, Finland, Indonesia, Netherlands, Norway, and Spain. \n\nAnd from the following countries one entry each was accepted: Brazil, Georgia, and Singapore. We are very happy to have authors from countries that have contributed in the past, as \nwell as those who contributed for the first time. \n\n\nWe hope you will appreciate the eighth edition. The printed copies will be sent out on request \nto all participants before the conference at the end of May 2023. \nYou  will find all the contributions online as open access publications at the  gis.Point and \ngis.Open platforms of Wichmann http:\/\/gispoint.de\/jodla.html. \n\nWe would also like to invite you to the next DLA conference. The 25th international conference on information technology in landscape architecture, Digital  Landscape  Architecture \nDLA 2024 with the main theme “New Trajectories in Computational Urban Landscapes and \nEcology”, will be held from June 5 to 7, 2024 at the Vienna University of Technology, Austria. \n\nThe Journal of Digital Landscape Architecture invites you to submit ideas for special issues \nand topics. Please follow our continuously updated announcements and call for papers and \nposters at www.dla-conference.com. Here you will also find the complete online documentation of the DLA beginning from the year 2013. For earlier contributions of DLA publications, you may ask our JoDLA office. \n\nErich Buhmann, Stephen Ervin, Pia Fricker, Sigrid Hehl-Lange, James Palmer, \nand Matthias Pietsch \n

LiDAR-Based Digital Modeling and Comparative \nAnalysis of Urban Street Tree Form and Dimensions \n\nAbstract:  Numerous  workflows  exist  to  computationally  generate  three-dimensional  tree  models \nwhich effectively simulate their real-world counterparts. This research hybridizes several existing and \nnew approaches to tree modeling to improve growth models based on point cloud data. The digital tree \nmodels are created in Blender using an add-on called The Grove, enabling digital trees to grow according to light availability, with full control over their branching structure and form. These three-dimensional tree models are then measured and their dimensions compared to the point cloud counterparts, \nwith average values indicating that the digitally-grown trees are relatively similar to the point cloud \ntrees though smaller in most dimensions. The results demonstrate that point-cloud models of trees can \nbe used to improve computational tree growth models leading to improved tree visualization. \n\nIntroduction \n\nOur objective is to create a hybrid workflow to model context-specific digital tree models \nbased on LiDAR data of existing trees. We also aim to visualize the tree models by placing \nthem within a rendered virtual environment. Our hypothesis is that point clouds of street trees \ncan be used to improve computational tree growth models, leading to improved visualizations \nof trees. Visual realism is a critical part of this research, since capturing the materiality, light, \nand atmosphere of the landscape can resonate with audiences. Our motivation for this project \nis to improve upon our recent research in computational tree modeling which generated three-dimensional tree models based on scientific data without sacrificing visual realism, yet which lacked  any  methods  for  comparing  the  modeled  trees  with  real-world  tree  information (ACKERMAN et al. 2022).  \n\nLandscape architects model sites of significant physical size, places which are naturally dynamic and which can take decades to fully develop according to the designer’s vision. Thus, \nit is logical that most 3D modeling software is not currently suited to simulating landscape \ncharacteristics. This territory is often taken up through adapting software intended for modeling trees and terrain for games and film, tools such as SpeedTree, a standard industry tool \nfor creating realistic trees and plants, and Terragen, software used to create large-scale photorealistic natural environments. In recent years, many landscape architects have begun using \nLumion, a real-time renderer which integrates with most 3D modeling software and has a \nlarge and accessible library of trees and other vegetation. \n\nConstantly improving imaging technology has allowed us to digitally model landscapes for \nseveral decades (LEWIS 2012). Yet distinct challenges exist in modeling natural elements of \nthe landscape. In contrast to the well-defined geometry of architectural and industrial objects, \nthe organic variation of natural elements and the multi-part composition of vegetation presents unique difficulties. For example, trees are comprised of a trunk, branches, twigs, and \nleaves, each following a similar pattern but with unique formation. Where a single model of \nan architectural element such as a window can be used repeatedly in a scene without creating visual dissonance, a single model of a tree cannot be multiplied without looking artificial. In order to overcome this artificiality, digital tree simulations must integrate architectural and self-organizing  components  of  tree  growth  to  create  scientifically-informed  tree  models \n(PALUBICKI et al. 2009). \n\nSeveral models have been created to computationally generate unique three-dimensional tree \nmodels. The Algorithmic Beauty of Plants describes the application of L-systems to generate \na variety of tree branching structures which build upon earlier work of others’ to computationally simulate branching patterns (PRUSINKIEWICZ et al. 1996). Weber and Penn developed \ndigital tree models which focused more on visual realism than strict adherence to botanical \nprinciples. Their model integrates branching, pruning, leaf orientation, stem bending from \nwind, and vertical attraction, and realistic materials (WEBER & PENN 1995). De Reffye et al. \nused characteristics of tree mortality and regeneration to generate digital models of tree species growth over time, a data-informed method to create vegetation that strictly adheres to botanical  structure  and  development.  While  effective,  this  method  requires  knowledge  of botany as well as their specific computational methods (DE REFFYE et al. 1988).  \n\nMethods for creating scientifically accurate, realistically-rendered digital trees has improved \nsignificantly in recent years; such as digitally modeling an endangered eucalyptus woodland \n(CHANDLER et al. 2021), and digitally modeling and visualizing fifty years of growth in a \nWisconsin forest (HUANG et al. 2021). This use of field specimens for material texturing is \nan emerging tree visualization practice that help capture the realism of the landscape being \ndepicted (DEMETRESCUE et al. 2020). Yet many of these techniques have been limited by the \nhigh  level  of  programming  skill  required  to  apply  these  techniques  in  a  meaningful  way, \nrunning the risk of stalling the use of landscape visualization in scientific communication \n(BELL 2001). \n\nHigh levels of  graphic realism in landscape  visualization  are valuable in part due to  their \nability to reliably replicate similar levels of human cognition that occur when viewing a physical landscape site (SHI 2020). Yet realism in digital landscape visualization is often challenging given the number of trees and the amount of detail required in tree geometry (BAO et al. 2011, COLDITZ et al. 2005). These digital tree models are burdened with simulating \ninteraction and competition between trees, responding to sun and shade, compete for light \nwith their neighbors, lose branches over time, and simulate a range of other tree growth factors which have long been understood as critical components of the development of a tree’s \nphysical form (BELLA 1971). However, it stands to reason that with a greater number of interrelated  factors  being  used  to  model  a  tree,  the  more  closely  we  must  understand  the \ncause\/effect relationship of the parameters being used. This understanding is especially critical when tree growth models also include context such as nearby architecture and neighboring trees. \n\nMethods  \n\nPoint Cloud Capture and Conversion \n\nA comprehensive model of urban street trees was developed using vehicular ground-based \nLiDAR to capture several sets of urban street trees in Zhengzhou, China. The capture was \nperformed by driving down several urban street corridors with LiDAR equipment on the roof \nof the vehicle. The goal of this LiDAR capture effort was to create several point cloud models \nshowing variation in tree maturity. Three different sets of tree maturities were captured: 5-6 \nyears, 8-13 years, and 13-18 years. We were able to capture different maturity levels because \nmultiple  tree  planting  efforts  had  occurred  in  the  area  over  several  years,  producing \nheterogeneous groupings of trees spanning over a decade of growth. All trees were planted \nin identical linear plans along urban streets with high traffic volumes. All trees were of the \nsame species, a large deciduous tree with the botanical name Platanus x acerifolia, commonly \nknown as the London Plane Tree. This species was ideal for our research as it is one of the \nmost common street trees throughout China and North America, making the project broadly \napplicable to several urban contexts (LI et al 2011, LU et al 2010).  \n\nOnce captured, the point cloud model was processed in Lidar360 software in order to classify \nthe  point  cloud  into  tree  canopy  and  ground  elements.  The  canopy  point  cloud  was  then \nseparated into individual tree point clouds for analysis. This separation was done in Lidar360 \nusing an algorithm based on the shortest-path metabolic ecological theory, which uses the \nfact that vascular plants optimize the shortest possible distance from leaf to root to determine \nevery  point’s  belonging  to  a  particular  trunk  (TAO  et  al.  2015).  Each  point  cloud  was \nclassified and colorized before exporting to an LAS dataset (Fig. 1).  \n\nThe LAS dataset then needed to be converted to physical geometry for visualization. This \nwas  done  by  using  the  three-dimensional  modeling  software  Rhino  and  its  parametric \nmodeling tool, Grasshopper. In Grasshopper, we used the Volvox component to load the LAS \ndataset, create a voxel for every point, and export to a mesh. We then used the Weaverbird \ncomponent to subdivide and smooth the mesh. The resulting geometry provided a reasonably \nlegible approximation of a three-dimensional tree model which delineated each tree’s trunk, \nbranching structure, and canopy fullness (Fig. 2). \n\nTree Growth Modeling \n\nWe selected the intermediate-aged group of 8-13 years for use in tree growth modeling, as it \nincluded enough branching and canopy detail for comparison, while also being small enough \nto minimize the computational load in iterative development of a growth model. The 8-13-\nyear  model  was  exported  from  Rhino  as  an  FBX  file  and  imported  into  Blender,  another \nthree-dimensional modeling program. Blender allows intuitive yet sophisticated tree growth \nsimulation  through  an  add-on  called The  Grove,  which  provides  an  interface  for  growing \ngroups of trees with precise control of growth characteristics, species, and age. The Grove \nalso enables tree growth in response to light and shade, competing with neighboring trees for \nlight and responding to shade from nearby objects. \n\nTo begin the growing process, we selected the Platanus x acerifolia from the preset list of \navailable species in The Grove. These presets, which included many common trees, provided \na starting point with settings for the unique growth characteristics for the selected species. \nWe then placed a seedling tree at spacing intervals identical to the point cloud trees and grew \nthe seedling trees to 10 years of age. Through a trial-and error process of visual comparison \nbetween the 8-13-year point cloud mesh and the 10-year Grove model, we adjusted specific \ngrowth characteristics and re-grew the seedling trees again to 10 years of age. With each step \nwe noted the adjustment and captured an image of the tree group (Tab. 1). \n\nThrough iterative adjustment and re-growth, we gradually improved the growth model. After \nnine iterations, the tree growth model bore enough resemblance to the LiDAR model with \nregard to branching, structure, and canopy that we were satisfied with the settings. A visual \ncomparison of the final growth model and the LiDAR model demonstrates the results (Fig. 3). \n\nResults and Discussion \n\nWe hypothesized that point cloud models of trees could be used to improve computational \ntree growth models. Referring back to Table 1, the change in form and structure from the first \niteration to the ninth is striking. It is possible that this process could be seen as a form of \nmodel validation against physical counterparts, forming the basis for accepting the landscape \ncognition  that  occurs  when  viewing  images  that  include  these  digital  tree  models.  This \npresents implications for use of digital tree models in performance calculations. Lidar360 has \nthe ability to generate a report showing dimensions for each tree within the point cloud model. \nThese values can be used in climate-based calculations such as the U.S. Forest Service Tree \nCarbon Calculator (USDA 2022). This and other tools allow calculation of carbon dioxide \nsequestration  and  aboveground  biomass,  critical  factors  in  mitigating  climate  change.  We \nperformed a comparative study of the dimensions of trees from Lidar360 and dimensions of \ntrees generated in this iterative study using the Grove. Trunk diameter of trees from the Grove \nwere taken by importing the tree meshes into Rhino and creating a clipping plane at 1.37 \nmeters from the ground, the approximate level at which DBH (diameter at breast height) is \ntaken. The diameter of each trunk was measured (Fig. 4). \n\nTo calculate tree canopy volume, we developed a crown envelope which essentially wrapped \nthe tree canopy in an enclosed volume. This builds on recent work in transforming urban tree \npoint clouds into three-dimensional crown models (GUO et al. 2021, MÜNZINGER et al. 2022). \nBecause we imported leafless trees into Rhino to reduce computing load, we added a small \nbuffer at the ends of branches to account for the larger volume when leaves are present (Fig. \n5). \n\nOverall, the Grove tree models average height was slightly higher than Lidar360 – an average \nof 10.173 meters vs. 9.910 meters. However, in every other measurement the Grove trees \naverage  values  were  somewhat  lower  than  those  in  Lidar360.  The  differences  are  small \nenough that we feel that we are close to a digital growth model that can produce trees for use \nin analysis and simulation. Our aim is to be as close as possible to approximating real-world \nvalues, and we will continue to iteratively adjust the Grove trees and analyze their dimensions \nuntil they more closely matched Lidar360. Narrowing the gap between digitally-grown trees \nand real-world counterparts will be critical if we wish to use the dimensions of trees grown \nwith The Grove and Blender to perform similar carbon calculations. This would provide a \nvaluable tool for responsibly determining future performance of urban street trees. \n\nConclusion and Outlook \n\nFuture directions of this work will aim to expand the workflow to include additional common \ntree  species  using  a  similar  workflow  of  point  cloud-based  iterative  growth  modeling.  As \npreviously mentioned, we also aim to quantify the digital models created with The Grove and \nBlender in order to perform predictive calculations for carbon sequestration in urban settings. \nCombining these calculations with visualizations of mature urban street trees may well be a \npowerful  advocacy  tool  for  promoting  increased  tree  planting  in  urban  areas  while \nresponsibly depicting the likely visual character of such plantings.  \n\nDespite these successes, there are several components of this research that are problematic. \nA primary issue is the number of software programs and skillsets required to move through \nthe phases of these workflows. Unless we are able to streamline the workflow significantly, \nthis  level  of  landscape  modeling  and  visualization  will,  as  Bell  (2001)  stated,  remain  an \nunderutilized tool in scientific communication. \n\nAn additional problem is the significant computational power needed to run the tree growth \nsimulations and Unity visualizations. Even with the high-end computer used to generate the \nmodels and visualizations, 10-20 minutes was needed to generate a group of 20 trees grown \nto 35 years of maturity – approaching an apparent upper limit on the amount of trees that can \nbe  modeled.  These  trees  also  experienced  some  lag  time  in  Unity  that  resulted  in  a  less \nresponsive experience using the software. This is a long-standing issue with rendering 3D \nvegetation using current high-end computing power, mentioned by Weber & Penn (1995), \nColditz et al. (2005), Bao et al. (2011), and others. This suggests that issues with realism and \nlimitations of computing power will persist and should be anticipated as a regular part of this \nwork. \n\nThis  research  has  overcome  some  of  the  primary  challenges  that  have  long  existed  in \nmodeling the natural landscape, primarily the difficulty in capturing the organic variation of \nnatural  elements.  It  has  added  new  knowledge  of  modeling  a  tree’s  physical  form  and  its \nbehavior among other trees, building upon decades of work to devise L-systems, botanically-based models, visual models, and others. Ongoing development of this research can further improve  the  ways  that  we  model,  analyze,  and  apply  computationally-grown  trees  to contemporary challenges. \n

Neural Radiance Fields for Landscape Architecture \n\nAbstract: In this paper, we examine potential applications of Neural Radiance Fields (NeRF) in the \nfield of landscape architecture. NeRF is a state-of-the-art method for novel view synthesis and volumetric scene reconstruction based on real-world training data. Our paper addresses NeRF and its derived models with a focus on the use and application of Instant-NGP, a method developed by researchers from the technology company NVIDIA. We discuss experimental applications of NeRF based on the case study of the post-disaster landscape of Ahr Valley, Germany, affected by a 100-year flood in \n2021. In particular, we are interested in the benefits of NeRF in comparison to other landscape modeling \nmethods, such as Structure-from-Motion (SfM) or Multi-View-Stereo (MVS), which use similar data \nas input.  \n\nThis study shows that the application of NeRF technology can be a promising alternative for capturing \nand visualizing landscape scenes. The study focuses especially on tasks and situations where the larger \nspatial context – the landscape – is of interest and importance. The technological aspects of how NeRF \nmodels work are relevant, but our main focus is on their potential implications for the field of landscape \narchitecture. Technical development and research in the scientific field of computer vision are accelerating rapidly. As users, rather than developers, of digital tools, we believe that NeRF technology re-\nquires professional validation through real-world landscape projects. \n\nIntroduction \n\nUpon reviewing a corresponding article on computer science, we developed a more comprehensive understanding of what can be generated with a Neural Radiance Field (NeRF) and, \nconsequently, the relevance and potentials of this technology and method in future developments of spatial design in general and more specifically, in landscape architecture. The NeRF \napproach comes from the computer science field of self-learning systems – as “neural” refers \nto “self-learning” – and we recognize the task of introducing this method to digital landscape \narchitecture as an urgency, which our contribution is centrally dedicated to. In this context, \nwe set out to generate on-site images – starting with the university campus and ending with \na significant flooded area after a disaster – that we could use for our related experiments with \nNeRF technology.  \n\nNeRF – Neural Radiance Fields \n\nNeural Radiance Fields (NeRF) is a method for novel view synthesis and volumetric scene \nreconstruction based on real-world training data. NeRF was introduced by (MILDENHALL et \nal. 2020) and, since then, has gained traction in computer vision and related fields (GAO et \nal. 2022, TEWARI et al. 2022). “In its basic form, a NeRF model represents three-dimensional \nscenes as a radiance field approximated by a neural network. The radiance field describes \ncolor and volume density for every point and for every viewing direction in the scene” (GAO \net al. 2022). The original approach by Mildenhall et al. “represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location (x; y; z) and viewing direction (\n)) and whose output is the volume density and view-dependent emitted radiance at that spatial location” (MILDENHALL et al. \n2020). The NeRF model uses a set of two-dimensional RGB images, and their camera poses \nto create synthetic three-dimensional scenes. These scenes can be rendered into new images \nor video animations of photo-realistic quality (GAO et al. 2022). NeRF models can also be \nexported as simple mesh models. Emerging from the field of computer vision, the primary \nfocus of the NeRF method is to produce visual representations of a scene, surface, or object. \nUnlike other methods and sensors in remote sensing and environmental modeling, NeRF does \nnot originate from a surveying or measurement context. NeRF uses internal coordinate sys-\ntems instead of geographic reference systems, which were not a priority in its development. \nIn the field of landscape architecture, the fact that the NeRF model is not connected to a real-world coordinate system that potentially links data to a ground-truth reference might be un-\nusual at first. The rooting in scanning and surveying that led to the rise of lidar point cloud \nmodels  in  the  field  is  being  replaced  with  a  kind  of  ground  truth  of  images.  The  article \n“Ground truth to fake geographies: machine vision and learning in visual practices” by GIL-FOURNIER & PARIKKA (2021) is of importance to this discussion and, particularly where the \nauthors argue that “ground truth has shifted from a reference to the physical, geographical \nground to the surface of the images.” \n\nA NeRF model is not limited to generating a radiation field but can also be used to generate \npoint-based radiation fields (XU et al. 2022) or voxel-based models (YU et al. 2021). Since \nits publication in 2020, the paper ‘NeRF: Representing Scenes as Neural Radiance Fields for \nView  Synthesis’  by  MILDENHALL et  al.  (2020)  has  inspired  many  researchers  to  advance, \nadjust, and refine their methods (GAO et al. 2022, TEWARI et al. 2022). Especially the processing speed metric has been a major threshold in making the method available to a wider \narray of users, as it is directly connected to the complexity of scenes and the hardware necessary for their generation. Comparing the element of speed between the newer and older \nmodels, we can observe that the former outperforms the latter by several orders of magnitude. \nWhile processing a specific scene takes twelve hours in 2020 (MILDENHALL et al. 2020), the \nsame scene takes only about five seconds in the middle of 2022 (MÜLLER et al. 2022).  \n\nGAO et al. (2022) provide an overview of existing literature grouped based on their focus on \napplications such as three-dimensional reconstruction, image processing, or urban applications. Especially interesting is a model for large-scale scene reconstruction (TANCIK et al. \n2022) that lets us envision potentially global scale models. Significant improvements have \nbeen made to NeRF models, creating a wide range of applications, including “urban mapping \n\/ modelling \/ photogrammetry, image editing \/ labelling, image processing, and 3D reconstruction and view synthesis of human avatars and urban environments” (GAO et al. 2022). \nRecent advances in NeRF model performance have also made this technology more accessible to professionals in related fields outside of computer vision. More specifically, professionals from fields involved in digital visualization and aesthetics, such as landscape architecture, will be encouraged to test and develop their own models in relation to their specific \ntasks and topics. \n\nNeRF Aesthetics \n\nCustomary techniques for reconstructing three-dimensional landscape scenes, such as point \nclouds or vectors derived from photogrammetry, result in models whose aesthetics are detached from their physical context – the surrounding landscape. Where the lidar scanner rays \nend for a point cloud model, a black hole opens as the model background. Such models represent their own digital aesthetics and stand in stark contrast to the realism of photography \nand film. From an aesthetic point of view, there was always a significant difference between \nthe navigable three-dimensional model and the modeled real scene. Lidar scans, or photo-\ngrammetric scene reconstructions, seem to be functionally limited by their rootedness in tech-\nnical correctness and dimensional accuracy. It is difficult to implement diverse, complex, and \nassociative topical links in these models. In contrast, NeRF technology translates the ability \nof photography or film to capture the full context of a scene, including the background, into \na complex three-dimensional model with an identifiable background (Fig. 1 and 2). A NeRF \nmodel generates a detailed reconstruction of variables, which are key in registering a scene. \nIn addition to position and color, other variables transferred to the model include light intensity, darkness, and transparency. The ability to incorporate these elements presents an unprecedented three-dimensional realism (Fig. 3). Point cloud models, with high point densities and an even distribution of points, appear sparse up close and denser from a distance, where \nthis  higher  density  does  not  correspond  to  increased  information.  Combining  point  cloud \nmodels with different resolutions or resampled data can thus be useful for creating large models. Christophe Girot describes such combined models through the term he coined as cloud-ism (GIROT 2020). As we have established the possibilities of the NeRF method, we propose to counteract the newfangled term cloudism, again with a classic term – realism. Landscape \nin the form of a model is still most accurately understood – by laypersons and experts alike \n– when it corresponds to the common appearance of the surrounding landscape. \n\nInstant-NGP \n\nFor the generation of our experimental NeRF outcomes, we used Instant-NGP (Instant Neural \nGraphics Primitives), an open-source software framework developed by NVIDIA. The software framework processes Neural Graphics Primitives that, in addition to NeRF, can also be used for Gigapixel images, neural Signed Distance Functions (SDF), and Neural Radiance Caching (NRC). Our paper is limited in scope to NeRF models. Instant-NGP is proving to be \none of the most popular and regularly updated NeRF generation solutions. It trains a NeRF \nin seconds using multi-resolution hash encoding. The coordinates are hashed and used as an \nindex into a stack of multi-resolution data arrays, drastically reducing the number of parameters per model. The NeRF model is constrained by a unit cube bounding box set at a coordinate space of [0,1]³. The model has the highest resolution around a central point positioned \nat the center of the unit cube, at [0.5, 0.5, 0.5]. \n\nCase Study Ahr River Valley \n\nFor our initial experimentation with the application of NeRF technology, we focused on the \ncase of the Ahr Valley in Germany in the aftermath of the 2021 flood disaster. We obtained \nthe related fieldwork data through camera tours and UAV flights on-site. In the summer of \n2021, between July 12th and July 15th, the Ahr River Valley experienced a 100-year flood as \na result of pronounced heavy regional rainfall events in connection with a low-pressure system. In addition, the soils in the affected regions of Rhineland-Palatinate and South West-phalia could hardly absorb any additional water (GERMAN WEATHER SERVICE 2021). After the flood,  which took the lives of  many people and caused extreme destruction, the  hasty \nreconstruction activity did not necessarily lead to sustainable design and building. \n\n“The moment after a natural disaster is a window of time that can be used to adapt-to-climate \n(change), but this opportunity is in many cases demonstrably wasted. […] After a disaster, \namnesia leads people to forget about what primarily should be designed and built” (REKITTKE \n& NINSALAM 2022). Without a thorough analysis of a disaster, economically and ecologically \nsensible decisions become unlikely. There is a danger in conducting post-disaster analysis \nand the subsequent planning and design relying solely on documents like maps or legal texts, \nwhich operate on a high level of abstraction. It is imperative to incorporate what the people \nthemselves have seen (REKITTKE & NINSALAM 2022). We are interested in NeRF technology \nfor this particular reason, as it opens up new possibilities for visual realism and the ability to \nintegrate different temporal layers into a single landscape model. Disasters reveal snapshots \nof many aspects that should have been taken into account during planning phases and are \novershadowed once the developments are carried through a short time later. In this pursuit, \nwe  aspire  to  preserve  the  memories  of  a  flood  disaster  by  creating  appropriate  landscape models. Like in an autopsy, the aim is to fill the common gap between reality, recollection, and  forward  planning  with  evidence  that  is  supposed  to  trigger  cogitation (REKITTKE  & NINSALAM 2022). \n\nData Collection and Processing \n\nFor testing NeRF models in the context of post-flood Ahr River landscapes, we created an \nextensive dataset consisting of 106 video and image samples using UAV-mounted cameras \n(Fig. 4) and ground-based handheld smartphone devices. Our data were collected in two separate sessions. The first was during the flood event in July 2021– sporadic and ad hoc. The \nsecond was in September 2022, in the course of systematic fieldwork. Our aim was to create \ncases using one of the most common NeRF methods available. All NeRF models were trained \nlocally using Instant-NGP. The GitHub repository (GITHUB \/ instant-ngp 2022) provides documentation  on  software  and  hardware  requirements,  installation,  pre-processing,  training, \nand rendering NeRF, as well as exporting. Another document on GitHub provides additional \nadvice on the process (GITHUB \/ nerf_dataset_tips 2022). We created a separate NeRF model \nfor each set of input data, following a list of six sequential processing steps: 1) data acquisition, 2) data pre-processing and frame extraction, 3) pose estimation, 4) NeRF model training, \n5) video export, and 6) post-processing. \n\n1) Data acquisition for each site was carried out using lightweight, field study-ready collection devices: a DJI Mini drone and an iPhone 11 Pro. For all data acquisition, we used the \nhighest  possible  resolution  of  the  devices.  The  drone  videos  were  shot  at  2.7K  resolution \n(2720x1530), 23,97 fps, in MPEG-4 format. With the smartphone camera, we shot videos at \nFull HD resolution (1920x1080), 59,94 fps, in MPEG-4 format, and pictures at 12MP resolution (4032x3024), in JPEG format. Shots in the  wide-angle camera  mode (0.5x, 13 mm \nequivalent focal length, 120° field of view) were particularly effective. In total, we collected \n96 videos and 10 image sequences, a raw data package of 35 Gigabytes. \n\n2) For the video shots from the field, we extracted a set of sequential frames ranging from 50 \nto over 400 images. The image sequences were filtered to the same amount. NeRF models \nbased on the method of Müller et al. (2022) do not infinitely increase resolution or quality \nwith a more extensive set of input images. Mildenhall et al. (2020) and Müller et al. (2022) \nuse tens to hundreds of images to train NeRF models. We followed the recommendations \npresented on the GitHub forum (GITHUB \/ nerf_dataset_tips 2022). Furthermore, we tested \nthe application of digital image enhancement techniques such as sharpening, noise reduction, \nand super-resolution to improve matching image detection. \n\n3) We used the COLMAP pipeline that was part of the Instant-NGP codebase to process an \nestimate of the camera poses for each image set. The resulting JSON file containing the camera parameters for each image was saved in a folder along with the original images in the \nformat TRANSFORMS.JSON. \n\n4) We trained our NeRF models using the interactive GUI (Graphical User Interface) that \nwas included in the codebase. The GUI offers a variety of different tools for training, visualization, and export, as well as allowing the user to interactively move through a scene while \nthe  model  is  being  rendered  in  real  time.  Training  begins  by  launching  the  GUI  from  an \nAnaconda prompt, and within seconds, the model evolves from blurry noise to a clear representation of a scene. Once the training reaches a satisfactory level, the training progress can \nbe saved as a JSON file – called snapshot – which can be used to reload the NeRF model or \nto create an animation. The GUI facilitates interactive creation and saves a camera path along \na set of key frames that can be used to export a video animation. \n\n5) The codebase allows exporting of flythrough video animations of the NeRF model using \nthe previously generated training progress and camera path. The export is handled outside \nthe GUI in an Anaconda code prompt using Python bindings. We exported a range of video \nanimations up to 4K resolution at 30 fps. \n\n6) The exported videos can be easily edited using common video and image editing tools. \nSince both the input and output of the NeRF model are image-based, digital editing and processing  pipelines  such  as  image  sharpening,  noise  removal,  or  frame  interpolation  can  be \napplied before and after NeRF modeling. The user has full control over both pre- and post-NeRF model media, as would be the case with photography, photogrammetry, or map-making. \n\nNeRF for Landscape Architecture \n\nAlthough we have been working with NeRF technology for a limited time and therefore did \nnot  yet utilize its full potential,  we can already identify and highlight some of its specific \nstrengths.  We  offer  a  selection  of  tested  applications  for  NeRF  technology,  generally  for landscape architecture and, more specifically, in the context of our case study. In addition to \nthe enormous technological advances that have determined the rise of NeRF technologies in \nrecent years, the method has to be tested in relation to issues concerning landscape architecture. \n\nMulti-Resolution Models \n\nFor NeRF models, it applies that their resolution is not developed in relation to the model but \nto the depth of information captured from the input images. “The multiresolution aspect of \nthe hash encoding covers the full range from a coarse resolution \nmin that is guaranteed to \nbe collision-free to the finest resolution \nmax that the task requires. Thereby, it guarantees \nthat all scales at which meaningful learning could take place are included, regardless of sparsity” (MÜLLER et al. 2022). In the context of the Ahr Valley after the flood, we are able to \ncreate a lightweight but complex three-dimensional model that enables capturing environ-\nments at multiple scales: from the rocks in the Ahr riverbed to the flowing water, from the \nriverbanks and adjacent vegetation to patterns of the urban fabric, and from the mountains in \nthe background to the clouds in the sky above the valley. The main benefit we see in our \ncase-based NeRF models is that they feature a high spatial depth, capturing the sky, clouds, \nand even distant landscape features such as mountains, valleys, and urban areas. In the case \nof the Ahr Valley, the NeRF model consolidates all flood-relevant factors to be discussed \nsimultaneously in one model: the change in sediment flows in the river, the altered course of \nthe river, the destruction of urban settlements and agriculture in the Ahr valley near the floodplain,  the  topography  of  the  valley  where  water  has  accumulated  downstream.  More  advanced NeRF models can present the rich contextual depth of the mapping in the form of a \nnavigable three-dimensional model. Xiangli et al. (2022) outline the nature of such prospective models by expanding the notion of rendering scenes at multiple resolutions by “modeling \ndifferent scenes at multiple scales with drastically varying views on multiple data sources” \n(XIANGLI et al. 2022). \n\nObject Focus versus Open World Scene? \n\nBased on our current research and studies, we observe a certain level of contradiction regarding the  great landscape potential of NeRF  models and their technical  nature. NeRF is designed to feature a central point in the model, from which the resolution gradually decreases towards the edges of the bounding cube. This raises the question of whether NeRF models \nare inherently object-oriented (single object) and how this might impact the modeling of non-point-centric open-world scenes, such as landscapes. Is our positive assessment of the NeRF \nlandscape model accurate, or will the triumph of the NeRF models primarily extend to object \nmodels, for example, in the context of architectural projects? Instant-NGP NeRF models are \nconstrained by a maximum resolution bounding box at its center. But in our case study, we \nfed this “machine” exclusively with data from landscape photography and landscape videos, \nthereby obtaining effective landscape models. We suggest that future explorations are “to be \ncontinued.” \n\nComparison to Photogrammetry and Point Cloud Models \n\nThere are partial overlaps in data collection and processing methods between NeRF models \nand photogrammetric processing. Both methods use two-dimensional raster images as input \ndata and share further similarities in the initial processing of this input data. A wide range of \nNeRF methods, including the one of Müller et al. (2022), use COLMAP, a package for SfM, \nto extract camera poses. Models derived from lidar scanning or photogrammetric modeling \nstill offer higher geometric accuracy than NeRF models (LEHTOLA et al. 2022). For our own \ncomparison of the different methods, we created a set of 406 frames from a selected drone \nflight, which we used as input for corresponding NeRF and photogrammetric models. The \nNeRF model was generated with Instant-NGP, and the photogrammetry model was processed \nas a dense point cloud in Agisoft Metashape. The point cloud was exported as a file in LAS \nformat with 12 million points and a file size of 326 MB. \n\nThe output quality of a photogrammetry process is assessed based on the accuracy of where \nthe resulting points are positioned with respect to a ground truth reality. Passive sensing data, \nsuch as intensity return data or true color imagery captured by other sensors, may only suport subsequent analysis or enhance visualization. In many ways, the NeRF model sits somewhere between the perception of space and the perception of textures, materials, light, and color. There are various metrics can be used to assess the quality of a NeRF model. Many \nfundamental advantages of photogrammetry, such as a relation to a “real world” Coordinate \nReference System (CRS) and transformations of the model with respect to this CRS, are not \nyet realized in the NeRF system we used. Nonetheless, this does not preclude the possibility \nof implementing them in future applications. \n\nA NeRF differs from all the traditional three-dimensional scene formats commonly used in \nthe field, some of which include vectors or meshes, grids, and point clouds. Each format can \nhave distinct ways of formulating a representation, which can yield a unique set of advantages \nand disadvantages depending on the format used. It can therefore be difficult to judge a NeRF \nin relation to the qualities of these formats. Some of these metrics may be embedded in the \nprocess or acquisition technology used for data generation to determine the potential for accurately representing a scene from the start. Different metrics apply to data obtained from \nphotogrammetry or lidar scanning. Such comparisons exist in various areas that are tangentially linked to landscape architecture, for example, in heritage preservation. Data obtained \nthrough lidar scanning is among the most accurate geometric data available in modern scanning techniques but lacks the ability to accurately capture the texture and diagnostic color \ninformation  (DOSTAL  &  YAMAFUNE  2018).  Perhaps  the  most  fascinating  outcome  of  the \nmethod is not the NeRF model itself but the images and videos that are generated from the \nmodel (Fig. 5 and 6). MILDENHALL et al. (2020) state that the results of view synthesis are \nbest viewed as videos. \n\nMaterial Noise \n\nMetrics such as reflection or change in transparency and color as a function of position are \nnot considered part of the physical enterprise of the object or scene in the current literature \non photogrammetrically derived models. Rather, they are viewed as  factors that distort or \ncorrupt the signal in ways that may need to be eliminated in order to derive a high-quality \nmodel.  In  scenes  produced  by  photogrammetry,  removing  water-surface  reflection  effects \npresents a challenge (PARTAMA et al. 2018). Materials featuring difficult optical properties –including but not limited to absorptivity, reflectivity, scattering, challenging texture and complex shape or geometry – still pose challenges in photogrammetry (NICOLAE et al. 2014). The \ndistinction between signal and noise is pronounced in the literature on photogrammetry and, \nmore generally, in remote sensing and earth observation. The NeRF model, on the other hand, \nallows data otherwise defined as noise to be used to visualize unstable materialities, surfaces, \nand objects. In our case study, for example, we had the means to illustrate the unstable nature \nof the Ahr River – with its changing water levels up to extreme flooding conditions. \n\nMulti-Source NeRF \n\nA multi-source model is based on input data generated through multiple acquisitions for the \nsame or a similar area. This method can be used in situations where only a sparse set of input \ndata is available to increase the resolution of the NeRF model by adding additional input data \nfor angles or features not previously captured. For our case study, we trained a NeRF model \nof the Kalvarienberg Monastery and the surrounding area in the town of Ahrweiler with sev-\neral of our drone acquisitions and eventually improved the model’s resolution. In addition, \nour model captures the changing light conditions between diffused and direct sunlight caused \nby different cloud conditions during the recording period. The various parameters – geometry, color, lighting, texture, and translucency – captured by a NeRF model may be acquired \nindependently. Each parameter can be derived from a separate set of input data. The final \nNeRF synthesis model allows navigating between these parameters in relation to the position \nand direction of a particular view. In working with a 3D landscape model, this synthesis is a \nnovelty that opens up considerable potential. \n\nMulti-Temporal NeRF \n\nIt sounds almost unattainable within the limitations and resources of our current time, but a \nsimultaneous coupling of movement through time, and movement through space, is fundamentally possible with NeRF technology. This option is yet to be defined and therefore, we \npropose to use “Multi-temporal NeRF models” when referring to the visualization of changing layers of time in the course of changing positions. Multi-temporal NeRF models use mul-\ntiple sets of images captured at different times and utilize them as the input to produce novel \nviews that interpolate between the images. The model synthesizes the input data and allows \nit to move through time while moving through space. A Multi-temporal NeRF model makes \nit possible to capture movements, visualize ongoing processes, and depict all kinds of patterns \nof change. For example, the growth or the changing state of the health of vegetation can be \ndocumented in this way. The intensity of the changes captured by the model can be related \nto the temporal extent of the capture and the intensity of the change in the underlying object \nor  study  surface.  Multi-temporality  is  a  common  concept  and  method  in  geosciences,  in \nwhich remote sensing  observations collected at different times are combined into a single \nmulti-temporal image or model. Multi-temporal analyses enable the detection and visualiza-\ntion of changes in  spatial patterns over  time. The concept  has  taken root in areas  such  as \narchitecture and landscape architecture to understand changes in the built environment. The \nlandscape architect, in particular, can think of numerous possible uses. The depiction of seasonal changes in the city, landscape, and vegetation are only a few of them. We find this \nmethod to be the most effective to this date for purposes of representing the “before” and \n“after” conditions of a site. \n\nIn 2021, it was already demonstrated that NeRF models could be trained with unstructured \ncollections of photographs taken at different times, from different angles, and under different \nlighting conditions. The model registers the static geometries of the scene but interpolates \nbetween color and illumination in dependence on the view position (MARTIN-BRUALLA et al. \n2021). It is possible for a NeRF to process a sequential set of images of the same scene at \ndifferent  times  of  the  day,  times  of  the  year,  and  so  on.  The  associated  different lighting \nconditions of these different images, which show a time difference, allow the generation of \nan outstanding level of multi-temporality in a single NeRF result. The resulting model allows \nthe user to literally move through time as they move through space – made possible by adjusting the different radiation fields between the time-shifted images. \n\nIn our case study, the Multi-temporal NeRF shifts the digital model from a state of representation to a state of simulation of the underlying flood event. Our NeRF model captures and \ninterpolates  situations  found  in  two  self-contained  trajectories.  The  model  combines  two \ndrone flights – one in 2019 and the other in 2022 – over the Ahr Valley municipality of Rech, \nGermany. The acquisition from 2019 shows a historic bridge over the Ahr River, connecting \nthe two halves of the village. The second acquisition captures the same location in the autumn \nof 2022, after the flood event destroyed parts of the bridge, swept away several buildings \nsouth of the bridge, and visibly changed the course of the river (Fig. 7). Both drone flights \nhave different trajectories and viewpoints, allowing us to create a model relating one set of \nviews to the 2019 acquisition and the other set of views to the 2022 acquisition. In the resulting NeRF model, we can navigate through the internal digital coordinate system and observe \nthe changing states in quasi-real-time. \n\nFlooding as a Multi-Temporal NeRF Application \n\nDue to the presence of temporal components – such as large amounts of water that flows in \nand out of a particular site – flood zones are generally considered to be suitable for the application of multi-temporal NeRF. Instant-NGP’s interactive GUI also provides a set of visual \ndebugging tools that can be used to uncover the internal structure of input and output neurons. \nThe parameters of these tools are recorded as part of a keyframe animation. For our case \nstudy dealing with speculative scenarios of a flood-ravaged valley, we used the partial acti-\nvation of neurons as a rising green light field to simulate the rising waters of the flood through \nvisuals (Fig. 8). Through this experimentation, we found a simple yet very powerful tool for \ndigital flood simulation with full visibility of all model elements. Supporting this hypothesis \n(LI et al. 2022) have shown that NeRF models can be used to simulate ultra-complex climate \nevents. \n\nConclusion \n\nThis paper presents a baseline study on  various approaches and  methods of  working  with \nNeRF models in landscape architecture. The aim is to inspire and encourage researchers in \nrelated fields to develop in-depth studies on the applications of NeRF. Our interest in NeRF \nis fundamentally rooted in the idea that landscape is anything but static, which is, at the same \ntime, where we find significant potential in this approach. NeRF models can be useful for \n“wandering” through changing light conditions or addressing moving objects, such as water, \nclouds,  birds,  cars,  trains,  and  others.  Different  materials  can  be  evaluated  through  direct \ncomparison.  Reflections  and  light,  as  well  as  structure,  can  be  included  in  their  changing \nappearance. Changed terrain, for example, differing terrain heights in the course of a construction project, can be evaluated. In addition, the same scenes and objects could be recorded \nunder different lighting conditions in order to enable a critical evaluation. For example, early \nin the morning, at noon, in the evening, or in cloudy weather. The NeRF interpolates between \nthe input images, allowing for seamless switching between different states within the result-\ning model. It is an important task to think of a landscape model not as a static set of coordi-\nnates, i. e. point clouds, raster, or vector data, but as a set of parameters that are constantly \nchanging. As in a landscape as such, the model changes depending on the viewer’s position \n– an unstable model. The fact that NeRF crosses the border between modeling and simulation \nsuits the instability and openness of the landscape subject. We are dealing with a technology \nthat is still very new and largely untested but whose potential seems enormous. Most com-\nputer graphics algorithms and techniques developed over more than half a century assume \nmeshes or point clouds as three-dimensional scene representations for rendering and editing. \nNeural rendering, on the other hand, is such a recent field that the term was first used in 2018. \nFor this reason, there is an inevitable gap between the available methods that can work with \nclassic three-dimensional representations and those that can be applied to neural representa-\ntions (TEWARI et al. 2022). This is definitely true for the field of landscape architecture, and \nwe look  forward to the developments and publications that  will qualify NeRF  models for \nlandscape architecture in the years to come. \n\nIn 2019, Christophe Girot described how the point cloud model overcomes the separation \nbetween model, architectural drawing, renderings, or other visualizations. “In the “cloudist” \napproach, there exists no separation between a model, a section and a plan: they all stem from \nthe same cloud of design information. Separate renderings or visualizations become quite \nunnecessary, since the views generated are directly derived from the model, with their own \nsingular  aesthetic”  (GIROT  2019).  NeRF  models  remove  the  threshold  between  different \nforms of representation (Fig. 9). The NeRF method offers qualities similar to point clouds \nbut significantly reduces the separation or the visual contrast between the model and reality.\n

Preface \n\nA network of engaged individuals teaching new information technologies at the International \nMaster of Landscape Architecture program MLA at Anhalt University established the annual \nConference on Digital Landscape Architecture DLA at our school in 1999. The DLA has to \ndate been held in Istanbul, Malta, Zurich, Munich, Aschersleben, twice in Boston, and frequently on our local campuses in Bernburg, Dessau and Köthen. In 2020 and 2022; the DLA \nwas hosted by Harvard University. Harvard  was able to organize the DLA 2022 as a full \nhybrid conference when the Pandemic still limited traveling. The Journal Digital Landscape \nArchitecture JoDLA which we have developed for the conference is listed in the international \ncitation database Scopus. This publication is supported academically by eighty reviewers and \nboard members. Here, we wish to thank them all for their committed long-term support.  \n\nHaving 64 papers (from more than 20 countries) which successfully meet the standards of \nthe review process coordinated by the founder of DLA, Prof. Erich Buhmann, and his editorial team once again guarantees a very substantial conference. \n\nThe 24th international conference on digital landscape architecture is now back at our internationally known campus in Dessau. Prof. Dr. Matthias Pietsch, this year's local host, is also \norganizing DLA 2023 as a hybrid conference in collaboration with Prof. Dr. Nicole Uhrig \nand Prof. Trevor Sears. Even now having more than two years of experience in organizing \nvirtual lectures and conferences, meeting all the additional needs for an international conference in a hybrid format is still a challenge and requires many university resources. We are \nvery thankful for the team spirit of so many colleagues at Anhalt University, and to the board \nmembers of the DLA for their support once again. \n\nThis  year’s  main  theme  “Future  Resilient  Landscapes”  is  a  core  issue  in  several  research \nefforts of Anhalt University. Our keynote speakers will widen our view on the challenges \nenvironmental design faces in coping with global change. \n\nAs we are able to work with a digital twin of our globe, we can focus on how to use the tools \nof digital landscape architecture in order to meet the challenges of global warming. \n\nAll positively reviewed papers are available as open access papers at Wichmann publisher \nand the outcome of the conference will be published DLA 2023 in Dessau at https:\/\/www.dla-\nconference.com\/ as in the past. \n\nWe are looking forward to welcoming many of you again in person in Dessau in 2023 and \nhopefully in the following years as well. At the same time, we looking forward to seeing the \nmany participants  who for a variety of reasons  will be virtually attending the 24th Digital \nLandscape Architecture Conference. \n\nKöthen, March 15, 2023 \n\nProf. Dr. Jörg Bagdahn, President Hochschule Anhalt \/ Anhalt University \n

The Influence of Perceived Landscape Qualities on \nEconomic Vitality: A Case Study of a Retail Coffee \nChain \n\nAbstract: As a crucial aspect of vitality, the economic facets of vitality at the store level have yet to be \ninvestigated in greater detail, and its relationship with micro-level perceived landscape qualities in the \npublic realm requires further examination. The recent advancements in big data and Machine Learning \n(ML) have presented an exceptional opportunity to empirically investigate vitality and its association\nwith the urban built environment. This research aims to comprehensively gather various dimensions of\neconomic vitality for retail coffee chain, using Starbucks stores in Hong Kong as a case study. The\nstudy incorporates the previously under-researched dimension of customer sentiment, which is interpreted through the Natural Language Processing (NLP) model. Additionally, the study collects both\nsubjectively measured landscape perceptions and objectively extracted visual features from street view\nimagery (SVI) using ML algorithms and crowdsourced surveys. Results indicate that micro-level perceived landscape qualities, such as scale and signage, have a greater impact on economic vitality than\nconventional macro-level planning characteristics. The findings of this research have the potential to\ninform and support a successful and economically dynamic retail model at the neighbourhood scale,\nfurther emphasizing the economic significance of human-scale landscape design in the public realm.\n\nIntroduction \n\nUrban vitality has long been considered a critical aspect of successful cities in place making, \ncontributing to resilience, creativity, and innovation for sustainable development (CHEN et \nal. 2022, MONTGOMERY 1998). First introduced in JACOBS (1961)’ seminal book, and initially defined as the presence of active street life, the concept of vitality has evolved into a \nmulti-faceted connotation that encompasses various dimensions, with economic vitality being regarded as a critical component (HUANG et al. 2020). \n\nQuantifying vitality remains a challenge due to its complex nature, encompassing both social \nand economic aspects. Previous studies have used macro-scale indicators, such as the number \nof entertainment facilities within a city, to measure vitality. However, with the rise of big \ndata,  new  opportunities  have  emerged  to  quantify  vitality.  Despite  this,  researchers  have \npointed out that some big data sources, such as cell phone records, have relatively low data \nquality. Therefore, researchers have shifted to using the intensity of geo-tagged catering businesses from POIs to measure economic aspects of vitality (XIA et al. 2020, YE et al. 2018). \nAlternatively, LONG & HUANG (2019) compared economic vitality across hundreds of cities \nin China using crawled numbers of reviews from popular social media websites that collects \nratings for restaurants. More recently, researchers have proposed more complex frameworks \nthat utilize information available from online service evaluation platforms, such as incorpo-\nrating service quality and scale in addition to popularity (LI et al. 2022). In conclusion, the \nspatial organization of small food establishments plays a significant role in reflecting human \nactivity patterns. Utilizing customer reviews to gather information about economic vitality \nhas also proven to be a valuable approach. However, these methods fail to consider the emotions  and  sentiments  of  user  groups,  which  play  a  crucial  role  in  the  human-environment \ninteraction and contribute to the economic and social aspects of individual businesses at a \nmicro-level (LIU et al. 2020). Additionally, calculating an overall vitality index using certain \nweighting methods for each dimension may be inexorably subject to bias, as different businesses may provide different types of services and target distinct demographic groups with \nvarying economic statuses. \n\nIn view of these factors, exploring the economic vitality of chained catering services, specifically  coffee  retail,  can  provide  an  innovative  approach  for  comparison  across  different \nstores. Coffee retail is often considered a crucial type of \"third place,\" where people gather \nfor socializing without an obligation to stay. It creates a sense of place, a key aspect of promoting  vitality  (OLDENBURG  1989).  The  success  of  coffee  retail  is  influenced  by  various \nfactors such as the environment, service quality, context, and food and beverage offerings. \nHowever, literature in the hospitality industry suggests that chained coffee shops often use \nstandardization and intra-regional diversification strategies based on ‘portfolio theory’ to reduce costs, providing a tactical advantage and greater survival rates over single-location franchises (PARK & JANG 2022). As a result, the differences in services and food offerings between stores within the same chained business can be largely ignored when comparing their \neconomic vitality, offering a solution to the limitations of previous methods. \n\nOn the other hand, previous research has shown that the design of the built environment can \naffect vitality. For instance, building morphology, density, typology, and land use mix have \nall been linked to vitality (HUANG et al. 2020, LONG & HUANG 2019, XIA et al. 2020, YE et \nal. 2018). However, these studies focused merely on objective environment factors at a macro \nand planning scale, but  neglected the nuances of daily life experience and the micro-level \nperceived landscape qualities which can be critical in promoting vitality. \n\nPerceived landscape qualities can be measured objectively, subjectively, or through a combination of the two measures. Advancements in Computer Vision (CV) technology have allowed for more efficient and high-throughput methods like using emerging urban data such \nas SVI to measure perceived qualities (DUBEY et al. 2016, ITO & BILJECKI 2021, ZHANG et \nal. 2018). In a nutshell, the perceived landscape qualities can be largely categorized into subjectively measured design perceptions and objectively measured visual elements (QIU et al. \n2022). These human-centric perceived qualities, which can proxy how people perceive the \nenvironment when walking down the street, have been used to examine the impact of microlevel  perceived  landscape  qualities  on  walking  behaviour  or  housing  prices  (BASU  & SEVTSUK 2022, SONG et al. 2023, SONG et al. 2022).  \n\nThough several recent studies have sought to reveal the correlation between perceived land-\nscape qualities and street vitality (CHEN et al. 2022, JIANG et al. 2022), they mainly focused \non pedestrian volume as a representation of vitality and only  studied a limited number  of \nperceived landscape qualities. Further research is needed to investigate how perceived environment qualities contribute to the economic vitality of coffee retail at a micro-scale. Additionally, due to differences in measurement methods, subjectively measured perceptions have \nbeen shown to exhibit different spatial heterogeneity patterns in comparison with their objective counterparts (SONG et al. 2022). Thus, their separate impacts on economic  vitality \nwarrant further understanding. \n\nIn conclusion, our research endeavours to address the existing knowledge gaps by integrating \nthe human-environment interaction into the measurement of economic vitality across chained \ncoffee stores, and examining how economic vitality is influenced by quantifiable micro-level \nperceived landscape qualities measured through both subjective and objective methods. Our \nresearch offers new insights in the following aspects: \n1) It sheds light on the multiple dimensions of economic vitality of chained coffee shops at \nthe store level and incorporates customer sentiment using advanced Natural Language \nProcessing (NLP) techniques. \n\n2)  The study measures both subjectively measured perceptions and objectively measured visual elements from SVI with ML tools.  \n\n3)  The relationship is disclosed between the perceived landscape qualities within the walking  radius  around  each  store  and  the  various  dimensions  of  economic  vitality,  by  the \ncomparison of the perceived landscape qualities with macro-level factors in relation to \neconomic vitality. \n\nData and Methods \n\nStudy Area and Data Source of Economic Vitality \n\nThe study area is Hong Kong, a high-density city that is one of the world's largest financial \ncentres with over 7 million residents. To control for factors that could impact the economic \nvitality of different services, chained coffee stores were selected for our investigation using \nbig data. By choosing stores from a single brand, the research can mitigate the influence of \nfood quality, service, and interior design and focus instead on other key factors such as the \nquality of the outdoor street environment and macro-level spatial qualities such as accessi-\nbility to transportation and points of interest (POI). This approach offers a straightforward \nresearch  design,  which  provides  a  clearer  understanding  of  the  economic  vitality  of  these \nstores compared to previous studies that have utilised a more broad-brush approach, observing citywide vitality in a coarser grid. Specifically, Starbucks coffee is chosen, a global market leader with over 150 stores in our study area. The analytical framework of this study can \nbe seen in Fig. 1. \n\nThe search results were finalised using the Google Map API, which returned information for \n158 Starbucks stores (Fig. 2) located throughout Hong Kong after initial data cleansing. It is \nworth mentioning although data was also obtained from the local restaurant evaluation platform 'Open Rice', the number of reviews for Starbucks Coffee on this platform was insufficient, so this data was not included in the study. Information gathered from the web crawl for each store comprised its geographic coordinates, address, and, most importantly, information on reviews, including the number of reviews, the number of review images, overall review score, review score distribution, and detailed review text (the 20 most recent reviews after January 2017).  \n\nNLP  is  a  field  of  Artificial  Intelligence  and  computational  linguistics  concerned  with  the \ninteractions between computers and human (natural) languages. It enables the interpretation \nof the human language in a meaningful way, for instance, to understand the emotions. Senti-\nment scores were calculated for each store based on its review texts using the state-of-the-art \nBidirectional Encoder Representations from Transformers (BERT) model, an NLP technique \nthat  uses  a  self-attention  mechanism  and  eliminates  biases  from  left-to-right  momentum \nwhich was used in previous models. The use of BERT has been increasing in recent studies \n(ALAPARTHI & MISHRA 2021). The  model  was pre-trained on a review dataset containing \n150k reviews and reported to achieve an exact prediction accuracy of 67% and an off-by-1 \nscore prediction accuracy of 95% for reviews in English. The sentiment score for each store \nwas calculated as the average of the sentiment scores interpreted from its crawled reviews, \nwith a score between 1 and 5, where 3 represents a neutral sentiment, 5 represents the most \npositive sentiment, and 1 represents the most negative sentiment. \n\nMeasuring Micro-level Perceived Landscape Qualities  \n\nThe street network for this  study  was obtained from  OpenStreetMap and points along the \nHong Kong road network were sampled every 50m using the QGIS platform (ZHANG et al. \n2018). To examine the correlation between perceived landscape qualities and economic vitality, points were selected within the 250m walking radius around each of the chained coffee \nstores located on the ground floor. Points located on highways were excluded as they do not \nreflect the pedestrian experience. The coordinates of points were fed into the Google Street \nView Static API and street view images (SVI) were obtained (heading = 0, field of view = \n90, image size = 800 x 400 pixels). After discarding grey or indoor images, 2,110 SVIs were \nleft and used for further analysis. \n\nTo extract objectively measured visual features from SVIs, the widely used ML algorithm \nPSPNet pre-trained on the ADE20K cityscape dataset was adopted. Around 20 streetscape \nelements, such as sky, sidewalk, trees, buildings, etc., were successfully extracted from each \nSVI. The view index of each visual feature (i. e., the percentage of an element  within the \nentire image) was calculated and the average value of each element within the walking radius \nwas used as the perceived objective feature quality for each store. A randomly sampled SVI \nand its semantic segmentation result using the PSPNet algorithm are shown in Fig. 3. \n\nMeanwhile,  in  accordance  with  previous  studies,  we  aimed  to  quantify  eight  subjectively \nmeasured design perceptions: typology, order, ecology, enclosure, aesthetics, accessibility, \nrichness and scale (EWING et al. 2006, SONG et al. 2022; TIAN et al. 2021). To achieve this, \nwe utilised perceived quality scores obtained from 300 SVIs, with 80% used for training and \n20% for testing, gathered from crowdsourcing surveys in a previous study (TIAN et al. 2021). \nThese scores served as the dependent variables, while the view indices of key street elements \nserved as the independent variables for the prediction task. \n\nEight ML algorithms were used and compared for prediction performance: K-Nearest Neighbours (KNN), Support Vector Machines (SVM), Random Forest (RF), Decision Tree (DT), \nGaussian Process (GP), Voting Selection (VS), ADA Boost (ADAB) and Bagging Regression  (BR).  The  ML  models  were  evaluated  by  using  R-squared  (R2)  and  Mean  Absolute \nError (MAE). The best-performing model for each subjectively measured landscape quality \nwas then selected to predict the scores for the entire SVI dataset in Hong Kong. \n\nMacro-level Conventional Planning Qualities and Correlation Analysis \n\nIn  addition  to  the  micro-level  perceived  landscape  qualities,  macro-level  planning  factors \nwere also computed to evaluate their impact on vitality. A 1.5 km buffer was created around \nthe centre of each store location, and the relevant  variables  were obtained from the Hong \nKong Geodata Store (https:\/\/geodata.gov.hk\/gs\/) and processed in QGIS. The variables included ‘number of POIs’, ‘number of hotels’, ‘number of Airbnb’, ‘number of elderly facilities’, ‘number of bus stops’, ‘distance to metro station’, and 'size of park area', which have \nbeen reported to contribute to street vitality. For example, accessibility to transportation facilities such as the distance to metro stations and the  number of bus stops can impact the \npotential crowds around the station. The accumulation of destinations (number of POIs) can \nattract people and promote vitality. Meanwhile, park size represents the neighbourhood-scale \nenvironmental quality, which contributes to subjective well-being and often attracts people. \nAdditionally, Airbnb can attract tourists and is essential to vitality. \n\nThe  study  conducted  further  statistical  analysis  to  determine  the  correlations  between  the \ndifferent dimensions of economic vitality of ground-floor stores and various groups of built \nenvironment qualities. Pearson correlation analysis was applied to provide a comprehensive \ncomparison between macro and micro-level factors and their relationship with economic vitality.  \n\nResults \n\nComparison of Economic Vitality \n\nThe 158 Starbucks Coffee outlets in Hong Kong are dispersed throughout various regions of \nthe city. Among these outlets, about 13 stores are located in the ‘Central’, which is its most \nconcentrated area, 91 stores of them on the ground floor and 67 stores on other floors ranging \nfrom -1st to 9th level. Because the intent of this research is to assess the economic vitality \nand its relationship with the surrounding context and integrates the Sentiment analysis based \non reviews, those review numbers were excluded if they were less than 30 times, and 127 \nstores were left. And because the stores located on the ground level have more direct interactions with the built environment, the stores on other levels were further removed, and 79 \nstores located on the ground level left. The detailed statistics are demonstrated in Table 1. \n\nAlthough only ground-floor stores were utilized for further analysis, a preliminary comparison was performed with stores located on other floors to identify potential biases. And the \nstatistics revealed similar results. In summary, ground-floor stores make up approximately \n60% of the total stores analysed. The average rating for these stores is slightly higher compared to those on other floors. The image count suggests that customers are more likely to \ntake and post photos in stores located on the ground floor, which may be due to the surrounding built environment. With regards to sentiment scores, it can be concluded that stores received overall positive sentiment scores, as a neutral emotion is rated as 3.0 on the scale used. \n\nML Model Performances \n\nMultiple  ML  algorithms  were  used  to  determine  the  most  effective  models  for  predicting \nsubjectively measured perceptions. As shown in Table 2, while four out of eight variables \n(Typology, Order, Aesthetics and Richness) had low  R-squared (R2) values and  were ex-\ncluded from further analysis, the qualities of Access, Ecology, Enclosure, and Scale achieved \nR2  values  ranging  from  0.40  to  0.53.  These  prediction  accuracies  are  deemed  acceptable \ngiven the size of the training sample, and they partially outperformed results from previous \nstudies  (DUBEY  et  al.  2016,  ITO & BILJECKI  2021,  SONG et  al.  2022).  Therefore,  the  four \nselected perceived landscape qualities were predicted for all SVIs using the best-performing \nmodels (i. e., Gaussian Process, Voting Selection, and Bagging Regression). After determining the qualities of each street view, we linked them to the corresponding Starbucks store \nlocations  and  obtained  the  mean  value  for  each  store  as  the  neighbourhood's  subjectively \nmeasured perceptions. \n\nCorrelation Analysis and Discussion \n\nThe Pearson Correlation analysis was conducted to investigate the correlation between the \nfour dimensions of economic vitality and selected macro-level spatial attributes (Fig. 4). The \nresults indicate that many macro-level factors had a moderate to weak positive correlation \nwith the review count. For instance, besides the most prominent impact of Airbnb (0.3), bus \nstops, POIs, and hotels also showed a similar positive association with the review count (0.26 \nto 0.27). The image count showed a weak positive relationship with bus stops (0.21). However, the correlations between the overall score and sentiment score and macro-level planning \nfactors were negligible. Despite this, POIs (-0.16) and hotels (-0.16) had the highest strengths \nin correlation coefficients with the sentiment score, suggesting that they may have a poten-\ntially negative impact on visitors' emotions, which in turn may negatively affect the economic \nvitality of the stores. \n\nWe conducted a separate analysis for the micro-level perceived landscape qualities (Fig. 5). \nOn the one hand, out of the four subjective perceptions, the quality of Scale, showed a mod-\nerate positive correlation with the review count (0.35), while its correlation with the image \ncount was weaker (0.23). Additionally, the review count demonstrated a weak positive correlation  with  Enclosure  (0.27)  and  a  weak  negative  correlation  with  Ecology  (-0.27). The \noverall review score showed a positive correlation with Ecology (0.2). Similar to the macrolevel spatial qualities, the correlations between sentiment and subjective landscape qualities \nwere statistically negligible. However, Ecology reported the highest positive impact (0.15) \non sentiment. \n\nOn  the  other  hand,  the  correlations  between  the  objectively  measured  visual  features  and \neconomic vitality dimensions were similar in strength to the subjectively measured percep-\ntions. The review count demonstrated a strong positive correlation with signboard (0.42). \n\nAdditionally, the review count showed comparable weak positive correlations with several \nother visual elements, including sky (-0.24), tree (-0.25), road (-0.26), streetlight (-0.26), and \nrailing (-0.26). It also reported a weak positive correlation with building (0.23). The image \ncount exhibited a moderate positive association with signboards (0.3) and weak negative re-\nlationships with the sky (-0.21) and road (-0.22). The sentiment demonstrated a positive cor-\nrelation with trees, showing its consistency of correlation with the Ecology perception (0.15), \nthough the correlation strength is statistically insignificant. \n\nOur study provides a brand-new insight into the hitherto poorly understood relationship between store-level economic vitality and built environment factors. Most importantly, it was \nobserved that compared to macro-level variables, micro-level perceived landscape qualities \nexhibit  stronger  correlations  with  economic  vitality  dimensions.  Additionally,  objectively \nperceived visual features were found to complement subjectively measured perceptions. For \nexample,  signboard  was  found  to  have  the  highest  impact  among  all  perceived  landscape \nqualities, offering meaningful design suggestions for enhancing future economic vitality. It \nproves that the wayfinding system is essential in the urban built environment. Conversely, \nsky, railing, and a few other visual elements had a negative impact, whereas building was \nfound to have a positive impact, potentially reflecting a different interpretation of enclosure \nquality, which supports walkability for pedestrians on the streets. This result is inconsistent \nwith the results of previous research that found sky and sidewalk to be positively related to \nvitality  using  SVI  (LI  et  al.  2022),  which  could  be  caused  by  differences  in  geographical \ncontext. It was also found that review count was negatively correlated with Ecology, which \nmight stem from a lack of available space in the public realm for street planting. This result \ncontradicts prior research, which suggests that street greenery has a positive impact on walking behaviours in Hong Kong (LU 2019) and that vegetation enhances street vitality (JIANG \net al. 2022). However, it did provide similar result which aligns with the findings of Y. LI et \nal. (2022), who found the greenery seem to show a degree of negative correlation when focusing  on  a  commercial  complex  site  in  Japan.  This  may  suggest  that  poorly  positioned \ngreenery may obstruct key commercial areas, potentially negatively affecting the economic \nvitality of stores. Future research should aim to conduct a more comprehensive analysis of \nthe relationship between street greenery and store-level economic vitality in Hong Kong. \n\nThe quality of Scale, Enclosure, and Access was all found to be positively related to review \nintensity, highlighting the importance of human-scale design quality in enhancing pedestrians’ experience and street vitality and supporting the benefits of appropriate street planning \nand design. Lastly, sentiment score was found to have a positive relationship with both greenery and ecology perception, albeit with relatively low strengths. This is in line with previous \nresearch that greenery can provide psychological benefits. Nevertheless, no statistically significant correlations  were established with other variables, suggesting the need for further \nresearch. The sentiments reported in reviews can be complex and might yield mixed results \ncompared to review intensity. \n\nRegarding macro-level factors, access to transportation was found to have a positive impact \non the dimensions of economic vibrancy, which is in line with previous research that suggests \npublic transportation facilities improve accessibility for non-local communities (HUANG et \nal. 2020). Additionally, the presence of visitor-oriented urban functions, such as hotels and \nAirbnb, were positively associated with economic vibrancy at the store level. The number of \nPoints of Interest (POIs) was found to have a relatively high impact among the macro-level \nvariables, which is consistent with earlier findings that land use density and functional mix \naffect economic vitality (LONG & HUANG 2019, XIA et al. 2020). However, our study sur-\nprisingly did not find significant correlation between park size and economic vitality, probably because park accessibility does not necessarily equate to increased economic activity in \nretail  or  commercial  stores.  Although  increasing  pedestrian  volume  can  increase  vitality, \nother driving forces, like perceived landscape qualities or urban micro-level amenities, are \nnecessary for attracting people to stay and linger so as to promote urban economic vitality. \n\nConclusion \n\nThis study offers several important contributions to the existing literature. Firstly, it provides \na unique perspective on quantifying  the dimensions of economic  vitality at the individual \nstore level, using a case study of chained coffee shops in Hong Kong. The study employs \ndata mining and NLP techniques to measure users’ sentiment scores from reviews, offering \na novel approach to this area of research. Secondly, the dimensions of economic vitality are \nstatistically evaluated in relation to both macro-level planning variables and micro-level perceived  landscape  qualities,  including  subjectively  measured  perceptions  and  objectively \nmeasured visual elements based on SVI dataset. This can help derivation of quantifiable design strategies and implementable guidelines to enhance the economic vitality of neighbour-\nhoods. Our preliminary data analysis suggests that compared to macro-level characteristics, \nsubjectively measured perceptions such as Scale, and objective visual elements, such as signboards, can have a significant impact on economic vitality. The objective visual elements in \nthe  streetscape  can  complement  the  subjectively  measured  perceptions  and  vice  versa. \nThirdly, although no statistically strong associations were found between sentiment scores \nand built environment factors, the study suggests that visual greenery and Ecology perception \ncould  play  a  positive  role  in  affecting  sentiment  scores,  which  is  beneficial  in  promoting \neconomic vitality. Lastly, this research adds to our knowledge of future recommendations for \nretail store location selection, and provides actionable insights for landscape architects on the \ndesign of streetscapes, with the goal of creating economically vibrant cities through meaningful placemaking. \n\nNevertheless, this research has several limitations. Firstly, the dataset could be enhanced by \nincluding comparison with other brands, such as Pacific Coffee, which holds a similar market \nshare  to  Starbucks  in  terms  of  coffee  outlets  in  Hong  Kong.  This  would  help  reduce  any \nbiases in the conclusion. Secondly, recent studies have shown that people's walking behaviour has a non-linear relationship with the built environment, and therefore, the vitality of an \narea may be influenced in a similar way. In future research, multiple walking radii could be \nemployed to gain deeper insights into this phenomenon. Thirdly, Thirdly, the accuracy  of \npredictions of subjectively measured landscape perceptions could be improved by either increasing the size of the training set or by employing more advanced machine learning algorithms such as Convolutional Neural Networks. Lastly, it would be beneficial to further explore other perceived landscape qualities or psychological perceptions, such as safety, in fu-\nture studies. \n